\documentclass[runningheads,a4paper]{llncs}

\usepackage{latexsym}
\usepackage{setspace}
\usepackage{cancel}

\usepackage{graphicx}
\usepackage{appendix}
\usepackage{amssymb}
%\usepackage{dsfont}
\usepackage{amsmath}
%\usepackage{amsthm}
%\usepackage{cancel}
%\usepackage{verbatim}
%\usepackage{chngpage}
%\usepackage{fullpage}

\usepackage{color}

\usepackage{mathrsfs}

%\newtheorem{definition}{Definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{example}{Example}
%\newtheorem{question}{Open Question}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{Algo}{Algorithm}
%\newtheorem{remark}[theorem]{Remark}

\def\arr#1{\stackrel{#1}{\longrightarrow}}

\def\Aa{{\mathscr{A} }}

\def\Bb{{\mathscr{B} }}

\def\Cc{{\mathcal{C} }}

\def\Dd{{\mathbb{D} }}

\def\Ee{{\mathcal{E} }}

\def\Ff{{\mathcal{F} }}

\def\Zz{{\mathcal{Z} }}

\def\Nn{{\mathbb{N} }}

\def\Ss{{\mathcal{S} }}

\def\schm{{\mathfrak{s} }}

\def\Tt{{\mathcal{T} }}

\def\Ii{{\mathbb{Z} }}

\def\Jj{{\mathcal{J}}}

\def\Vv{{\mathcal{V}}}

\def\Rr{{\mathcal{R} }}

\def\Ll{{\mathcal{L}}}


\def\treeset{{\mathscr{T}}}

\def\contextset{{\mathcal{C}}}

\def\theory{{\mathcal{L}}}

\def\termset{{\mathcal{T}}}

\def\formulaset{{\mathcal{F}}}

\newcommand\univ{\mathsf{Univ}}

\newcommand\op{\mathfrak{o}}

\newcommand\dv{\mathtt{x}}

\newcommand\ydv{\mathtt{y}}

\newcommand\cv{\mathtt{z}}

\newcommand\thla{\mathcal{LIA}}

\newcommand\thdif{\mathcal{DIF}}

\newcommand\thord{\mathcal{ORD}}

\newcommand\thset{\mathcal{SET}}

\newcommand\thmset{\mathcal{MUS}}

\newcommand\natnum{{\mathbb{N} }}

\newcommand\intnum{{\mathbb{Z} }}

\newcommand{\hide}[1]{}
\newcommand{\yfc}[1]{\color{blue} {YF: #1 :FY} \color{black}}
\newcommand{\zhilin}[1]{\color{cyan} {ZL: #1 :LZ} \color{black}}
\newcommand{\lei}[1]{\color{green} {LE: #1 :EL} \color{black}}
\newcommand{\SDSIT}{SDSIT}
\newcommand{\Name}{Streaming data string to integer transducer}
\newcommand{\name}{streaming data string to integer transducer}
%\def\Ss{{$\mathcal{A}$\ }}

\title{The~Commutativity~Problem~of~the~Map-Reduce Framework: A Transducer-based Approach}
\titlerunning{Commutativity of MapReduce: A Transducer-based Approach}
\author{}
\institute{}

%\author{Yu-Fang Chen, Lei Song, Zhilin Wu}

\begin{document}

\maketitle

\begin{abstract}

Map-Reduce is a popular programming model for data parallel computation. 
In Map-Reduce, the \emph{reducer} produces an output from a list of inputs. Due the scheduling policy and the settings of machines, the input may arrive the reducers with different orders. The \emph{commutative problem} of reducers asks if the output of a reducer independent of the order of its inputs. The problem is in general undecidable due to Rice's theorem and thus is seemingly uninteresting. However, the Map-Reduce model is usually used for data analytics and thus requires very simple data and control flow. 
By exploiting the simplicity of the required program flows, we propose a simple programming language for reducers where the commutative problem can be decide by a reduction to the equivalence problem of \emph{streaming numerical transducer}. 
We show that the language is expressive enough for common data analytics operations.
\end{abstract}

\section{Introduction}
%What is Map-Reduce
Map-Reduce is a  popular framework for data parallel computation. It has been adopt in various widely used cloud computing frameworks such as Hadoop~\cite{Hadoop} and Spark~\cite{Spark}. In a typical Map-Reduce program, a \emph{mapper} reads from data sources and outputs a list of key-value pairs. The load balance mechanism of the Map-Reduce framework processes the key-value pairs and sends the pairs with the same key to the same \emph{reducer}, in the form of a key and a list of values. The reducer then iterates through the input list and output a key-value pair.

To be more concrete, taking the ``word-counting'' Map-Reduce program as an example. It counts the occurrences of each word in a set of documents. The mappers reads the documents and output for each document a list in the form of $(word_1, count_1), (word_2, count_2), \ldots, (word_n, count_n)$, where $count_k$ is the number of occurrences of $word_k$ in the document being processed. These lists will be reorganized into the form of $(word_1, list_1), (word_2,list_2), \ldots, (word_n,list_n)$ and sent to the reducers, where $list_k$ is a list of integers recording the number of occurrences of $word_k$ in the set of documents. Note that the \emph{order} of the integers in the lists can differ in different executions due to network latency, load balancing, etc.
This results in the \emph{ commutativity problem}.

%The communitativity problem
We say that a reducer is \emph{commutativity} if its output is independent of the order of its inputs. The commutativity problem asks if a reducer is commutativity. A study from Microsoft~\cite{XZZ+14} reports that XX\% of the reducers submit to their Map-Reducer platform are non-commutative. Among them, YY\% are confirmed as correctness bug by the programmers who wrote them. So we know that non-commutativity is a good indicator for errors in the programs. 
Moreover, having the commutativity property makes program testing easier. It is hard to reproduce a bug if the reducer under test is non-commutative. 

%The reason for studying syntatical restrictions 
The reducer commutative problem in general is undecidable by Rice's theorem. However, in practice, the reducers  are seldom Turing machines. They are usually used for data analytics and have very simple control structures and data types. Many of them just iterate through the input list and compute the output with very simple operations.
We want to study if the commutative problem of real-world reducers are decidable.

A simple programming language of reducers has been considered in~\cite{CHSW15}, where they allow only loops that iterate though the input list\hide{(c.f. Figure~\ref{language})}. They show that the commutative problem of even such a simple language is undecidable by a reduction to the satisfiability problem of Diophantine equation. In a scrutiny, the language is still too expressive for typical data analytics programs. For example, it allows multiplications of variables, which is a key element for the undecidable proof. 

In this paper, we propose a formalism named \emph{streaming numerical transducers (SNT)}, which is expressive enough to cover a huge percentage of data analytics reducer programs. We show that the equivalence and commutative problem of SNTs are decidable. Moreover, SNTs can be composed to form a commutative/equivalence proof of programs that read the input list multiple times.
Essentially, SNTs combine the features of register automata~\cite{XX} and counter automata~\cite{XX} with restrictions on the structure of the transition systems and the syntax.
The separation of data and control variables (inspired by~\cite{RP11}) and the requirement of independent variable evolving enables the decision problems of SNTs to be decidable. 
We believe such concepts provide good insights for reducer programming language design.

The rest of the paper is organized as follows. Section~\ref{sec:preliminaries} describes design of the streaming numerical transducer model, including the formal definition, the rationale behind the model design, and the types of data analytics reducer programs it can express. Section~\ref{sec:decision} discusses the decision problems and the procedure for solving the problems.

\hide{
\begin{figure}
	
	\caption{A Simple Programming Language for Reducers}
\end{figure}}

\section{Preliminaries}

For a mapping $\pi$, let $dom(\pi)$ and $rng(\pi)$ denote the domain and range of $\pi$.

Let $\Ii$ denote the set of integers. Let $X$ denote a finite set of variables ranging over $\Ii$ and $x,y$ are variables in $X$. We assume that $X$ contains a special variable $cur$, which is used to denote the current data value. Then a guard over $X$ is a formula defined by the rules, $g::= cur\ o\ c \mid cur\ o\ x \mid g \wedge g$, where $o \in \{=,\neq,<, >, \le, \ge\}$. Let $Y$ be another set of variables over $\Ii$. An arithmetic expression over $Y$ is defined by the rules, $e::= y \mid c \mid e + e \mid e-e \mid e * e \mid e / e$, where $y \in Y$ and $c$ is a constant over $\Ii$. For an expression $e$, let $vars(e)$ denote the set of variables occurring in $e$. Let $\Ee_Y$ denote the set of arithmetic expressions over $Y$. An assignment $\eta$ for $X \cup Y$ is a partial function from $(X \setminus \{cur\}) \cup Y$ to $\Ee_{X \cup Y}$ (the set of arithmetic expressions over $X \cup Y$) such that for each $x \in dom(\eta) \cap X$, $\eta(x)=cur$. Note that the assignments to the special variable $cur$ are disallowed.

A data word is a sequences of data values, that is, sequences $d_1\dots d_n$, where $d_i \in \Ii$ for each $i$.

A streaming numerical transducer (SNT) $\Ss$ is a tuple $(Q, X, Y, \delta, q_0, O)$ such that 
\begin{itemize}
\item $Q$ is a finite set of states,
%\item $K \in \Nn$ is the maximum number of data values in each position, 
\item $X$ is a finite set of control variables which is used to store some data values that have been met,
\item $Y$ is a finite set of data variables, which is used to aggregate some information for the output,
\item $\delta$ comprises the tuples $(q,  g, \eta, q')$, where $q,q'\in Q$, $g$ is a guard over $X$ (note that the variables from $Y$ do not occur in $g$), $\eta$ is an assignment for $X \cup Y$, 
%\zhilin{I am wondering whether we should add constraints e.g. $p_1 > 5$, which is not available in the original definition of streaming transducer}\lei{Constraints like $x > p_1$ is also not allowed? For me, it makes more sense to include such constraints.}
\item $q_0 \in Q$ is the initial state,
\item $O$ is the output function, which is a partial function from $Q$ to $\Ee_{(X \setminus \{cur\}) \cup Y}$.
\end{itemize}

%A SNT $\Ss$ is said to be \emph{generalized flat} if each SCC (strongly connected component) of the transition graph of $\Ss$ is either a single state or a collection of cycles that they share a unique state.

In this paper, we restrict our attention to SNTs $\Ss$ satisfying the following constraints.
\begin{description}
\item [1 (deterministic).] For every pair of distinct tuples $(q, g_1, \eta_1,q'_1), (q, g_2,\eta_2,q'_2) \in \delta$, it holds that $g_1$ and $g_2$ are mutually exclusive, that is, $g_1 \wedge g_2$ is unsatisfiable.
%
\item[2 (copyless).] For each $(q, g, \eta, q') \in \delta$ and each $y \in Y$, $y$ appears at most once in the collection of expressions $\{\eta(y') \mid y' \in Y\}$.
%
\item[3 (independently evolving).] For each $(q, g, \eta, q') \in \delta$ and each $y \in Y$, $\eta(y)$ contains no variables $y' \in Y$ such that $y' \neq y$.
%
\item [4 (generalized flat).] Each SCC (strongly connected component) of the transition graph of $\Ss$ is either a single state or a collection of cycles that they share a unique state.
\end{description}
Note that the ``copyless'' constraint forbids the use of the expressions of the form $y+y$ in the transitions.

The semantics of a SNT $\Ss$  is given by a transduction as follows: A configuration of $\Ss$ is a pair $(q,\beta)$, where $q \in Q$ and $\beta$ is a valuation of $X \cup Y$, that is, a partial function from $X \cup Y$ to $\Ii$. When reading a data word $w=d_1 \dots d_n$, $\Ss$ runs over $w$ from left to right. Let $(q, \beta)$ be the configuration of $\Ss$ reached after running over $w$, then the output of $\Ss$ is $\beta(O(q))$, if $O(q)$ is defined and $vars(O(q)) \subseteq dom(\beta)$, and the output is undefined otherwise.

A SNT $\Ss$ is said to be a SNT$_\pm$ if all the expressions occurring in $\Ss$ use only $+,-$, but not $\ast,/$.

\begin{example}[Max, average]
The max transducer over sequences of integers is given by the transitions $(q_0, 1, x < p_1, x:=p_1, q_0)$, where $x:= p_1$ assigns $p_1$ to $x$, and $(q_0, 1, x \ge p_1 , \emptyset, q_0)$, and the output function $O(q_0)=x$. The average transducer over sequences of integers is given by the transition $(q_0, 1, true, (sum:=sum + p_1, len := len +1), q_0)$, and $O(q_0)=sum / len$. 
\end{example}

\begin{example}[Example inspired by Pagerank]
The following transducer sum all the data values, except the last position, then it outputs a concatenation of the sum and the last tuple: $(q_0, 1, true, sum:= sum + p_1, q_0)$, $(q_0, k, true, (x_i:=p_i)_{1 \le i \le k}, q_1)$, $O(q_1)=(sum, x_1,\dots, x_k)$.
\end{example}

We focus on the following decision problems of SNT.
\begin{description}
\item[(Commutativity).] Given a SNT $\Ss$, decide whether $\Ss$ is commutative, that is, whether for each data word $w$ and each permutation $w'$ of $w$, the output of $\Ss$ over $w$ is equal to that of $\Ss$ over $w'$.
%
\item[(Equivalence).] Given two SNTs $\Ss_1,\Ss_2$, decide whether $\Ss_1$ and $\Ss_2$ are equivalent, that is, whether over each data word $w$, the output of $\Ss_1$ on $w$ is defined iff that of $\Ss_2$ on $w$ is defined, moreover, if the outputs of $\Ss_1$ and $\Ss_2$ are defined, then the output of $\Ss_1$ is equal to that of $\Ss_2$.
%
\item[(Non-zero output reachability).] Given a SNT $\Ss$, decide whether $\Ss$ has a non-zero output, that is, whether there is an input $w$ such that the output of $\Ss$ on $w$ is non-zero. 
\end{description}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
\yfc{can we describe the following Triangle-counting algorithm using the model?}
\zhilin{Could you describe how to implement the algorithm in MapReduce framework?}
\yfc{this is based on the sample code in Spark, I found antoher sample code in Hadoop, maybe fits the model better, check https://github.com/vertica/Graph-Analytics----Triangle-Counting/blob/master/src/com/vertica/mr/graphs/TriangleCounter.java}

\zhilin{I will describe my understanding of the algorithm in the following} 

The task comprises of three MapReduce jobs. 
\begin{description}
\item[Job1] Map: Filter out the pairs $(v1,v2)$ such that $v1 > v2$. Reduce: on the input $(v, w_1 \dots w_k)$ (where $v < w_i$ for each $i$), output the list $((v,w_1),0), \dots, ((v,w_k),0), ((w_1,w_2),1), \dots, ((w_{k-1},w_k),1)$.
\item[Job2] Map: Identity function. Reduce: on the input $((v1,v2),i_1 ... i_k)$, if $i_j=0$ for some $j$, then output $(1, i_1+...i_k)$, otherwise, output $(1,0)$.
\item[Job3] Map: Identity function. Reduce: on the input $(1,n_1 \dots n_k)$, ouput $((n_1+\dots + n_k),null)$.
\end{description}

\zhilin{The most challenging one is Job1. The reducer in Job1 need output each distinct pair $((w_i, w_j),1)$ for a list $w_1 \dots w_n$. For this transduction, at first we need extend the transducer to output a list of $(key, value)$ pairs, instead of a single $(key,value)$ pair. Moreover, the relatively complex transduction from lists to lists seems exceeding the capability of streaming transducers.}

\newcommand{\numTri}[1]{\triangle_{#1}}
Let $G = (V, E)$ be an undirected graph without self-loops or multiple
edges. For $u, v \in V$, $\{ u, v \} \in E$ denotes that $u$ and $v$
are adjacent. A  \emph{triangle} in $G$ is formed by $u, v, w \in V$ with $\{ u, v \},
\{ u, w \}, \{ v, w \} \in E$. 
We want to count the number of triangles in a given graph.

Suppose that the graph is described as a list of edges.

For each edge $\{ u, v \} \in E$, the algorithm sends the sets $\{ u \}$
and $\{ v \}$ to $v$ and $u$ respectively. If several messages are
sent to a vertex, they are merged by unions.
\yfc{So maybe we need to also support the data type ``set''}

After this operation, we get a list of pairs $(u, U)$, where $u \in V$ and $U$ is the set $\{ v : \{ u, v \} \in E \}$.

Then for each edge $\{ u, w \} \in E$, again we send the size of the set $| U \cap W |$ to both $u$ and $w$, where $U$ and $W$ are
the set of vertices adjacent to $u$ and $v$ respectively. 
\yfc{This is difficult in our model. We need to first traverse E (the first input list) and then get the corresponding set U and W from the 2nd list. Then count the size of their intersection. Maybe can be implemented in a slightly different way.}

Observe that for every $s \in U \cap W$, we have $\{ s, u \}, \{ s, w \}, \{ u, w
\} \in E$. Let $\numTri{\{u, v\}}$ denote the number of triangles
containing the edge $\{ u, w \}$. Then $\numTri{\{u, w\}}$ is sent to
both $u$ and $w$. If several messages are sent to $w$, they are merged
by summation. After this operation we get a list of pairs $(u, \sum_{\{ u, w \} \in E} \numTri{\{u, w\}})$.

Now consider a vertex $v$ in a triangle of $u, v, w$. The triangle is
counted in both $\numTri{\{ u, v \}}$ and $\numTri{\{ w, v \}}$. Hence
we need to divide the the number by 2 to get the number of triangles containing $v$. }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Consider the permutation $\tau_2$ and $\tau_n$ in \cite{CHSW15}. We can define two streaming data string transducers $\Ss$ and $\Ss'$ (note that $\Ss'$ is independent from $n$)  for $\tau_2$ and $\tau_n$. Then the commutativity of a given SNT $\Tt$ is reduced to the equivalence of $\Tt$ and $\Ss \circ \Tt$ as well as the equivalence of $\Tt$ and $\Ss'\circ \Tt$. Note that an equivalent SNT can be defined for $\Ss \circ \Tt$ and $\Ss' \circ \Tt$ respectively.

\begin{proposition}
The commutativity of SNTs is reduced to the equivalence of SNTs in linear time. 
\end{proposition}

\begin{proposition}
From SNT $\Ss_1$ and $\Ss_2$, a SNT $\Ss_3$ can be constructed in polynomial time such that $\Ss_1$ is not equivalent to $\Ss_2$ iff there is a data word $w$ such that the output of $\Ss_3$ over $w$ is nonzero. 
\end{proposition}

Therefore, the equivalence problem of SNTs is reduced to the non-zero output reachability problem of SNTs.

\section{Closure properties}

Boolean operations.

Union, intersection, complement

composition: It seems that \SDSIT are not closed under composition, similar to that of streaming transducers.

\section{Decision problems}

In this section, we consider the non-zero output problem of SNT$_{\pm}$. Recall that we assume that the SNTs are deterministic, copyless, independently evolving and generalized flat.

%equivalence, commutativity.
%
%Cost register automata may be relevant \cite{ADD+13}. 
%\yfc{The paper assumes finite input alphabet}

%Let us start with the following simple model, called \SDSIT$_{\pm}$, where the assignment expressions used in assignments are defined by the rules $e::= y \mid e+e \mid e - e$. Note that only $+,-$ are used here and constants are forbidden. Moreover, without loss of generality, we assume that for a \SDSIT$_{\pm}$, it only ouputs a single integer (instead of a tuple of integers).


%Suppose $\Ss_1=(Q_1, K, X_1, Y_1, \delta_1, q_{0,1}, O_1)$ and $\Ss_1=(Q_2, K, X_2, Y_2, \delta_2, q_{0,2}, O_2)$ are two generalized flat SDSIT$_{\pm}$. Without loss of generality, we assume that the state spaces (resp. the set of data variables, the set of output variables) of $\Ss_1$ and $\Ss_2$ are disjoint. Moreover, the SDSIT$_{\pm}$ $\Ss$ constructed from $\Ss_1$ and $\SS_2$ (cf. Proposition~\ref{prop-equiv-reduce}), satisfies the following property: 
%\begin{quote}
%\it the output variables in $Y_1$ are updated independently of those in $Y_2$: For each transition $((q_1,q_2),g,\eta,(q'_1,q'_2))$ in $\Ss$, for each $y_1 \in Y_1$(resp. $y_2 \in Y_2$), no variables from $Y_2$ (resp. $Y_1$) occurs in $\eta(y_1)$ (resp. $\eta(Y_2)$). \hfill ($\ast$)
%\end{quote}

%In the rest of this paper, we will assume that the SDSIT$_{\pm}$ $\Ss$ in the non-zero reachability problem satisfies that the set of output variables of $\Ss$ is $Y_1 \uplus Y_2$ and $Y_1,Y_2$ satisfy the constraint $(\ast)$.


\subsection{Normalization}

Suppose $\Ss=(Q,X,Y,\delta,q_0,O)$ is a SNT. Let $c_{min}$ and $c_{max}$ denote the minimum resp. maximum constant occurring in the transitions of $\Ss$. 


A SNT $\Ss=(Q,X,Y,\delta,q_0,O)$ is said to be \emph{normalized} if the following two constraints are satisfied.
\begin{itemize}
\item For each transition $(q,g,\eta,q') \in \delta$, if $\eta(x)=cur$ for some $x \in X$, then the guard $g$ implies $\bigwedge \limits_{x \in X \setminus \{cur\}} cur \neq x$.  Intuitively, when the current data value is stored into some register, it is required that the data value is distinct from all the data values that have already been stored in the register.
%
\item For each transition $(q, g, \eta, q')$ in $\Ss$, $g$ includes one of the following formulae as a conjunct: $cur < c_{min}$, or $cur = c$ for $c_{min} \le c \le c_{max}$, or $cur > c_{max}$.
\end{itemize}


\begin{proposition}
From each SNT, an equivalent normalized SNT can be constructed (with a possibly exponential blow-up). 
\end{proposition}

From now on, we assume that all SNTs are normalized.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Analysis of a single cycle}

Let $\Ss = (Q,X,Y,\delta,q_0,O)$ be a (normalized) SNT such that $X=\{cur, x_1,\dots, x_k\}$ and $Y = \{y_1,\dots,y_l\}$. Moreover, in this and next subsection, we assume that the guards in $\Ss$ contain no comparisons with constants. Later on, we will consider the more general situation.

Suppose that $C=q_0 \xrightarrow{(g_1,\eta_1)} q_1 \dots q_{n-1} \xrightarrow{(g_n, \eta_n)} q_n$ is a path in $\Ss$ such that $q_n = q_0$.  

Suppose the initial values of the $k$ control variables are $d_1,\dots, d_k$ and the $n$ data values introduced when traversing the cycle once are $d_{k+1},\dots,d_{k+n}$ (These data values may repeat). Then the guards and the assignments in the cycle induce an equivalence relation $\sim$ on $\{1,\dots, k+n\}$ so that  $i \sim j$ iff it can be inferred from the guards and assignments that $d_i = d_j$. Since $\Ss$ is normalized, we know that for each pair of indices $i,j: 1 \le i < j \le k+n$ such that $i \sim j$, it holds that $j \ge k+1$. Let $I_1,\dots, I_{k+r}$ be an enumeration of the equivalence classes of $\sim$ on $\{1,\dots, k+n\}$ such that $\min(I_1) < \dots < \min(I_{k+r})$. Then for each $j: 1 \le j \le k$, $\min(I_j)=j$.

In the following, for $\ell =1,2,\dots$, we will define the assignment function $\chi_\ell$ with the domain $X \cup Y$ to describe the values of the control and data variables after traversing the cycle for $i$ times. 

Suppose the initial values of the $k$ control variables are $d^0_1,\dots,d^0_k$. Moreover, suppose that the $r$ data values $d^1_{1},\dots,d^1_{r}$ are introduced when traversing the cycle for the first time, with one data value for each of $I_{1},\dots,I_{r}$. 
In addition, suppose that the initial values of $y_1,\dots, y_l$ are $o_1,\dots,o_l$. 

The assignment function $\chi_1$ is of the following form,
\begin{itemize}
\item there is an injective mapping $\pi: \{1,\dots,k\} \rightarrow \{1,\dots, k+r\}$ such that for each $x_j \in X$, if $\pi(j) \le k$, then $\pi(j)=j$ and $\chi_1(x_j)=d^0_{j}$, otherwise, $\chi_1(x_j)=d^1_{\pi(j)-k}$,
% 
\item for each $y_j \in Y$, $\chi_1(y_j) = \alpha_{j,0} + \alpha_{j,1} o_j + \beta_{j,1} d^0_1 + \dots + \beta_{j,k} d^0_k + \gamma_{j,1} d^1_1 +\dots + \gamma_{j,r} d^1_{r}$ for some constants $\alpha_{j,0},\alpha_{j,1}, \beta_{j,1},\dots,\beta_{j,k}, \gamma_{j,1},\dots,\gamma_{j,r}$ such that $\alpha_{j,1} \in \{0,+1,-1\}$ (as a result of the ``copyless'' and ``independently evolving'' constraint).
\end{itemize}

Let $J_1$ be set of indices $j$ such that $\pi(j)= j$ and $J_2 = \{1,\dots,k\} \setminus J_1$. Intuitively, the values of the variables from $J_1$ are  unchanged after traversing the cycle once, and the values of the variables from  $J_2$ are changed. Then $(J_1,J_2)$ forms a partition of $\{1,\dots,k\}$. Moreover, let $J_3=\{\pi(j)-k \mid j \in J_2\}$ and $J_4 = \{1,\dots,r\} \setminus J_3$. Then $(J_3,J_4)$ forms a partition of $\{1,\dots,r\}$.

Let $d^2_{1},\dots,d^2_{r}$ be the data values introduced when traversing the cycle for the second time. Then $\chi_2$ is defined as follows,
\begin{itemize}
\item for each $j \in J_1$, $\chi_2(x_j)=\chi_1(x_j)=d^0_j$, and for each $j \in J_2$, $\chi_2(x_j) =d^2_{\pi(j)-k}$, 
%
\item for each $y_j \in Y$, $\chi_2(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_1(y_j) + \beta_{j,1} \chi_1(x_1) + \dots + \beta_{j,k} \chi_1(x_k) + \gamma_{j,1} d^2_1 +\dots + \gamma_{j,r} d^2_{r}$.
\end{itemize}

By expanding the expressions $\chi_1(y_j), \chi_1(x_1),\dots,\chi_1(x_k)$, we get the following expression,
\[
\begin{array}{l c l}
\chi_2(y_j)  & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + \alpha^2_{j,1} o_j + (\alpha_{j,1} \beta_{j,1}) d^0_{1} +\dots + (\alpha_{j,1}\beta_{j,k}) d^0_{k} + \\
& & (\alpha_{j,1} \gamma_{j,1}) d^1_1 + \dots (\alpha_{j,1} \gamma_{j,r}) d^1_r + \sum \limits_{j' \in J_1} \beta_{j,j'} d^0_{j'} + \sum \limits_{j' \in J_2} \beta_{j,j'} d^1_{\pi(j')-k} + \\
& &  \gamma_{j,1} d^2_1 + \dots + \gamma_{j,r} d^2_{r}\\
& = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + \alpha^2_{j,1} o_j + \sum \limits_{j' \in J_1} (\beta_{j,j'} + \alpha_{j,1}  \beta_{j,j'}) d^0_{j'} + \sum \limits_{j' \in J_2} (\alpha_{j,1}\beta_{j,j'}) d^0_{j'} +\\
& &  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\alpha_{j,1}\gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (\alpha_{j,1} \gamma_{j,j'}) d^1_{j'} +\\
& & \gamma_{j, 1} d^2_{1} + \dots + \gamma_{j,r} d^2_{r}.
\end{array} 
\]

Let $d^3_{1},\dots,d^3_{r}$ be the data values introduced when traversing the cycle for the third time. Then $\chi_3$ is defined as follows, 
\begin{itemize}
\item for each $j \in J_1$, $\chi_3(x_j)=\chi_2(x_j)=d^0_j$, and for each $j \in J_2$, $\chi_3(x_j) =d^3_{\pi(j)-k}$, 
%
\item for each $y_j \in Y$, $\chi_3(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_2(y_j) + \beta_{j,1} \chi_2(x_1) + \dots + \beta_{j,k} \chi_2(x_k) + \gamma_{j,1} d^3_{1} + \dots + \gamma_{j,r} d^3_{r}$.
\end{itemize}

By expanding the expressions $\chi_2(y_j), \chi_2(x_1),\dots,\chi_2(x_k)$, we get the following expression,
\[
\begin{array}{l c l}
\chi_3(y_j)  & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+\alpha^2_{j,1} \alpha_{j,0}) + \alpha^3_{j,1} o_j + \sum \limits_{j' \in J_1} (\beta_{j,j'}+\alpha_{j,1}\beta_{j,j'} + \alpha^2_{j,1}  \beta_{j,j'}) d^0_{j'} + \\
& & \sum \limits_{j' \in J_2} (\alpha^2_{j,1}\beta_{j,j'}) d^0_{j'} +  \sum \limits_{j' \in J_3} (\alpha_{j,1}\beta_{j, \pi^{-1}(j'+k)}+\alpha^2_{j,1}\gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (\alpha^2_{j,1} \gamma_{j,j'}) d^1_{j'} +\\
& & \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\alpha_{j,1}\gamma_{j,j'}) d^2_{j'} + \sum \limits_{j' \in J_4} (\alpha_{j,1} \gamma_{j,j'}) d^2_{j'} +\\
& & \gamma_{j, 1} d^3_{1} + \dots + \gamma_{j,r} d^3_{r}.
\end{array} 
\]

In general, for $\ell \ge 2$, we have the following expression,
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \dots +\alpha^{\ell-1}_{j,1} \alpha_{j,0}) + \alpha^\ell_{j,1} o_j + \\
& & \sum \limits_{j' \in J_1} (\beta_{j,j'}+\alpha_{j,1}\beta_{j,j'} + \dots +\alpha^{\ell-1}_{j,1}  \beta_{j,j'}) d^0_{j'} + \\
%
& & \sum \limits_{j' \in J_2} (\alpha^{\ell-1}_{j,1}\beta_{j,j'}) d^0_{j'} +  \sum \limits_{j' \in J_3} (\alpha^{\ell-2}_{j,1}\beta_{j, \pi^{-1}(j'+k)}+\alpha^{\ell-1}_{j,1}\gamma_{j,j'}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_4} (\alpha^{\ell-1}_{j,1} \gamma_{j,j'}) d^1_{j'} + \dots + \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\alpha_{j,1}\gamma_{j,j'}) d^{\ell-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_4} (\alpha_{j,1} \gamma_{j,j'}) d^{\ell-1}_{j'} + \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]

Since $\alpha_{j,1} \in \{0,+1,-1\}$, for $\ell \ge 4$, we observe the following fact.
\begin{itemize}
\item If $\alpha_{j,1}=0$, then
\[\chi_\ell(y_j)=\alpha_{j,0}+ \sum \limits_{j' \in J_1} \beta_{j,j'} d^0_{j'}+ \sum \limits_{j' \in J_3} \beta_{j, \pi^{-1}(j'+k)} d^{\ell-1}_{j'} +\gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.\]
%
\item If $\alpha_{j,1}=+1$, then 
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & (\alpha_{j,0}\ell) + o_j +  \sum \limits_{j' \in J_1} (\beta_{j,j'} \ell) d^0_{j'} + \sum \limits_{j' \in J_2} \beta_{j,j'} d^0_{j'} + \\
& &   \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\gamma_{j,j'}) d^1_{j'} +  \sum \limits_{j' \in J_4} \gamma_{j,j'} d^1_{j'} + \dots  \\
& &  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+ \gamma_{j,j'}) d^{\ell-1}_{j'} +  \sum \limits_{j' \in J_4} \gamma_{j,j'} d^{\ell-1}_{j'} + \\
& & \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]
%
\item If $\alpha_{j,1}=-1$ and $\ell$ is even, then
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & o_j +  \sum \limits_{j' \in J_2} (-\beta_{j,j'}) d^0_{j'} +  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)} - \gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (-\gamma_{j,j'}) d^1_{j'} + \\
& &  \sum \limits_{j' \in J_3} (-\beta_{j, \pi^{-1}(j'+k)}+ \gamma_{j,j'}) d^2_{j'} +   \sum \limits_{j' \in J_4} \gamma_{j,j'} d^2_{j'} + \dots + \\
& & \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)} - \gamma_{j,j'}) d^{\ell-1}_{j'} +  \sum \limits_{j' \in J_4} (- \gamma_{j,j'}) d^{\ell-1}_{j'} + \\
& & \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]
\item If $\alpha_{j,1}=-1$ and $\ell$ is odd, then
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & \alpha_{j,0}  - o_j +  \sum \limits_{j' \in J_1} \beta_{j,j'} d^0_{j'} +  \sum \limits_{j' \in J_2} \beta_{j,j'} d^0_{j'} +  \\
& & \sum \limits_{j' \in J_3} (-\beta_{j, \pi^{-1}(j'+k)}+\gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (\gamma_{j,j'}) d^1_{j'} + \\
& &  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)} - \gamma_{j,j'}) d^2_{j'} +  \sum \limits_{j' \in J_4} (-\gamma_{j,j'}) d^2_{j'} + \dots + \\
& & \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}-\gamma_{j,j'}) d^{\ell-1}_{j'} +  \sum \limits_{j' \in J_4} (-\gamma_{j,j'}) d^{\ell-1}_{j'} + \\
& & \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]
\end{itemize}

From the analysis above, we know that in $\chi_\ell(y_j)$, 
\begin{itemize}
\item the coefficient of $o_j$ is from $\{0,+1,-1\}$, 
%
\item the constant coefficient is either $\alpha_{j,0}$, or $\alpha_{j,0} \ell$, or $0$, 
%
\item for each data value $d^0_{j'}$, the coefficient of $d^0_{j'}$ is either $\pm \beta_{j,j'}$, or $0$, or $\beta_{j,j'} \ell$,
%
\item for each data value $d^i_{j'}$ with $i > 0$, the coefficient of $d^i_{j'}$ is either $0$, or $\beta_{j, \pi^{-1}(j'+k)}$, or $\beta_{j, \pi^{-1}(j'+k)}+\gamma_{j,j'}$, or $\pm \gamma_{j,j'}$, or $\pm(\beta_{j, \pi^{-1}(j'+k)}-\gamma_{j,j'})$.
\end{itemize}

To summarize, we get the following intuition.
\begin{itemize}
\item For the control variables with indices from $J_1$, they can be dealt with the same as the constant coefficients, that is, dealt with as integer counters.

\item For the other control variables as well as those newly introduced data values, their coefficients are from a bounded domain and can be dealt with easily.
\end{itemize}

\subsection{Algorithm for a generalized lasso}

In this subsection, we present a decision algorithm for a generalized lasso, that is, the transition graph comprises a handle $q_0 q_1 \dots q_m$ and a collection of simple cycles $C_1,\dots,C_n$ which share the unique state $q_m$. Moreover, we assume that $O(q_m) = a_0 + a_1 x_1 + \dots + a_k x_k + a'_1 y_1 + \dots + a'_l y_l$ and $O(q)$ is undefined for all the other states $q$.

In the following, we will illustrate the argument for the case $n=2$, that is, there are only two cycles.

Let $d_1,\dots, d_m$ denote the $m$ data values met when traversing the handle. The guards and assignments of the transitions in the handle induce an equivalence relation on $\{1,\dots,m\}$ such that $i \sim j$ if the guards and assignments imply that $d_i = d_j$. For each $i: 1\le i \le m$, let $[i]$ denote the equivalence class containing $i$. Suppose the equivalence relation $\sim$ has $s$ equivalence classes, say $[i_1],\dots,[i_s]$ such that $i_1 < \dots < i_s$. Let $d^0_1,\dots,d^0_{s}$ denote the $s$ distinct data values introduced when traversing the cycle, corresponding to $[i_1],\dots,[i_s]$ respectively. 

We show by induction that for each $i: 1 \le i \le m$ and each variable $x_j$ (resp. $y_j$), an arithmetic expression $e_{i,x_j}$ (resp. $e_{i,y_j}$) corresponding to $x_j$(resp. $y_j$) after going through the state sequence $q_0 \dots q_i$ can be constructed. Let $(q_{i}, g_{i}, \eta_{i}, q_{i+1})$ be the $i$-th transition for each $i: 0 \le i < m$.

For each $j: 1 \le j \le k$, if $\eta_1(x_j)=cur$, then $e_{1,x_j}=d^0_1$, otherwise, $e_{1,x_j}=\bot$.

For each $j: 1 \le j \le l$, $e_{1,y_j} = (\eta_{1}(y_j))[d^0_1/cur]$. 

For each $i: 1 < i \le m$, 
\begin{itemize}
\item for each $j: 1 \le j \le k$, $e_{i,x_j}=d^0_{s'}$ if $\eta_i(x_j)=cur$ and $[i] = [i_{s'}]$, and $e_{i,x_j}=e_{i-1,x_j}$ otherwise,
%
\item for each $j: 1 \le j \le l$, $e_{i,y_j} = \theta_i(\eta_i(y_j))$, where $\theta_i(x_{j'})=e_{i-1,x_{j'}}$, $\theta_i(y_{j'})=e_{i-1, y_{j'}}$, and $\theta_i(cur)=d^0_{s'}$, where $[i]=[i_{s'}]$.
\end{itemize}

Then for each $j: 1 \le j \le k$, $e_{m,x_j}=d^0_{\pi_0(j)}$ for some injective mapping $\pi_0: \{1,\dots,k\} \rightarrow \{1,\dots,s\}$, and for each $j: 1 \le j \le l$, $e_{m,y_j} = c_{0,j} + c_{1,j} d^0_1 + \dots + c_{s,j} d^0_s$ for some integer constants $c_{0,j},\dots, c_{s,j}$. We use $\chi_0$ to denote the assignment function such that $\chi_0(x_j)=e_{m,x_j}$ and $\chi_0(y_j)=e_{m,y_j}$. Note here we ignore the situations that $e_{m,x_j} = \bot$ for simplicity.

\smallskip

\noindent {\bf Step I}. Decide whether $\chi_0(O(q_m))$ is not identical to zero (it is easy to do so, just check the coefficients of $d^0_1, \dots, d^0_s$). If the answer is yes, then the decision procedure terminates and returns the answer $true$. Otherwise, the decision procedure continues.

\smallskip

For the cycle $C_b$ (where $b=1,2$), the assignment function $\chi_{b,\ell}$ can be defined to describe the values of the control and output variables after traversing the cycle $C_b$ for $\ell$ times.

Suppose that for $b=1,2$, the initial values of the $k$ control variables are $d^0_{\pi_0(1)},\dots,d^0_{\pi_0(k)}$. Moreover, suppose that the $r_b$ data values $d^1_{1}, \dots, d^1_{r_b}$ are introduced when traversing the cycle for the first time, with one data value for each of $I_{1},\dots,I_{r_b}$. 
In addition, suppose that the initial values of $y_1,\dots, y_l$ are $o_1,\dots,o_l$. 

Then for $b=1,2$, the assignment function $\chi_{b,1}$ is of the following form,
\begin{itemize}
\item there is an injective mapping $\pi_b: \{1,\dots,k\} \rightarrow \{1,\dots, k+r_b\}$ such that for each $x_j \in X$, if $\pi_b(j) \le k$, then $\pi_b(j)=j$ and $\chi_{b,1}(x_j)=d^0_{\pi_0(j)}$, otherwise, $\chi_{b,1}(x_j)=d^1_{\pi_b(j)-k}$,
% 
\item for each $y_j \in Y$, $\chi_{b,1}(y_j) = \alpha_{b,(j,0)} + \alpha_{b,(j,1)} o_j + \beta_{b,(j,1)} d^0_{\pi_0(1)} + \dots + \beta_{b,(j,k)} d^0_{\pi_0(k)} + \gamma_{b,(j,1)} d^1_1 +\dots + \gamma_{b,(j,r_b)} d^1_{r_b}$ such that $\alpha_{b,(j,1)} \in \{0,+1,-1\}$.
\end{itemize}

Let $J_{b,1}$ be set of indices $j \in \{1,\dots,k+r_b\}$ such that $\pi_b(j)= j$ and $J_{b,2} = \{1,\dots,k\} \setminus J_{b,1}$. Intuitively, the values of the variables from $J_1$ are  unchanged after traversing the cycle once, and the values of the variables from  $J_{b,2}$ are changed. Then $(J_{b,1}, J_{b,2})$ forms a partition of $\{1,\dots,k\}$. Moreover, let $J_{b,3}=\{\pi_b(j)-k \mid j \in J_{b,2}\}$ and $J_{b,4} = \{1,\dots,r_b\} \setminus J_{b,3}$. Then $(J_{b,3}, J_{b,4})$ forms a partition of $\{1,\dots,r_b\}$.

We will present the argument for the situation that $J_{1,1} \cap J_{2,1} \neq \emptyset$, $J_{1,1} \setminus J_{2,1} \neq \emptyset$, and $J_{2,1} \setminus J_{1,1} \neq \emptyset$.

A \emph{cycle scheme} $\schm$ is a sequence $\schm=(1,\ell_1) (2, \ell_2 ) \dots (((m-1) \bmod 2)+1, \ell_m)$ such that $\ell_1,\dots, \ell_m \ge 1$. The number $m$ is called the length of the cycle scheme $\schm$. In principle, for each cycle scheme $\schm$, the expressions $\chi_{\schm}(y_j)$ can be defined to describe the values of $y_j$ after traversing the cycles according to $\schm$.

%\begin{proposition}\label{prop-mult-cycle}
%From a cycle scheme $\schm=(1,\ell_1) (2, \ell_2 ) \dots (((m-1) \bmod 2)+1, \ell_m)$, for each $j: 1 \le j \le l$, an expression $\chi_{\schm}(y_j)$ can be constructed from $\chi_{(1,\ell_1)}(y_j),\dots,\chi_{(((m-1) \bmod 2)+1, \ell_m)}(y_j)$ by collecting all the data variables therein and some linear combinations of their coefficients.
%\end{proposition}

In the following, we first show how to construct the expressions $\chi_{(1,\ell_1)(2,\ell_2)}$ for a cycle scheme $(1,\ell_1)(2,\ell_2)$ such that $\ell_1,\ell_2 \ge 2$, to describe the values of the control and data variables after traversing $C_1$ for $\ell_1$ times and $C_2$ for $\ell_2$ times.

At first, from the analysis of cycles, we know that
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)}(y_j)  & = & (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) + \alpha^{\ell_1}_{1,(j,1)} o_j + \\
& & \sum \limits_{j' \in J_{1,1}} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{1,2}} (\alpha^{\ell_1-1}_{1,(j,1)}\beta_{1,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')}) d^1_{j'} + \dots + \sum \limits_{j' \in J_{1,3}} (\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha_{1,(j,1)} \gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \gamma_{1,(j, 1)} d^{\ell_1}_{1} + \dots + \gamma_{1,(j,r_1)} d^{\ell_1}_{r_1},
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi_{(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)}) + \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{2,1}} (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{2,2}} (\alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+\\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{j'} +  \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{r_2}.
\end{array} 
\]

The coefficients of $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ can be obtained those of $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ as follows: For each $i: 1 \le i \le \ell_1$ and $j': 1 \le j' \le r_1$, let $d^i_{j'}$ denote the data values introduced when traversing $C_1$, and for each  $i: 1 \le i \le \ell_2$ and $j': 1 \le j' \le r_2$, let $d^{i}_{(1, \ell_1),j'}$ denote the data values introduced when traversing $C_2$ for $\ell_2$ times (after traversing $C_1$ for $\ell_1$ times).
\begin{itemize}
\item The coefficient of $o_j$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\theta_1\theta_2$, where $\theta_1$ and $\theta_2$ are the coefficient of $o_j$ in $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.
%
\item The constant coefficient of $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1,\theta_2$ are the constant coefficient of $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.
%
\item For each $j': 1 \le j' \le k$, suppose $\chi_{(1,\ell_1)}(x_{j'})=d^{i}_{j'}$, then the coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1,\theta_2$ are the  coefficient of $d^i_{j'}$ in $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.  
%
%\item For $j' \in J_{1,2}$, the coefficient of $d^{\ell_1}_{\pi_1(j')-k}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1$ is the  coefficient of $d^{\ell_1}_{\pi_1(j')-k}$ in $\chi_{(1,\ell_1)}(y_j)$ and $\theta_2$ is the coefficient of $d^0_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$.
%
\item For each pair $(i,j')$ such that $d^i_{j'} \not \in \{\chi_{(1,\ell_1)}(x_{j''}) \mid 1 \le j'' \le k\}$, the coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta$, where $\theta$ is the  coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)}(y_j)$.
%
\item For each pair $(i,j')$ such that $1 \le i \le \ell_2$ and $j' \in J_{2,3} \cup J_{2,4}$, the coefficient of $d^{i}_{(1, \ell_1),j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\theta$, where $\theta$ is the  coefficient of $d^{i}_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$, where $d^{i}_{(1, \ell_1),j'}$ is the data variable corresponding to $d^{i}_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$, decorated with $(1,\ell_1)$.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
More specifically, 
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)} + \\
%
& & \alpha^{\ell_2}_{2,(j,1)} (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) ) + \alpha^{\ell_1}_{1,(j,1)} \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{1,1} \cap J_{2,1}} (\alpha^{\ell_2}_{2,(j,1)} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) + \\
%
& & (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')})) d^0_{j'}  + \\
%
& & \sum \limits_{j' \in J_{1,2} \cap J_{2,1}} (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j,\pi_1(j')-k)} + \beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots + \\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^{\ell_1}_{\pi_1(j')-k} + \\
%
& & \sum \limits_{j' \in J_{1,1} \cap J_{2,2}}  (\alpha^{\ell_2}_{2,(j,1)} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')})+ \\
& & \alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{j'} +\\
%
& & \sum \limits_{j' \in J_{1,2} \cap J_{2,2}}  (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j,\pi_1(j')-k)}+ \alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^{\ell_1}_{\pi_1(j')-k}  +\\
%
& & \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')})) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')})) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_2}_{2,(j,1)}(\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')})) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha_{1,(j,1)} \gamma_{1,(j,j')})) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j'+k \not \in \pi_1(J_{1,2})} (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j, j')}) d^{\ell_1}_{j'}+ \\
%
& & \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{(1,\ell_1),j'} +  \\
%
& & \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{(1,\ell_1),j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{(1,\ell_1), j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{(1,\ell_1), j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{(1,\ell_1), 1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{(1,\ell_1), r_2}.
\end{array} 
\]
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\smallskip

\noindent {\bf Step II}. For $b=1,2$, let 
\[
\begin{array}{l c l}
\chi_{(b,\ell_b)}(O(q_m)) & = & a_0 + a_1 \chi_{(b,\ell_b)}(x_1) + \dots a_k \chi_{(b,\ell_b)}(x_k) + \\
& & a'_1 \chi_{(b,\ell_b)}(y_1) + \dots + a'_l \chi_{(b,\ell_b)}(y_l).
\end{array}
\] 

Then $\chi_{(b,\ell_b)}(O(q_m))$ is a linear combination of the variables $d^0_1,\dots, d^0_s$ and $d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$.

For each $j' \in J_{b,1}$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{(b,\ell_b)}(O(q_m))$ is 

\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\beta_{b,(j,j')}.\]

In general, for each $j' \in J_{1,1}$ and each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$), the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \ \ \  (\ast)\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast)$ is of the form 
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j  s_j (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')},\]
where $s_j \in \{0,+1,-1\}$.

The expression $(\ast)$ can be rewritten as $\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')}$ for some integer constant $\mu_{\schm,(1,j')},\nu_{\schm,(1,j')}$ (possibly $\mu_{\schm,(1,j')}=0$). 

If there are a cycle scheme $\schm$ starting from $C_1$  and $j' \in J_{1,1}$ such that $\mu_{\schm,(1,j')} \neq 0$, then return $true$. Note that in this case, we can let $\ell_1$ and $d^0_{\pi_0(j')}$ sufficiently large so that $(\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')})d^0_{\pi_0(j')}$ dominates $\chi_{\schm}(O(q_m))$ and $\chi_{\schm}(O(q_m))$ becomes non-zero. We would like to remark that although there are infinitely many cycle schemes $\schm$, the constants $\mu_{\schm,(1,j')}$ can only have values from a bounded domain. Therefore, it is decidable whether there exist such a desired cycle scheme $\schm$ starting from $C_1$ and $j' \in J_{1,1}$.

The similar discussion can be applied to $C_2$ and $J_{2,1}$.

If there are no desired cycle schemes $\schm$ and $j'$ for $C_1$ and $J_{1,1}$, as well as for  $C_2$ and $J_{2,1}$, then the decision procedure continues.

The constant coefficient in $\chi_{(b,\ell_b)}(O(q_m))$ is 

\[a_0 + \sum \limits_{1 \le j \le l} a'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)}.\]

In general, for each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$), the constant coefficient in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a_0 + \sum \limits_{1 \le j \le l} a'_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)}. \ \ \  (\ast\ast)\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast\ast)$ is of the form 
\[a_0 + \sum \limits_{1 \le j \le l} a'_j  s'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)},\]
where $s'_j \in \{0,+1,-1\}$.

The expression $(\ast\ast)$ can be rewritten as $\mu_{\schm,(1,0)} \ell_1 + \nu_{\schm,(1,0)}$ for some integer constant $\mu_{\schm,(1,0)},\nu_{\schm, (1,0)}$ (possibly $\mu_{\schm,(1,0)}=0$). 

If there are a cycle scheme $\schm$ starting from $C_1$ such that $\mu_{\schm,(1,0)} \neq 0$, then return $true$. Note that in this case, we can let $\ell_1$ sufficiently large so that $\mu_{\schm,(1,0)} \ell_1 + \nu_{\schm,(1,0)}$ dominates $\chi_{\schm}(O(q_m))$ and $\chi_{\schm}(O(q_m))$ becomes non-zero. We would like to remark that although there are infinitely many cycle schemes $\schm$, the constants $\mu_{\schm,(1,0)}$ can only have values from a bounded domain. Therefore, it is decidable whether there exist such a desired cycle scheme $\schm$ starting from $C_1$.

A similar discussion for the constant coefficient can be applied to the cycle schemes starting from $C_2$.

If the decision procedure has not returned yet, then we go to Step III. 

\smallskip

\noindent {\bf Step III}. For each cycle scheme $\schm=(1,\ell_1) (2,\ell_2) \dots (1+ (t-1) \bmod 2,\ell_t)$ or $\schm=(2,\ell_1) (1,\ell_2) \dots (1+ (t-1) \bmod 2,\ell_t)$, we can ignore all the expressions of the form $c\ \ell_1,\dots, c\ \ell_m$ (where $c$ is an integer constant) in $\chi_{\schm}(y_j)$, since these expressions will disappear for sure in $\chi_{\schm}(O(q_m))$, according to the analysis above. From this observation, we can show that the constant coefficient as well as the coefficients for $d^0_{\pi_0(j')}$ with $j' \in J_{1,1} \cap J_{2,1}$ in $\chi_{\schm}(y_1),\dots,\chi_{\schm}(y_l), \chi_{\schm}(O(q_m))$ can be calculated by a $\intnum$-VAS (cf. \cite{HH14}), that is, an integer vector addition system. Moreover, all the other coefficients in $\chi_{\schm}(y_1),\dots,\chi_{\schm}(y_l), \chi_{\schm}(O(q_m))$ are from a bounded domain, no matter how long the scheme $\schm$ is.  

Therefore, in this case, the non-zero output reachability problem is reduced to the non-zero reachability problem of $\intnum$-VAS, that is, given an index $i$, decide whether a vector $\vec{z}$ where $z_i$ is non-zero can be reached.  It is not hard to see that the non-zero reachability problem of $\intnum$-VAS can be reduced to the coverability problem of $\intnum$-VAS. From the fact that the coverability of $\intnum$-VAS is NP-complete (\cite{HH14}),  we conclude that the non-zero output reachability of SNS$\pm$ whose transition graph is a generalized lasso is decidable.


\subsection{Comparison with constants}

We now consider the situation that the guards include the comparisons with constants, that is, the atomic formulae of the form $cur\ o\ c$, where $c$ is an integer constant. 

For this situation, we adapt the algorithm for a generalized lasso into Step I', II' and III' below.

\smallskip

\noindent {\bf Step I'}. Decide whether $\chi_0(O(q_m))$ is not identical to zero. If the answer is yes, then the decision procedure terminates and returns the answer $true$. Otherwise, the decision procedure continues.

When decide whether $\chi_0(O(q_m))$ is not identical to zero, it is unsound to just consider the coefficients of $d^0_1,\dots,d^0_s$, since some of the data values may be integer constants as well. 

From the analysis, we know that 
\[
\begin{array}{l c l }
\chi_0(O(q_m)) & = & a_0 + a_1 \chi_0(x_1) + \dots + a_k \chi_0(x_k) + a'_1 \chi_0(y_1) + \dots a'_l \chi_0(y_l).\\
& = & (a_0+a'_1 c_{0,1} + \dots + a'_l c_{0,l}) + \sum \limits_{j \not \in rng(\pi_0)}  (a'_1 c_{j,1}+\dots + a'_l c_{j,l}) d^0_j+\\
& & \sum \limits_{j \in rng(\pi_0)} (a_{\pi_0^{-1}(j)}+ a'_1 c_{j,1}+\dots + a'_l c_{j,l}) d^0_j.
\end{array}
\]

From the guards and assignments of the transitions in the handle, we know that some of $d^0_1,\dots,d^0_s$ are just integer constants. Let $J_0 \subseteq \{1,\dots,s\}$ denote the subset of indices for these data values. For $d^0_j$ such that $j \not \in J_0$, we know that either $d^0_j < c_{\min}$ or $d^0_j > c_{\max}$, since the SNT is assumed to be normalized.

Then to decide whether $\chi_0(O(q_m))$ is identical to zero, we will first check whether the coefficient of $d^0_j$ in $\chi_0(O(q_m))$ for some $j \not \in J_0$ is non-zero. If this is the case, the return ``$true$''. Otherwise, $\chi_0(O(q_m))$ is in fact an integer constant, and we just check whether it is equal to zero. If it is not equal to zero, then return ``true''. Otherwise, we continue the procedure.

For $b=1,2$, we know that $\chi_{b,1}(y_j) = \alpha_{b,(j,0)} + \alpha_{b,(j,1)} o_j + \beta_{b,(j,1)} d^0_{\pi_0(1)} + \dots + \beta_{b,(j,k)} d^0_{\pi_0(k)} + \gamma_{b,(j,1)} d^1_1 +\dots + \gamma_{b,(j,r_b)} d^1_{r_b}$.

Moreover, from the guards and assignments in the transitions of the handle and $C_b$, we know that some of $d^0_{\pi_0(1)}, d^0_{\pi_0(k)}, d^1_1,\dots, d^1_{r_b}$ are integer constants. From this, we know that for the data values $d^0_1,\dots, d^0_s, d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$ introduced when traversing $C_b$ for $\ell_b$ times, which ones are integer constants.

\smallskip

\noindent {\bf Step II'}. For $\chi_{(b,\ell_b)}(O(q_m))$, we then do the analysis for the coefficient of $d^0_{\pi_0(j')}$ that is not a constant, similar to that in Step II.  Moreover, we consider the sum of the constant coefficient and all the components $c\ d^{i}_{j'}$ in  $\chi_{(b,\ell_b)}(O(q_m))$ such that $d^i_{j'}$ is a constant, and do the analysis for it, similar to that for the constant coefficient in Step II.

\smallskip

\noindent {\bf Step III'}. We will do the same analysis as in Step III.


\subsection{Generalized flat}

We will illustrate the argument by the following scenario:  
\begin{quote}
$q_0\dots q_{m} (C_1,\dots,C_n) q'_0 \dots q'_{m'} (C'_1,\dots,C'_{n'})$ is a path scheme of the transducer, where each pair of $C_1,\dots,C_n$ share the unique common state $q_m$, $q'_0 = q_m$, and each pair of $C'_1,\dots,C'_{n'}$ share the common state $q'_{m'}$. Moreover, $O(q'_{m'})$ is defined and $O(q)$ is undefined for all the other states $q$.
\end{quote}

For simplicity, we assume that $n = n' = 2$.

We will illustrate the argument for the situation that there are no comparisons with constants in the guards.

For the handle $q_0 \dots q_m$, we can obtain a mapping $\chi_0$ to describe the value of the control and data variables after traversing the handle. Suppose for each $j: 1 \le j \le l$,  $\chi_0(y_j) = c_{0,j} + c_{1,j} d^0_1 + \dots + c_{s,j} d^0_s$. Moreover, we assume that there is an injective mapping $\pi_0$ such that for each $j: 1 \le j \le k$, $\chi_0(x_j) = d^0_{\pi_0(j)}$.

Suppose that the mapping $\chi_{1,\ell_1}$ and $\chi_{2,\ell_2}$ to describe the values of the control and data variables after traversing the cycle $C_1$ and $C_2$ for $\ell_1$ and $\ell_2$ times are as in the analysis of generalized lasso above.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
 that is,
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)}(y_j)  & = & (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) + \alpha^{\ell_1}_{1,(j,1)} o_j + \\
& & \sum \limits_{j' \in J_{1,1}} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{1,2}} (\alpha^{\ell_1-1}_{1,(j,1)}\beta_{1,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')}) d^1_{j'} + \dots + \sum \limits_{j' \in J_{1,3}} (\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha_{1,(j,1)} \gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \gamma_{1,(j, 1)} d^{\ell_1}_{1} + \dots + \gamma_{1,(j,r_1)} d^{\ell_1}_{r_1},
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi_{(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)}) + \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{2,1}} (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{2,2}} (\alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+\\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{j'} +  \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{r_2}.
\end{array} 
\]
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Moreover, suppose the initial values of the control variables are $d'_1,\dots,d'_k$ and the initial values of the data variables are $o'_1,\dots,o'_l$, then for the handle $q'_0 \dots q'_{m'}$, let $\chi'_0$ be the mapping to describe the values of the control and data variables after traversing the handle, 
\[
\chi'_0(y_j) = c'_{0,j} + c'_{1,j} (d^0_1)' + \dots + c'_{s',j} (d^0_{s'})'+c''_{0,j} o'_j + c''_{1,j} d'_1 + \dots c''_{k,j} d'_k,
\] 
where $(d^0_1)' ,\dots, (d^0_{s'})'$ are the data values introduced when traversing the handle. Let $\pi'_0: \{1,\dots,k\} \rightarrow \{1,\dots,k+s'\}$ be an injective mapping such that $\chi'_0(x_j) = d'_{j}$ if $\pi'_0(j) \le j$ (in this case $\pi'_0(j)=j$), and $\chi'_0(x_j) = (d^0_{\pi'_0(j)-k})'$ otherwise.


Moreover, suppose $d''_1,\dots,d''_k$ are the initial values of the control variables and $o''_1,\dots,o''_l$ are the initial values of the data variables, then $\chi'_{1,\ell'_1}$ and $\chi'_{2,\ell'_2}$, which describe the values of the control and data variables after traversing the cycle $C'_1$ and $C'_2$ for $\ell_1$ and $\ell_2$ times respectively, are as follows, 
%
\[
\begin{array}{l c l}
\chi'_{(1,\ell'_1)}(y_j)  & = & (\alpha'_{1,(j,0)} + \alpha'_{1,(j,1)} \alpha'_{1,(j,0)}+ \dots +(\alpha'_{1,(j,1)})^{\ell'_1-1} \alpha'_{1,(j,0)}) + (\alpha'_{1,(j,1)})^{\ell'_1} o''_j + \\
& & \sum \limits_{j' \in J'_{1,1}} (\beta'_{1,(j,j')}+\alpha'_{1,(j,1)}\beta'_{1,(j,j')} + \dots +(\alpha'_{1,(j,1)})^{\ell'_1-1}  \beta'_{1,(j,j')}) d''_{j'} + \\
%
& & \sum \limits_{j' \in J'_{1,2}} ( (\alpha'_{1,(j,1)})^{\ell'_1-1} \beta'_{1,(j,j')}) d''_{j'} +  \sum \limits_{j' \in J'_{1,3}} ( (\alpha'_{1,(j,1)})^{\ell'_1-2} \beta'_{1,(j, \pi^{-1}(j'+k))}+\\
%
& &  (\alpha'_{1,(j,1)})^{\ell'_1-1} \gamma'_{1,(j,j')}) (d^1_{j'})' +  \sum \limits_{j' \in J'_{1,4}} ( (\alpha'_{1,(j,1)})^{\ell'_1-1} \gamma'_{1,(j,j')}) (d^1_{j'})' + \dots +  \\
%
& & \sum \limits_{j' \in J'_{1,3}} (\beta'_{1,(j, \pi^{-1}(j'+k))}+\alpha'_{1,(j,1)}\gamma'_{1,(j,j')}) (d^{\ell'_1-1}_{j'})' +\\
& & \sum \limits_{j' \in J'_{1,4}} (\alpha'_{1,(j,1)} \gamma'_{1,(j,j')}) (d^{\ell'_1-1}_{j'})' + \gamma'_{1,(j, 1)} (d^{\ell'_1}_{1})' + \dots + \gamma'_{1,(j,r_1)} (d^{\ell'_1}_{r'_1})',
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi'_{(2,\ell'_2)}(y_j)  & = & (\alpha'_{2,(j,0)} + \alpha'_{2,(j,1)} \alpha'_{2,(j,0)}+ \dots +(\alpha'_{2,(j,1)})^{\ell'_2-1} \alpha'_{2,(j,0)}) + (\alpha'_{2,(j,1)})^{\ell'_2} o''_j + \\
& & \sum \limits_{j' \in J'_{2,1}} (\beta'_{2,(j,j')}+\alpha'_{2,(j,1)}\beta'_{2,(j,j')} + \dots +(\alpha'_{2,(j,1)})^{\ell'_2-1}  \beta'_{2,(j,j')}) d''_{j'} + \\
%
& & \sum \limits_{j' \in J'_{2,2}} ( (\alpha'_{2,(j,1)})^{\ell'_2-1} \beta'_{2,(j,j')}) d''_{j'} +  \sum \limits_{j' \in J'_{2,3}} ( (\alpha'_{2,(j,1)})^{\ell'_2-2} \beta'_{2,(j, \pi^{-1}(j'+k))}+\\
%
& &  (\alpha'_{2,(j,1)})^{\ell'_2-1} \gamma'_{2,(j,j')}) (d^2_{j'})' +  \sum \limits_{j' \in J'_{2,4}} ( (\alpha'_{2,(j,1)})^{\ell'_2-1} \gamma'_{2,(j,j')}) (d^2_{j'})' + \dots +  \\
%
& & \sum \limits_{j' \in J'_{2,3}} (\beta'_{2,(j, \pi^{-1}(j'+k))}+\alpha'_{2,(j,1)}\gamma'_{2,(j,j')}) (d^{\ell'_2-1}_{j'})' +\\
& & \sum \limits_{j' \in J'_{2,4}} (\alpha'_{2,(j,1)} \gamma'_{2,(j,j')}) (d^{\ell'_2-1}_{j'})' + \gamma'_{2,(j, 1)} (d^{\ell'_2}_{1})' + \dots + \gamma'_{2,(j,r_1)} (d^{\ell'_2}_{r'_2})'.
\end{array} 
\]

\noindent {\bf Step I''}. We can do the same analysis for the handle $q_0 \dots q_m$ as for generalized lasso.

\smallskip 
\noindent {\bf Step II''}. Let $\chi$ Consider
\[
\begin{array}{l c l}
\chi'_{0}(O(q'_{m'})) & = & a_0 + a_1 \chi'_0(x_1) + \dots a_k \chi'_0(x_k) + \\
& & a'_1 \chi'_0(y_1) + \dots + a'_l \chi'_0(y_l) \\
&  = &  (a_0+\sum \limits_{1 \le j \le l} a'_j c'_{0,j}) + \sum \limits_{\pi'_0(j)=j} (a_j + \sum \limits_{1 \le j' \le l} a'_{j'} c''_{j,j'}) d'_j  + \\
& & \sum \limits_{\pi'_0(j) \neq j} \sum \limits_{1 \le j' \le l} (a'_{j'} c''_{j,j'}) d'_j + \sum \limits_{1\le j \le l} (a'_{j} c''_{0,j}) o'_j + \\
& & \sum \limits_{1 \le j \le s', j \in rng(\pi'_0)} (\sum \limits_{1 \le j' \le l} (a_{(\pi'_0)^{-1}(j)} + a'_{j'} c'_{j,j'})) (d^0_j)' +\\ & & \dots  + \sum \limits_{1 \le j \le s', j \not \in rng(\pi'_0)} (\sum \limits_{1 \le j' \le l} (a'_{j'} c'_{j,j'})) (d^0_j)'.
\end{array}
\] 

Then we can think $q_m$ as a state with the output expression $O(q_m)=\chi'_{0}(O(q'_{m'}))$, where $d'_1,\dots,d'_k, o'_1,\dots, o'_l$ denote the values of the control and data variables. 

Let $a''_0$ be the constant coefficient of $\chi'_{0}(O(q'_{m'}))$, $a''_1,\dots,a''_k,a'''_1,\dots,a'''_l$ be the coefficient of $d'_1,\dots,d'_k,o'_1,\dots,o'_l$ of $\chi'_{0}(O(q'_{m'}))$ respectively.

Similarly to the analysis of generalized lassos, $\chi_{(b,\ell_b)}(O(q_m))$ is a linear combination of the variables $d^0_1,\dots, d^0_s$ and $d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$. For each $j' \in J_{b,1}$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{(b,\ell_b)}(O(q_m))$ is 
%
\[a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\beta_{b,(j,j')}.\]
%

In general, for each $j' \in J_{1,1}$ and each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$) of $(C_1,C_2)$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \ \ \  (\ast')\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast')$ is of the form 
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j  s_j (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')},\]
where $s_j \in \{0,+1,-1\}$.

The expression $(\ast')$ can be rewritten as $\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')}$ for some integer constant $\mu_{\schm,(1,j')},\nu_{\schm,(1,j')}$ (possibly $\mu_{\schm,(1,j')}=0$). 

If $\mu_{\schm,(1,j')} \neq 0$, then return ``$true$''. 

Otherwise, for each cycle scheme $\schm'=(1,\ell'_1)(2,\ell'_2) \dots (1+(t'-1) \bmod 2,\ell'_{t'})$ (where $t' \ge 1$) of $(C'_1,C'_2)$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm (q'_0 \dots q'_{m'})\schm'}(O(q'_{m'}))$ includes the following expression as a component,
\[
\begin{array}{l c l}
a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)} (\alpha'_{1,(j,1)})^{\ell'_{1}} (\alpha'_{2,(j,1)})^{\ell'_{2}} \dots (\alpha'_{1,(j,1)})^{\ell'_{t'}}) \\
\hspace{16mm} (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \hspace{2cm}. (\ast'')
\end{array}
\]

The a similar analysis can be applied to $(\ast'')$ by considering all the cycle shcemes of $(C'_1,C'_2)$.

Moreover, we can apply a similar analysis for the cycle $C'_1,C'_2$ as for $C_1,C_2$, by using the output expressions $O(q'_{m'})$.

If the procedure does not return yet, then we go to Step III''.

\smallskip

\noindent {\bf Step III''}. Similar to Step III, for the path scheme, we can simulate the updates of the coefficients of the data values for the data variables as well as the output expression by a $\intnum$-VAS.


\section{Discussions}

From the analysis of the commutativity of reducers in \cite{XZZ+14}, the commutativity of a reducer in a sequential composition oa map-reduce jobs may depend on some implicit data properties guaranteed by the preceding map-reduce jobs. Therefore, to analyze the commutativity of a reducer in a sequential composition of map-reduce jobs, we may need model both mappers and reducers and do a backward analysis.

\bibliographystyle{abbrv}
\bibliography{data}


\begin{appendix}



\end{appendix}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{The analysis of a lasso with only one output variable for each transducer}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. Suppose $Y=Y_1 \cup Y_2$, $Y_1 \cap Y_2 = \emptyset$, $Y_1=\{y_1\}$ and $Y_2 = \{y_2\}$. We will do the analysis step by step.

At first, we assume that $X=\emptyset$, thus all the guards in the transitions are trivial.

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

We use $d_1,\dots,d_n$ to denote the $n$ data values for the handle.

Then for $j=1,2$, an expression $e_{j}=\alpha_{j,0}+ \alpha_{j,1}d_1 + \dots \alpha_{j,n}d_n$ can be constructed to describe the value of $y_{j}$ after going through the handle, where the coefficients $\alpha_{j,0},\dots, \alpha_{j,n}$ are obtained from the transitions in the handle. Note here we ignore the special situations that the value of $y_{j}$ is undefined after going through the handle. Because of the ``copyless'' constraint, it holds that $\alpha_{j,1},\dots,\alpha_{j,n} \in \{0,+1,-1\}$.

Let $\theta$ be the assignment function such that $\theta(y_1)=e_1$ and $\theta(y_2)=e_2$.

Suppose $O(q_n)=a_0+a_1 y_{1} + a_2 y_2$. Then $\theta(O(q_n))$, that is, the expression obtained by replacing $y_1,y_2$ with $e_1,e_2$, is $a_0+a_1 e_{1} + a_2 e_2$, which can be rearranged into the following expression,
\[
(a_0 + \alpha_{1,0}+\alpha_{2,0}) + (a_1 \alpha_{1,1}+a_2 \alpha_{2,1}) d_1 + \dots + (a_1 \alpha_{1,n}+a_2 \alpha_{2,n}) d_n.
\]
Let $\mu_0,\dots,\mu_n$ denote the coefficients of the expression. 
If $\mu_i \neq 0$ for some $i: 1 \le i \le n$, then we know that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

Otherwise, we continue analyzing the loop. 

Similarly to the handle, for each $j=1,2$, an expression $f_1 = \beta_{1,0} + \beta_{1,1} \theta(y_1) + \gamma_{1,1} d'_1 + \dots + \gamma_{1,m} d'_m$ can be constructed to describe the value of the variable $y_{1}$ after going through the loop, where $\theta(y_{1})$ denote the initial value of the output variable $y_1$ and $d'_1, \dots, d'_m$ denote the data values occurring in the loop. Similarly, an expression $f_2 = \beta_{2,0} + \beta_{2,1} \theta(y_2) + \gamma_{2,1} d'_1 + \dots + \gamma_{2,m} d'_m$ can be constructed for $y_2$. As a result of the ``copyless'' constraint again, we know that $\beta_{j,1}, \gamma_{j,1},\dots,\gamma_{j,m} \in \{0,+1,-1\}$ for $j=1,2$.

Let $\chi$ be the assignment function such that $\chi(y_1)=f_1$ and $\chi(y_2)=f_2$.

Then $\chi(O(q_n)) = a_0 + a_1 f_1 + a_2 f_2$ can be rearranged into the following expression,
\[
(a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} ) + (a_1 \beta_{1,1})\theta(y_1)+(a_2 \beta_{2,1} )\theta(y_2) + 
 (a_1\gamma_{1,1} + a_2 \gamma_{2,1}) d'_1 + \dots + (a_1\gamma_{1,m} + a_2 \gamma_{2,m}) d'_m.
\]


If $a_1 \gamma_{1,i} +a_2 \gamma_{2,i} \neq 0$ for some $i: 1 \le i \le m$, then we are done.


Otherwise, let $a'_0, a'_1,a'_2$ be the coefficients in the expression above, that is, $\chi(O(q_n))=a'_0 + a'_1 \theta(y_1)+ a'_2 \theta(y_2)$.

By expanding the expressions $\theta(y_1)=e_1$ and $\theta(y_2)=e_2$ in $\chi(O(q_n))$, we get the following expression,

\[
(a'_0 + \alpha_{1,0}+\alpha_{2,0}) + (a'_1 \alpha_{1,1}+a'_2 \alpha_{2,1}) d_1 + \dots + (a'_1 \alpha_{1,n}+a'_2 \alpha_{2,n}) d_n.
\]

For each $i: 0 \le i \le n$, let $\mu'_i$ denote the $i$-th coefficient of the expression. 
%
Intuitively, $\theta(O(q_n)) = \mu_0 + \mu_1 d_1 + \dots + \mu_n d_n$ and $\chi(O(q_n)) = \mu'_0 + \mu'_1 d_1 + \dots \mu'_n d_n$.

If $\mu'_i \neq 0$ for some $i: 0 \le i \le n$, then we are done. 

Otherwise, we iterate the loop once more.  Then we get the output $a'_0 + a'_1 \chi(y_1)+ a'_2 \chi(y_2)$, which can be rearranged into
\[
 (a'_0 + a'_1 \beta_{1,0} + a'_2 \beta_{2,0} ) + (a'_1 \beta_{1,1})\theta(y_1)+(a'_2 \beta_{2,1} )\theta(y_2) + 
 (a'_1\gamma_{1,1} + a'_2 \gamma_{2,1}) d'_1 + \dots + (a'_1\gamma_{1,m} + a'_2 \gamma_{2,m}) d'_m.
\]

By expanding the expressions $a'_0 = a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0}$, $a'_1=a_1 \beta_{1,1}$, $a'_2=a_2 \beta_{2,1}$, as well as $\theta(y_1)$ and $\theta(y_2)$, we get the following expression,
\[
\begin{array}{l}
 (a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} + \alpha_{1,0} + \alpha_{2,0}) + \\
 ((a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,1}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,1})d_1 + \\
 \multicolumn{1}{c}{\dots} \\
  ((a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,n}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,n})d_n \\
 (a_1 \beta_{1,1}\gamma_{1,1} + a_2 \beta_{2,1} \gamma_{2,1}) d'_1 + 
 \dots + (a_1 \beta_{1,1}\gamma_{1,m} + a_2 \beta_{2,1} \gamma_{2,m}) d'_m.
\end{array}
\]

From the fact that $\mu_0=\mu_1 = \dots \mu_n =0$ and $\mu'_0=\mu'_1=\dots = \mu'_n=0$, we get the following equations, 
\[
\begin{array}{l c l}
a_0 + \alpha_{1,0}+\alpha_{2,0} & = & 0,\\
a_1 \alpha_{1,1} + a_2 \alpha_{2,1} & = & 0,\\
\multicolumn{3}{c}{\dots}  \\
a_1 \alpha_{1,n} + a_2 \alpha_{2,n} & = & 0, \\
a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + \alpha_{1,0}+ \alpha_{2,0}  & =  & 0,\\
a_1\beta_{1,1} \alpha_{1,1} + a_2 \beta_{2,1} \alpha_{2,1} & = & 0,\\
\multicolumn{3}{c}{\dots}  \\
a_1\beta_{1,1} \alpha_{1,n} + a_2 \beta_{2,1} \alpha_{2,n}  & = & 0.
\end{array}
\] 

If $\beta_{1,1} \neq \beta_{2,1}$ and $a_1 \beta_{1,0} \neq 0$, then from $a_1 \beta_{1,0} + a_2 \beta_{2,0} =0$, we deduce that 
\[a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} + \alpha_{1,0} + \alpha_{2,0} = a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} \neq 0.\]
In this case, we conclude that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

Similarly, if $\beta_{1,1} \neq \beta_{2,1}$ and $a_1 \gamma_{1,i} \neq 0$ for some $i: 1 \le i \le m$, then from $a_1 \gamma_{1,i} + a_2 \gamma_{2,i} =0$, we deduce that 
$(a_1 \beta_{1,1}\gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i}) \neq 0$. In this case, we also conclude that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

In the following, we assume that $\beta_{1,1} = \beta_{2,1}$ or $a_1 \beta_{1,0} = 0$ or for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$.

If $\beta_{1,1} = \beta_{2,1}$, then it is easy to see that $a'_0 + a'_1 \chi(y_1)+ a'_2 \chi(y_2) = 0$ and we can conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

Therefore, in the following, we assume that $\beta_{1,1} \neq \beta_{2,1}$. Then $a_1 \beta_{1,0} = 0$ or for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$. 

If $|\beta_{1,1}| =|\beta_{2,1}|$ and for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$, then we can conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

Therefore, in the following, we assume that $|\beta_{1,1}| \neq |\beta_{2,1}|$ or there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$. 
\begin{enumerate}
\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} = 0$, there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$,
\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} = 0$, for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$,
%\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} \neq 0$, for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$,
\item $|\beta_{1,1}| = |\beta_{2,1}|$ (but $\beta_{1,1} \neq \beta_{2,1}$), $a_1 \beta_{1,0} = 0$, there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$.
\end{enumerate}

For the first case above, we have $\beta_{1,1}=0$ and $\beta_{2,1} = \pm 1$, or vice versa. Then $a_1 \beta_{1,1} \gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i} \neq 0$. Therefore, we conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

For the second case above, we have $\beta_{1,1}=0$ and $\beta_{2,1} = \pm 1$, or vice versa. Then for each $i: 1 \le i \le n$, $(a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,i}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,i} = a_2  \alpha_{2,i}$ or $a_1 \alpha_{1,i}$. If there is $i: 1 \le i \le n$ such that $a_1 \alpha_{1,i} \neq 0$, then we conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero. Otherwise, we conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

For the third case above, we have that $\beta_{1,1} = 1$ and $\beta_{2,1} =-1$ or vice versa. Then $a_1 \beta_{1,1}\gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i} = 2a_1 \gamma_{1,i}$ or $-2a_1 \gamma_{1,i}$. We conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.



\section{Analysis of a lasso with multiple output variables}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. 

We assume that $X=\emptyset$, thus all the guards in the transitions are trivial. Let $Y=\{y_1,\dots,y_l\}$.

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

<<<<<<< HEAD
We then focus on the equivalence problem of generalized flat \SDSIT$_{\pm}$.

A \SDSIT$_{\pm}$ is called \emph{generalized flat} if each nontrivial SCC (strongly-connected component) of the transition graph is a collection of edge-disjoint simple cycles such that there is a unique state which is shared by each pair of distinct cycles in the collection.

Let $\Ss_1$ and $\Ss_2$ be two generalized flat \SDSIT$_{\pm}$.

\begin{proposition}\label{prop-equiv-reduce}
The equivalence problem of two generalized flat \SDSIT$_{\pm}$ be reduced to the non-zero output problem of a generalized flat \SDSIT$_{\pm}$.
\end{proposition}

%Suppose $\Ss_1=(Q_1, K, X_1, Y_1, \delta_1, q_{0,1}, O_1)$ and $\Ss_1=(Q_2, K, X_2, Y_2, \delta_2, q_{0,2}, O_2)$ are two generalized flat \SDSIT$_{\pm}$. Without loss of generality, we assume that the state spaces (resp. the set of data variables, the set of output variables) of $\Ss_1$ and $\Ss_2$ are disjoint. Moreover, the \SDSIT$_{\pm}$ $\Ss$ constructed from $\Ss_1$ and $\SS_2$ (cf. Proposition~\ref{prop-equiv-reduce}), satisfies the following property: 
%\begin{quote}
%\it the output variables in $Y_1$ are updated independently of those in $Y_2$: For each transition $((q_1,q_2),g,\eta,(q'_1,q'_2))$ in $\Ss$, for each $y_1 \in Y_1$(resp. $y_2 \in Y_2$), no variables from $Y_2$ (resp. $Y_1$) occurs in $\eta(y_1)$ (resp. $\eta(Y_2)$). \hfill ($\ast$)
%\end{quote}

%In the rest of this paper, we will assume that the \SDSIT$_{\pm}$ $\Ss$ in the non-zero reachability problem satisfies that the set of output variables of $\Ss$ is $Y_1 \uplus Y_2$ and $Y_1,Y_2$ satisfy the constraint $(\ast)$.

For simplicity, from now on, we assume that $K=1$, that is, there is at most one data value over each position, and we will omit the number $K$ in the definition of \SDSIT$_{\pm}$.
=======
In the following, we will illustrate that if only the non-zero output problem is concerned, then no matter what the initial values of the output variables are, it is sufficient to traverse the loop for a bounded number of times.

%Suppose $O(q_n) = a_0 + a_1 y_1 + \dots + a_l y_l$. As a result of the ``copyless'' constraint, we know that $|a_1|, \dots, |a_l| \le 1$.

Let us traverse the loop for the first time. Then for each $1 \le j_1 \le l$, an expression 
\[f^1_{j_1} = \beta_{j_1,0} + \beta_{j_1,1} o_1 + \dots + \beta_{j_1,l} o_l + \gamma_{j_1,1} d^1_1 + \dots + \gamma_{j_1,m} d^1_m\] 
can be constructed to describe the value of the variable $y_{j_1}$ after traversing the loop for the first time, where $o_1,\dots,o_l$ denote the initial value of the output variables and $d^1_1, \dots, d^1_m$ denote the data values introduced when traversing the loop for the first time. 

As a result of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+\dots +|\beta_{l,i}| \le 1$.


We then traverse the loop for the second time. Then for each $1 \le j_2 \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^2_{j_2} = \beta_{j_2,0} + \beta_{j_2,1} f^1_1 + \dots + \beta_{j_2,l} f^1_l + \gamma_{j_2,1} d^2_1 + \dots + \gamma_{j_2,m} d^2_m$, where $d^2_1, \dots, d^2_m$ denote the data values introduced when traversing the loop for the second time. 

By expanding the expressions $f^1_1,\dots, f^1_l$, we get the following expression for $f^2_{j_2}$ (where $1 \le j_2 \le l$),
\[
\begin{array}{l}
f^2_{j_2} = (\beta_{j_2,0} + \sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, 0}) + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,1}) o_1 + \dots + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,l}) o_l +  \\
(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,1}) d^1_1 +\dots + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,m}) d^1_m  + \\
\gamma_{j_2,1} d^2_1 + \dots + \gamma_{j_2,m} d^2_m.
\end{array}
\]
>>>>>>> f2cb40ca9967a5ef6cc325a5ecf49fb6ef047542

Note that because of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+ \dots |\beta_{l,i}| \le 1$, thus the absolute value of $\sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, i}$ is at most one. 

We continue traversing the loop for the third time. Then for each $1 \le j_3 \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^3_{j_3} = \beta_{j_3,0} + \beta_{j_3,1} f^2_1 + \dots + \beta_{j_3,l} f^2_l + \gamma_{j_3,1} d^3_1 + \dots + \gamma_{j_3,m} d^3_m$, where $d^3_1, \dots, d^3_m$ denote the data values introduced when traversing the loop for the third time. 

By expanding the expressions $f^2_1,\dots,f^2_l$, we get the following expression for $f^3_{j_3}$ (where $1\le j_3 \le l$),
\[
\begin{array}{l}
f^3_{j_3} = (\beta_{j_3,0} + \sum \limits_{1 \le j_2 \le l} \beta_{j_3,j_2} (\beta_{j_2,0} + \sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, 0})) +\\
%
 (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,1})) o_1 + \dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,l})) o_l +  \\
 %
(\sum \limits_{1 \le j_2 \le l}\beta_{j_3, j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,1})) d^1_1 +\dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,m})) d^1_m  + \\
(\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}\gamma_{j_2,1}) d^2_1 +\dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}\gamma_{j_2,m}) d^2_m  + \\
\gamma_{j_3,1} d^3_1 + \dots + \gamma_{j_3,m} d^3_m.
\end{array}
\]

<<<<<<< HEAD
%In the following, we focus on the non-zero reachability problem of generalized flat \SDSIT$_{\pm}$ such that $|Y_1| = |Y_2|=1$. The more general case is open. \zhilin{See appendix for an incomplete analysis of a lasso in the general case}
=======
Note that because of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+ \dots |\beta_{l,i}| \le 1$, thus the absolute value of $\sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, i}$ is at most one. 
>>>>>>> f2cb40ca9967a5ef6cc325a5ecf49fb6ef047542
















We illustrate the argument for this fact with the following example: There are six data variables, $x_1,\dots,x_5$ such that  $G_C$ comprises a cycle $x_1x_2x_3$ and a path $x_4 x_5$. Without loss of generality, we assume that $\chi_1(x_4)=d^1_{\min(I_6)}=d^1_6$. We will show that it is sufficient to traverse the loop for three times.

Let $\chi_2$ be the assignment function that describes the values of the data and output variables after traversing the loop twice. Then for each $j: 1 \le j \le k$, $\chi_2(x_j)=d^2_j$, and for each $j: 1 \le j \le l$, 
\[\chi_2(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_1(y_j) + \beta_{j,1} d^2_{\min(I_1)} + \dots + \beta_{j,r} d^2_{\min(I_r)},\]
where $d^2_{\min(I_1)}=d^2_1 = \chi_1(x_3)=d^1_3$, $d^2_{\min(I_2)}=d^2_2 = \chi_1(x_1)=d^1_1$, $d^2_{\min(I_3)}=d^2_3 = \chi_1(x_2)=d^1_2$, $d^2_{\min(I_4)}=d^2_4 = d^1_{\min(I_6)}=d^1_6$, and $d^2_{\min(I_5)}=\chi_1(x_4)=d^1_4$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_1(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_2(y_j) & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + \alpha^2_{j,1} o_j + (\alpha_{j,1} \beta_{j,1}) d^1_{\min(I_1)} +  \dots + (\alpha_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
& &  \beta_{j,1} d^1_3 + \beta_{j,2} d^1_1 + \beta_{j,3} d^1_2 + \beta_{j,4} d^1_6 + \beta_{j,5} d^1_4 + \beta_{j,6} d^2_{\min(I_6)} + \dots + \beta_{j,r} d^2_{\min(I_r)}\\
& = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + (\alpha_{j,1})^2 o_j + (\alpha_{j,1} \beta_{j,1} + \beta_{j,2}) d^1_1 + (\alpha_{j,1}\beta_{j,2}+\beta_{j,3})d^1_2+\\
& & (\alpha_{j,1}\beta_{j,3}+\beta_{j,1})d^1_3 +  (\alpha_{j,1}\beta_{j,4}+\beta_{j,5})d^1_4 + (\alpha_{j,1}\beta_{j,5})d^1_5 + (\alpha_{j,1}\beta_{j,6}+\beta_{j,4})d^1_6 + \\
& & (\alpha_{j,1}\beta_{j,7}) d^1_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^1_{\min(I_r)} + \beta_{j,6} d^2_{\min(I_6)} + \dots + \beta_{j,r} d^2_{\min(I_r)}.
\end{array}
\] 

Let $\chi_3$ be the assignment function that describes the values of the data and output variables after traversing the loop for the third time. Then for each $j: 1 \le j \le k$, $\chi_3(x_j)=d^3_j$, and for each $j: 1 \le j \le l$, 
\[\chi_3(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_2(y_j) + \beta_{j,1} d^3_{\min(I_1)} + \dots + \beta_{j,r} d^3_{\min(I_r)},\]
where $d^3_{\min(I_1)}=d^3_1 = \chi_2(x_3)=d^2_3=d^1_2$, $d^3_{\min(I_2)}=d^3_2 = \chi_2(x_1)=d^2_1=d^1_3$, $d^3_{\min(I_3)}=d^3_3 = \chi_2(x_2)=d^2_2=d^1_1$, $d^3_{\min(I_4)}=d^3_4 = d^2_{\min(I_6)}=d^2_6$, and $d^3_{\min(I_5)}=\chi_2(x_4)=d^2_4=d^1_6$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_2(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_3(y_j) & = & 
%
%(\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}) + (\alpha_{j,1})^3 o_j + (\alpha^2_{j,1} \beta_{j,1}) d^1_{\min(I_1)} +  \dots + (\alpha^2_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
%& &  (\alpha_{j,1}\beta_{j,1}) d^1_3 + (\alpha_{j,1}\beta_{j,2}) d^1_1 + (\alpha_{j,1}\beta_{j,3}) d^1_2 + (\alpha_{j,1}\beta_{j,4}) d^1_6 + (\alpha_{j,1}\beta_{j,5}) d^1_4 + \\
%& & (\alpha_{j,1}\beta_{j,6}) d^2_{\min(I_6)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+\beta_{j,1} d^1_2 + \beta_{j,2}  d^1_3 + \beta_{j,3} d^1_1 + \beta_{j,4} d^2_6 + \\
%& & \beta_{j,5} d^1_6 + \beta_{j,6} d^3_{\min(I_6)} + \dots + \beta_{j,r} d^3_{\min(I_r)}\\
%
%& = & 
(\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}) + \alpha^3_{j,1} o_j + (\alpha^2_{j,1} \beta_{j,1}+ \alpha_{j,1}\beta_{j,2} + \beta_{j,3} ) d^1_1 + \\
& & (\alpha^2_{j,1} \beta_{j,2}+\alpha_{j,1}\beta_{j,3} + \beta_{j,1} ) d^1_2 + (\alpha^2_{j,1} \beta_{j,3} + \alpha_{j,1}\beta_{j,1} + \beta_{j,2}  ) d^1_3 + (\alpha^2_{j,1} \beta_{j,4}+\alpha_{j,1}\beta_{j,5}) d^1_4 +\\
& & (\alpha^2_{j,1} \beta_{j,5}) d^1_5 + (\alpha^2_{j,1} \beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5})d^1_6 + (\alpha^2_{j,1} \beta_{j,7}) d^1_{\min(I_7)}+ \dots + (\alpha^2_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
& & (\alpha_{j,1}\beta_{j,6}+\beta_{j,4}) d^2_{6} + (\alpha_{j,1}\beta_{j,7}) d^2_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+  \\
& &  \beta_{j,6} d^3_{\min(I_6)} + \dots + \beta_{j,r} d^3_{\min(I_r)}.
\end{array}
\] 

Let $\chi_4$ be the assignment function that describes the values of the data and output variables after traversing the loop for the third time. Then for each $j: 1 \le j \le k$, $\chi_4(x_j)=d^4_j$, and for each $j: 1 \le j \le l$, 
\[\chi_4(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_3(y_j) + \beta_{j,1} d^4_{\min(I_1)} + \dots + \beta_{j,r} d^4_{\min(I_r)},\]
where $d^4_{\min(I_1)}=d^4_1 = \chi_3(x_3)=d^3_3=d^1_1$, $d^4_{\min(I_2)}=d^4_2 = \chi_3(x_1)=d^3_1=d^1_2$, $d^4_{\min(I_3)}=d^4_3 = \chi_3(x_2)=d^3_2=d^1_3$, $d^4_{\min(I_4)}=d^4_4 = d^3_{\min(I_6)}=d^3_6$, and $d^4_{\min(I_5)}=\chi_3(x_4)=d^3_4=d^2_6$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_3(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_4(y_j) & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}+\alpha^3_{j,1} \alpha_{j,0}) + \alpha^4_{j,1}  o_j + (\alpha^3_{j,1} \beta_{j,1}+ \alpha^2_{j,1}\beta_{j,2} + \alpha_{j,1}\beta_{j,3} + \beta_{j,1}) d^1_1 + \\
& & (\alpha^3_{j,1} \beta_{j,2}+\alpha^2_{j,1}\beta_{j,3} + \alpha_{j,1}\beta_{j,1} + \beta_{j,2}) d^1_2 + (\alpha^3_{j,1} \beta_{j,3} + \alpha^2_{j,1}\beta_{j,1} + \alpha_{j,1}\beta_{j,2} +\beta_{j,3}) d^1_3 + \\
& & (\alpha^3_{j,1} \beta_{j,4}+\alpha^2_{j,1}\beta_{j,5}) d^1_4 + (\alpha^3_{j,1} \beta_{j,5}) d^1_5 + (\alpha^3_{j,1} \beta_{j,6}+\alpha^2_{j,1}\beta_{j,4}+\alpha_{j,1}\beta_{j,5})d^1_6 + \\
& & (\alpha^3_{j,1} \beta_{j,7}) d^1_{\min(I_7)}+ \dots + (\alpha^3_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + 
 (\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4} + \beta_{j,5}) d^2_{6} + \\
 & & (\alpha^2_{j,1}\beta_{j,7}) d^2_{\min(I_7)} + \dots + (\alpha^2_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+  (\alpha_{j,1}\beta_{j,6}+\beta_{j,4}) d^3_{6} +  \\
 & & (\alpha_{j,1}\beta_{j,7}) d^3_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^3_{\min(I_r)} + \beta_{j,6} d^4_{\min(I_6)} + \dots +  \beta_{j,r} d^4_{\min(I_r)}.
\end{array}
\] 

Consider the coefficient of $o_j, d^1_5, d^1_{\min(I_7)},\dots,d^1_{\min(I_r)}$.
\begin{itemize}
\item $\alpha^4_{j,1}o_j = \alpha^2_{j,1}o_j$, $(\alpha^3_{j,1} \beta_{j,5}) d^1_5 = (\alpha_{j,1} \beta_{j,5}) d^1_5$,
\item $(\alpha^3_{j,1} \beta_{j,7}) d^1_{\min(I_7)}= (\alpha_{j,1} \beta_{j,7}) d^1_{\min(I_7)}$, $\dots$, $(\alpha^3_{j,1} \beta_{j,r}) d^1_{\min(I_r)}= (\alpha_{j,1} \beta_{j,r}) d^1_{\min(I_r)}$.
\end{itemize}
Therefore, all these coefficients are the same as those in $\chi_2(y_j)$.

Let us check the constant coefficient and the coefficients of $d^1_1,d^1_2,d^1_3,d^1_4,d^1_5$ and $d^1_6,d^2_6,\dots$.

\begin{itemize}
\item The constant coefficient and the coefficient of $d^1_1$, $d^1_2$, $d^1_3$ can be seen as integer counters.  

\item The coefficient of $d^1_4$ is $\alpha_{j,1} \beta_{j,4}+\beta_{j,5}, \alpha_{j,1}(\alpha_{j,1} \beta_{j,4}+\beta_{j,5}), \alpha^2_{j,1}(\alpha_{j,1} \beta_{j,4}+\beta_{j,5}), \dots$.

\item The coefficient of $d^1_5$ is $\beta_{j,5},\alpha_{j,1}\beta_{j,5}, \alpha^2_{j,1}\beta_{j,5},\alpha^3_{j,1}\beta_{j,5},\dots$.

\item The coefficient of $d^1_6$ (resp. $d^2_6,d^3_6,\dots$) is $\beta_{j,6}, \alpha_{j,1}\beta_{j,6}+\beta_{j,4}, \alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}, \alpha_{j,1}(\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}),\alpha^2_{j,1}(\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}),\dots$.
\end{itemize}
Since $\alpha_{j,1} \in\{0,+1,-1\}$, the values of the coefficients of $d^1_4,d^1_5$ and $d^1_6,d^2_6,d^3_6,\dots$ are from a bounded domain.












\subsection{The analysis of a lasso with independently evolving multiple output variables}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. 

We assume that $X=\emptyset$, thus all the guards in the transitions are trivial. Let $Y=\{y_1,\dots,y_l\}$. In addition, we assume that all the output variable are \emph{independently evolving} in the sense that for each transition $(q,g, \eta, q')$, it holds that for each $y \in Y$, only $y$ can occur in $\eta(y)$ and no other output variables can occur in $\eta(y)$. 

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

In the following, we will illustrate that if only the non-zero output problem is concerned, then no matter what the initial values of the output variables are, it is sufficient to traverse the loop for a bounded number of times.

%Suppose $O(q_n) = a_0 + a_1 y_1 + \dots + a_l y_l$. As a result of the ``copyless'' constraint, we know that $|a_1|, \dots, |a_l| \le 1$.

Let us traverse the loop for the first time. Then for each $1 \le j \le l$, an expression 
\[f^1_{j} = \beta_{j,0} + \beta_{j} o_{j} + \gamma_{j,1} d^1_1 + \dots + \gamma_{j,m} d^1_m\] 
can be constructed to describe the value of the variable $y_{j}$ after traversing the loop for the first time, where $o_1,\dots,o_l$ denote the initial value of the output variables and $d^1_1, \dots, d^1_m$ denote the data values introduced when traversing the loop for the first time. Note that as a result of ``independently evolving'' constraint, for each $j: 1 \le j \le l$, $f^1_{j}$ contains only $o_{j}$ and no other output variables. Moreover, because of ``copyless'' constraint, $\beta_j \in \{0,+1,-1\}$.

Suppose $O(q_n)=a_0 + a_1 o_1 + \dots a_l o_l$. 

Let $\chi_1$ be the assignment $\chi_1(y_j)=f^1_j$ for each $j: 1\le j \le l$.
Then $\chi_1(O(q_n)) = a_0+ a_1 f^1_1 + \dots a_l f^1_l$ is the following expression,
\[
(a_0 + \sum \limits_{1 \le j \le l} (a_j\beta_{j,0})) +  (a_1 \beta_1) o_1 + \dots + (a_l \beta_l) o_l + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^1_m.
\]

If $(\sum \limits_{1 \le j \le l} a_j \gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j \gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.

We then traverse the loop for the second time. Then for each $1 \le j \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^2_{j} = \beta_{j,0} + \beta_{j} f^1_{j} + \gamma_{j,1} d^2_1 + \dots + \gamma_{j,m} d^2_m$, where $d^2_1, \dots, d^2_m$ denote the data values introduced when traversing the loop for the second time. 

By expanding the expressions $f^1_1,\dots, f^1_l$, we get the following expression for $f^2_{j}$ (where $1 \le j \le l$),
\[
%\begin{array}{l}
f^2_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0}) + (\beta_{j})^2 o_{j} +
%\\
(\beta_{j}\gamma_{j,1}) d^1_1 +\dots + (\beta_{j}\gamma_{j,m}) d^1_m  + 
%\\
\gamma_{j,1} d^2_1 + \dots + \gamma_{j,m} d^2_m.
%\end{array}
\]

Let $\chi_2$ be the assignment $\chi_2(y_j)=f^2_j$ for each $j: 1\le j \le l$.
Then $\chi_2(O(q_n)) = a_0+ a_1 f^2_1 + \dots a_l f^2_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0})) +  (a_1 (\beta_1)^2) o_1 + \dots + (a_l (\beta_l)^2) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j \beta_{j}\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_{j}\gamma_{j,m}) d^1_m + \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^2_m.
\end{array}
\]

If $(\sum \limits_{1 \le j \le l} a_j \beta_j\gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j \beta_j\gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.


We continue traversing the loop for the third time. Then for each $1 \le j \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^3_{j} = \beta_{j,0} + \beta_{j} f^2_j  + \gamma_{j,1} d^3_1 + \dots + \gamma_{j,m} d^3_m$, where $d^3_1, \dots, d^3_m$ denote the data values introduced when traversing the loop for the third time. 

By expanding the expressions $f^2_1,\dots,f^2_l$, we get the following expression for $f^3_{j}$ (where $1\le j \le l$),
\[
\begin{array}{l}
f^3_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0}) + (\beta_{j})^3 o_{j} +
%\\
((\beta_{j})^2\gamma_{j,1}) d^1_1 +\dots + ((\beta_{j})^2\gamma_{j,m}) d^1_m  + \\
%\\
(\beta_j \gamma_{j,1}) d^2_1 + \dots + (\beta_j \gamma_{j,m}) d^2_m + \gamma_{j,1} d^3_1 + \dots + \gamma_{j,m} d^3_m.
\end{array}
\]

Let $\chi_3$ be the assignment $\chi_3(y_j)=f^3_j$ for each $j: 1\le j \le l$.
Then $\chi_3(O(q_n)) = a_0+ a_1 f^3_1 + \dots a_l f^3_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0})) +  (a_1 (\beta_1)^3) o_1 + \dots + (a_l (\beta_l)^3) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,m}) d^1_m + \\
(\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,m}) d^2_m \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^3_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^3_m. 
\end{array}
\]

Since for each $j: 1 \le j \le l$, $\beta_j \in \{0,+1,-1\}$, we know that for each $j: 1 \le j \le l$, $(\beta_j)^3=\beta_j$. Therefore, $(a_1 (\beta_1)^3) o_1 + \dots + (a_l (\beta_l)^3) o_l = (a_1 \beta_1) o_1 + \dots + (a_l \beta_l) o_l$.

If $(\sum \limits_{1 \le j \le l} a_j (\beta_j)^2\gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j (\beta_j)^2\gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.


We continue traversing the loop for the fourth time. Then for each $1 \le j \le l$, the resulting value of the variable $y_j$ is described by the expression 
\[
\begin{array}{l}
f^4_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0}+(\beta_j)^3 \beta_{j,0}) + (\beta_{j})^4 o_{j} +
\\
((\beta_{j})^3\gamma_{j,1}) d^1_1 +\dots + ((\beta_{j})^3 \gamma_{j,m}) d^1_m  + 
((\beta_{j})^2\gamma_{j,1}) d^2_1 +\dots + ((\beta_{j})^2 \gamma_{j,m}) d^2_m \\
(\beta_j \gamma_{j,1}) d^3_1 + \dots + (\beta_j \gamma_{j,m}) d^3_m + \gamma_{j,1} d^4_1 + \dots + \gamma_{j,m} d^4_m.
\end{array}
\]

Let $\chi_4$ be the assignment $\chi_4(y_j)=f^4_j$ for each $j: 1\le j \le l$.
Then $\chi_4(O(q_n)) = a_0+ a_1 f^4_1 + \dots a_l f^4_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0} + (\beta_j)^3 \beta_{j,0})) +  (a_1 (\beta_1)^4) o_1 + \dots + (a_l (\beta_l)^4) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,m}) d^1_m + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,m}) d^2_m + \\
(\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,1}) d^3_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,m}) d^3_m \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^4_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^4_m. 
\end{array}
\]

Since for each $j: 1\le j \le l$, $(\beta_j)^3=\beta_j$, we deduce that $(\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,i}) = (\sum \limits_{1 \le j \le l} a_j \beta_{j} \gamma_{j,i}) =0$ for each $i: 1\le i \le m$.

Since $\beta_j \in \{0,+1,-1\}$, we know that for each $j: 1\le j \le l$, $(\beta_j)^4=(\beta_j)^2$. Therefore, $(a_1 (\beta_1)^4) o_1 + \dots + (a_l (\beta_l)^4) o_l=(a_1 (\beta_1)^2) o_1 + \dots + (a_l (\beta_l)^2) o_l$.

Therefore, if the constant coefficient is ignored, then it is sufficient to traverse the loop for \emph{three times}.

For the consideration of the constant coefficient, let us assume that for each $j: 1 \le j \le l$, 
$o_j = \alpha_{j,0} + \alpha_{j,1} d_1+ \dots + \alpha_{j,n}d_n$, where $d_1,\dots,d_n$ are the data values introduced in the handle.

Then the constant coefficient after traversing the loop for $r$ times ($r \ge 1$) is described by the following expression,
\[a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}).\]

Since for each $j: 1 \le j \le l$, $\beta_j \in \{0,+1,-1\}$, we know that 
\begin{itemize}
\item if if $\beta_j=0$, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}=\beta_{j,0}$,
%
\item if $\beta_j=1$, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}=r\beta_{j,0} + \alpha_{j,0}$,
%
\item if $\beta_j = -1$ and $r$ is odd, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}= \beta_{j,0} - \alpha_{j,0}$,

\item if $\beta_j = -1$ and $r$ is even, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}= 2\beta_{j,0} + \alpha_{j,0}$.
\end{itemize}

Therefore, the non-zero output problem is reduced to the following problem: 
\begin{quote}
\it Given an expression of the form $c_0+c_1 r$, where $c_0 ,c_1$ are constants, and $r$ is a variable ranging over natural numbers, decide whether there exists $r$ such that $c_0+ c_1 r$ is non-zero. 
\end{quote}

\zhilin{I stopped here}



\subsection{Flat transducer with independently evolving output variables}

Let $\Ss=(Q, K, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. Suppose $X=\{x_1,\dots,x_k\}$ and $Y=\{y_1,\dots,y_l\}$. For simplicity, we assume that $K = 1$, that is, each position holds one data value.

A path scheme is a path in the SCC graph, which corresponds to a sequence of SCCs in the transition graph such that for each pair of consecutive SCCs in the sequence, say $C_1$ and $C_2$, there is an edge from $C_1$ to $C_2$.

Let us fix a path scheme, say $C_0 \dots C_n$.

For simplicity, let us start with the easy case that for each $i: 0 \le i < n$, $C_i$ is a single state and $C_n$ contains more than one node, that is, $C_0 \dots C_n$ is $q_0 \dots q_{n-1} q_n (C^1_n,\dots,C^m_n)$, where $C^1_{n},\dots, C^m_n$ are the collection of simple cycles in $C_n$ which share a unique state $q_{n}$. Moreover, we assume that $O(q_n)$ is defined and $O$ is undefined in each of the other states of $C_n$.

Without loss of generality, assume that each state in $C_0 \dots C_n$ is reachable. It is known that the state reachability problem of flat register automata is PSPACE-complete (\cite{DL09}). 

%Recall that we assume that $\Ss$ is copyless.

We show by induction that for each $i: 1 \le i \le n$ and each variable $x_j$ (resp. $y_j$), an arithmetic expression $e_{i,x_j}$ (resp. $e_{i,y_j}$) corresponding to $x_j$(resp. $y_j$) after going through the state sequence $q_0 \dots q_i$ can be constructed. Let $(q_{i}, 1, g_{i}, \eta_{i}, q_{i+1})$ be the $i$-th transition for each $i: 0 \le i < n$.

For each $j: 1 \le j \le k$, if $\eta_1(x_j)=p_1$, then $e_{1,x_j}=d_1$, otherwise, $e_{1,x_j}=\bot$.

For each $j: 1 \le j \le l$, $e_{1,y_j} = (\eta_{1,y_j}[d_1/p_1])$. 

For each $i: 1 < i \le n$, 
\begin{itemize}
\item for each $j: 1 \le j \le k$, $e_{i,x_j}=d_i$ if $\eta_i(x_j)=p_1$, and $e_{i,x_j}=e_{i-1,x_j}$ otherwise,
%
\item for each $j: 1 \le j \le l$, $e_{i,y_j} = \theta_i(\eta_i(y_j))$, where $\theta_i(x_{j'})=e_{i-1,x_{j'}}$ and $\theta_i(y_{j'})=e_{i-1, y_{j'}}$, and $\theta_i(p_1)=d_i$.
\end{itemize}

Then for each $j$, $e_{n,y_j} = c_{0,j} + c_{1,j} d_1 + \dots + c_{n,j} d_n$, where $c_{0,j},\dots, c_{n,j}$ are integer constants.

\smallskip

\noindent {\bf Step 1}: Decide whether $\theta_{n+1}(O(q_n))$ is not identical to zero (it is easy to do so, just check the coefficients of $d_1,\dots,d_n$), where $\theta_{n+1}(x_j)=e_{n,x_j}$ and $\theta_{n+1}(y_j)=e_{n,y_j}$. If the answer is yes, then we are done. Otherwise, we will continue checking the cycles of $C_n$.

Similarly, for each cycle $C^i_n = q'_0 q'_1 \dots q'_{l_i}$ such that $q'_0 = q'_{l_i}=q_n$, we can construct expressions $e'_{i,x_j}$ and $e'_{i,y_j}$ where the variables $x_1,\dots,x_k,y_1,\dots,y_l$ and the data value variables $d'_1,\dots,d'_{l_i}$ occur. Note that $x_1,\dots,x_k,y_1,\dots,y_l$ denote the values of these variables before executing the transitions in the cycle.

\smallskip

\noindent {\bf Step 2}: Iterate the following procedure for $i = 1, \dots, m$.
\begin{enumerate}
\item Consider $\theta'_i(O(q_n))$, where $\theta'_i(x_j)=e'_{i,x_j}$ and $\theta'_i(y_j)=e'_{i,y_j}$. 
%
\item If there is $j: 1 \le j \le l_i$ such that the coefficient of $d'_j$ in $\theta'_i(O(q_n))$ is nonzero, then we are done. 
\end{enumerate}

\smallskip

\noindent {\bf Step 3}: Let $\theta''_0=\theta_{n+1}$ and $\theta''_i = \theta''_{i-1}(\theta'_i)$ for $i = 1, \dots, m$.  Continue iterating the following procedure for $i = 1, \dots, m$:   If in $\theta''_i(O(q_n))$, the constant coefficient or the coefficient of some $d_{i'}$ for some $i': 1 \le i' \le n$ is nonzero, then we are done. 

\zhilin{These three steps are basically what I thought. But Step 3 is incorrect. Since we may need iterate over a cycle for multiple times to reach nonzero output. For some special cases, e.g. difference constraints or octagon constraints, we can use Presburger formula to summarize the effect of a cycle}.

\zhilin{My current feeling is that the problem is indeed more difficult than what we thought. Therefore, let us focus on the problem at present. We will try to work for CAV. If in the end we do not work out a submittable version, then we will target another conference.}

\subsection{Generalized flat transducer with independently evolving output variables}


