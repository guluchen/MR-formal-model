\documentclass[runningheads,a4paper]{llncs}

\usepackage{latexsym}
\usepackage{setspace}
\usepackage{cancel}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{appendix}
\usepackage{amssymb}
%\usepackage{dsfont}
\usepackage{amsmath}
%\usepackage{amsthm}
%\usepackage{cancel}
%\usepackage{verbatim}
%\usepackage{chngpage}
%\usepackage{fullpage}

\usepackage{color}

\usepackage{mathrsfs}

%\newtheorem{definition}{Definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{example}{Example}
%\newtheorem{question}{Open Question}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{Algo}{Algorithm}
%\newtheorem{remark}[theorem]{Remark}

\def\arr#1{\stackrel{#1}{\longrightarrow}}

\def\Aa{{\mathscr{A} }}

\def\Bb{{\mathscr{B} }}

\def\Cc{{\mathcal{C} }}

\def\Dd{{\mathbb{D} }}

\def\Ee{{\mathcal{E} }}

\def\Ff{{\mathcal{F} }}

\def\Zz{{\mathcal{Z} }}

\def\Nn{{\mathbb{N} }}

\def\Ss{{\mathcal{S} }}

\def\schm{{\mathfrak{s} }}

\def\Tt{{\mathcal{T} }}

\def\Ii{{\mathbb{Z} }}

\def\Jj{{\mathcal{J}}}

\def\Vv{{\mathcal{V}}}

\def\Rr{{\mathcal{R} }}

\def\Ll{{\mathcal{L}}}


\def\treeset{{\mathscr{T}}}

\def\contextset{{\mathcal{C}}}

\def\theory{{\mathcal{L}}}

\def\termset{{\mathcal{T}}}

\def\formulaset{{\mathcal{F}}}

\newcommand\univ{\mathsf{Univ}}

\newcommand\op{\mathfrak{o}}

\newcommand\dv{\mathtt{x}}

\newcommand\ydv{\mathtt{y}}

\newcommand\cv{\mathtt{z}}

\newcommand\thla{\mathcal{LIA}}

\newcommand\thdif{\mathcal{DIF}}

\newcommand\thord{\mathcal{ORD}}

\newcommand\thset{\mathcal{SET}}

\newcommand\thmset{\mathcal{MUS}}

\newcommand\natnum{{\mathbb{N} }}

\newcommand\intnum{{\mathbb{Z} }}

\newcommand{\hide}[1]{}
\newcommand{\yfc}[1]{\color{blue} {YF: #1 :FY} \color{black}}
\newcommand{\zhilin}[1]{\color{cyan} {ZL: #1 :LZ} \color{black}}
\newcommand{\lei}[1]{\color{green} {LE: #1 :EL} \color{black}}
\newcommand{\SDSIT}{SDSIT}
\newcommand{\Name}{Streaming data string to integer transducer}
\newcommand{\name}{streaming data string to integer transducer}
%\def\Ss{{$\mathcal{A}$\ }}

\title{The~Commutativity~Problem~of~the~Map-Reduce Framework: A Transducer-based Approach}
\titlerunning{Commutativity of MapReduce: A Transducer-based Approach}
\author{}
\institute{}

%\author{Yu-Fang Chen, Lei Song, Zhilin Wu}

\begin{document}

\maketitle

\begin{abstract}

Map-Reduce is a popular programming model for data parallel computation. 
In Map-Reduce, the \emph{reducer} produces an output from a list of inputs. Due the scheduling policy and the settings of machines, the input may arrive the reducers with different orders. The \emph{commutative problem} of reducers asks if the output of a reducer independent of the order of its inputs. The problem is in general undecidable due to Rice's theorem and thus is seemingly uninteresting. However, the Map-Reduce model is usually used for data analytics and thus requires very simple data and control flow. 
By exploiting the simplicity of the required program flows, we propose a simple programming language for reducers where the commutative problem can be decide by a reduction to the equivalence problem of \emph{streaming numerical transducer}. 
We show that the language is expressive enough for common data analytics operations.
\end{abstract}

\section{Introduction}
%What is Map-Reduce
Map-Reduce is a  popular framework for data parallel computation. It has been adopt in various widely used cloud computing frameworks such as Hadoop~\cite{Hadoop} and Spark~\cite{Spark}. In a typical Map-Reduce program, a \emph{mapper} reads from data sources and outputs a list of key-value pairs. The load balance mechanism of the Map-Reduce framework processes the key-value pairs and sends the pairs with the same key to the same \emph{reducer}, in the form of a key and a list of values. The reducer then iterates through the input list and output a key-value pair.

To be more concrete, taking the ``word-counting'' Map-Reduce program as an example. It counts the occurrences of each word in a set of documents. The mappers reads the documents and output for each document a list in the form of $(word_1, count_1), (word_2, count_2), \ldots, (word_n, count_n)$, where $count_k$ is the number of occurrences of $word_k$ in the document being processed. These lists will be reorganized into the form of $(word_1, list_1), (word_2,list_2), \ldots, (word_n,list_n)$ and sent to the reducers, where $list_k$ is a list of integers recording the number of occurrences of $word_k$ in the set of documents. Note that the \emph{order} of the integers in the lists can differ in different executions due to network latency, load balancing, etc.
This results in the \emph{commutativity problem}.

%The communitativity problem
We say that a reducer is \emph{commutativity} if its output is independent of the order of its inputs. The commutativity problem asks if a reducer is commutativity. A study from Microsoft~\cite{XZZ+14} reports that XX\% of the reducers submit to their Map-Reducer platform are non-commutative. Among them, YY\% are confirmed as correctness bug by the programmers who wrote them. So we know that non-commutativity is a good indicator for errors in the programs. 
Moreover, having the commutativity property makes program testing easier. It is hard to reproduce a bug if the reducer under test is non-commutative. 

%The reason for studying syntatical restrictions 
The reducer commutative problem in general is undecidable by Rice's theorem. However, in practice, the reducers are seldom Turing machines. They are usually used for data analytics and have very simple control structures. Many of them just iterate through the input list and compute the output with very simple operations.
We want to study if the commutative problem of real-world reducers are decidable.

A simple programming language of reducers over integers has been considered in~\cite{CHSW15}, where they allow only loops that iterate though the input list (c.f. Figure~\ref{language}). They show that the commutative problem of programs written by such a simple language is undecidable by a reduction to the satisfiability problem of Diophantine equation. Under scrutiny, we found that the language is still too expressive for typical data analytics programs. For example, it allows multiplications of two different variables, which is a key element in the undecidability proof. 

\begin{figure}
	\centering
	\begin{tabular}{rcl}
		$c \in \mathbb{Z}$&&\\	
		$v \in Var$&$\equiv$&$x \mid y \mid z \mid cur()\mid \ldots$\\
		$g \in Guard$&$\equiv$&$cur() > v \mid cur()= v \mid v>c \mid v=c \mid \neg g \mid g\wedge g$\\
		$e \in Expressions$&$\equiv$&$c\mid v \mid e+e \mid e\times e \mid e - e$\\
		$ s \in Statements$&$\equiv$&$v := e\mid s;s\mid \mbox{if(} g \mbox{)then\{} s;\mbox{\}else\{}s;\mbox{\}}\mid \mbox{return }e\mid $\\
		&&$\mbox{while(}cur()\neq end() \mbox{)\{} s;\mbox{\}}\mid init()\mid next()$		
	\end{tabular}
	\label{fig:language}
	\caption{A Simple Programming Language for Reducers}
\end{figure}

By observing the behavioral pattern of reducer programs for data analytics, we characterize the essential components in a programming language for reducers. However, we found that even only with the essential parts of the language, the commutativity problem is still undecidable. 
Inspired by~\cite{RP11}, we found that the commutativity problem becomes decidable if we partition variables into \emph{control variables} and \emph{data variables}. Data variables cannot be used in transition guards and control variables can store only elements in the input list (e.g., it is not allowed to store the sum of two variables in a control variable). 
We believe such concepts provide good insights for reducer programming language design.

We define a formalism named \emph{streaming numerical transducers (SNT)} and use it to create a decision procedure for the reducer commutative problem.
SNTs combine the features of register automata~\cite{XX} and vector addition system with states (VASS)~\cite{YY} with restrictions on the structure of the transition systems.
We show that the equivalence, commutative, and non-zeroness problems of generalized flat SNTs are decidable.
Moreover, SNTs can be composed to form a commutative/equivalence proof of reducer programs that read the input list multiple times.
On theoretical point of view, the study of deterministic SNT is
interesting on its own right. It is tightly related to both register automata and integer VASS and the decidability of its decision problems are seemingly non-trivial. 

The rest of the paper is organized as follows. Section~\ref{sec:preliminaries} describes design of the streaming numerical transducer model, including the formal definition, the rationale behind the model design, and the types of data analytics reducer programs it can express. Section~\ref{sec:decision} discusses the decision problems and the procedure for solving the problems.

\section{Preliminary}
For a mapping $\pi$, let $dom(\pi)$ and $rng(\pi)$ denote the domain and range of $\pi$.
Let $\Ii$ denote the set of integers. Let $X$ denote a finite set of variables ranging over $\Ii$ and $x,y$ are variables in $X$. We assume that $X$ contains a special variable $cur$, which is used to denote the current data value. Then a guard over $X$ is a formula defined by the rules, $g::= cur\ o\ c \mid cur\ o\ x \mid g \wedge g$, where $o \in \{=,\neq,<, >, \le, \ge\}$. Let $Y$ be another set of variables over $\Ii$. An arithmetic expression over $Y$ is defined by the rules, $e::= y \mid c \mid e + e \mid e-e \mid e * e \mid e / e$, where $y \in Y$ and $c$ is a constant over $\Ii$. For an expression $e$, let $vars(e)$ denote the set of variables occurring in $e$. Let $\Ee_Y$ denote the set of arithmetic expressions over $Y$. An assignment $\eta$ for $X \cup Y$ is a partial function from $(X \setminus \{cur\}) \cup Y$ to $\Ee_{X \cup Y}$ (the set of arithmetic expressions over $X \cup Y$) such that for each $x \in dom(\eta) \cap X$, $\eta(x)=cur$. Note that the assignments to the special variable $cur$ are disallowed.
A data word is a sequences of data values, that is, sequences $d_1\dots d_n$, where $d_i \in \Ii$ for each $i$.

\section{Language For Integer Reducers}
In this section we discuss the rationale behind the design of the programming language for reducers in which the commutativity problem is decidable. 
First, we characteristic the essential subset of the programming language  in Figure~\ref{fig:language} that is sufficient for common data analytics operations. We show that the commutative problem of this subset is still undecidable, by a reduction from perti-net with zero test~\cite{petri}. Then we show that by partitioning the roles of variables into control and data, the commutative problem becomes decidable.

We will use the language in Figure~\ref{fig:language} to describe reducers. 

We demonstrate in Figure~\ref{fig:examples} a few simple examples of reducers performing data analytics operations. Observe that all of them follow the same behavioral pattern: the program iterates through the input list and aggregates the processed result in some variables. The operation used for the aggregation is usually ratter simple: it either adds a new value (the cases \texttt{avg} and \texttt{MAD}) or assigns a new value (the case {\texttt max\_abs}) to the variable storing the aggregated result.


\begin{figure}
	\centering
	\lstset{language=C,
		basicstyle=\ttfamily\scriptsize}
	\begin{tabular}{|c|c|c|}
\hline
		\begin{minipage}[t]{0.28\textwidth}
			(a)
			\begin{lstlisting}[mathescape=true]
int max_abs() {
 if(cur()>0){
   max:=cur();
 }else{
   max:= -cur();
 }
 next();
 while(cur()$\neq$end()){
  if(cur()>0){
   if(cur()>max){
    max:=cur();
   }
  }else{
   if(-cur()>max){
    max:=-cur();
   }  
   next();
  }
  return max;
}
			\end{lstlisting}
		\end{minipage}&
		\begin{minipage}[t]{0.28\textwidth}
			(b)
			\begin{lstlisting}[mathescape=true]
int avg() {
 sum:=cur();
 cnt:=0;
 next();
 while(cur()$\neq$end()){
  sum:=sum+cur();
  cnt+=cnt+1;
  next();
 };
 return sum/cnt;
}
			\end{lstlisting}
		\end{minipage}&
		\begin{minipage}[t]{0.29\textwidth}
		(c)
			\begin{lstlisting}[mathescape=true]
int MAD() {
 ...
 // repeat the body  
 // of (b) to compute
 // sum and cnt
 
 init();
 avg:= sum/cnt;
 mad:=0;
 while(cur()$\neq$end()){
  if(cur()<avg){
   mad=mad-(cur()-avg);
  }else{
   mad=mad+(cur()-avg);
  }
  next();
 }
 return mad/cnt;
}
			\end{lstlisting}
		\end{minipage}\\
\hline		
	\end{tabular}
	\label{fig:examples}
	\caption{Examples of Reducers Performing Data Analytics Operations: (a)Maximal Absolute Value (b)Average (c)Mean Absolute Deviation}
\end{figure}


\section{Streaming Numerical Transducers}
A streaming numerical transducer (SNT) $\Ss$ is a tuple $(Q, X, Y, \delta, q_0, O)$ such that 
\begin{itemize}
\item $Q$ is a finite set of states,
%\item $K \in \Nn$ is the maximum number of data values in each position, 
\item $X$ is a finite set of control variables which is used to store some data values that have been met,
\item $Y$ is a finite set of data variables, which is used to aggregate some information for the output,
\item $\delta$ comprises the tuples $(q,  g, \eta, q')$, where $q,q'\in Q$, $g$ is a guard over $X$ (note that the variables from $Y$ do not occur in $g$), $\eta$ is an assignment for $X \cup Y$, 
%\zhilin{I am wondering whether we should add constraints e.g. $p_1 > 5$, which is not available in the original definition of streaming transducer}\lei{Constraints like $x > p_1$ is also not allowed? For me, it makes more sense to include such constraints.}
\item $q_0 \in Q$ is the initial state,
\item $O$ is the output function, which is a partial function from $Q$ to $\Ee_{(X \setminus \{cur\}) \cup Y}$.
\end{itemize}

%A SNT $\Ss$ is said to be \emph{generalized flat} if each SCC (strongly connected component) of the transition graph of $\Ss$ is either a single state or a collection of cycles that they share a unique state.

In this paper, we restrict our attention to SNTs $\Ss$ satisfying the following constraints.
\begin{description}
\item [1 (deterministic).] For every pair of distinct tuples $(q, g_1, \eta_1,q'_1), (q, g_2,\eta_2,q'_2) \in \delta$, it holds that $g_1$ and $g_2$ are mutually exclusive, that is, $g_1 \wedge g_2$ is unsatisfiable.
%
\item[2 (copyless).] For each $(q, g, \eta, q') \in \delta$ and each $y \in Y$, $y$ appears at most once in the collection of expressions $\{\eta(y') \mid y' \in Y\}$.
%
\item[3 (independently evolving).] For each $(q, g, \eta, q') \in \delta$ and each $y \in Y$, $\eta(y)$ contains no variables $y' \in Y$ such that $y' \neq y$.
%
\item [4 (generalized flat).] Each SCC (strongly connected component) of the transition graph of $\Ss$ is either a single state or a collection of cycles that they share a unique state.
\end{description}
Note that the ``copyless'' constraint forbids the use of the expressions of the form $y+y$ in the transitions.

The semantics of a SNT $\Ss$  is given by a transduction as follows: A configuration of $\Ss$ is a pair $(q,\beta)$, where $q \in Q$ and $\beta$ is a valuation of $X \cup Y$, that is, a partial function from $X \cup Y$ to $\Ii$. When reading a data word $w=d_1 \dots d_n$, $\Ss$ runs over $w$ from left to right. Let $(q, \beta)$ be the configuration of $\Ss$ reached after running over $w$, then the output of $\Ss$ is $\beta(O(q))$, if $O(q)$ is defined and $vars(O(q)) \subseteq dom(\beta)$, and the output is undefined otherwise.

A SNT $\Ss$ is said to be a SNT$_\pm$ if all the expressions occurring in $\Ss$ use only $+,-$, but not $\ast,/$.

\begin{example}[Max, average]
The max transducer over sequences of integers is given by the transitions $(q_0, 1, x < p_1, x:=p_1, q_0)$, where $x:= p_1$ assigns $p_1$ to $x$, and $(q_0, 1, x \ge p_1 , \emptyset, q_0)$, and the output function $O(q_0)=x$. The average transducer over sequences of integers is given by the transition $(q_0, 1, true, (sum:=sum + p_1, len := len +1), q_0)$, and $O(q_0)=sum / len$. 
\end{example}

\begin{example}[Example inspired by Pagerank]
The following transducer sum all the data values, except the last position, then it outputs a concatenation of the sum and the last tuple: $(q_0, 1, true, sum:= sum + p_1, q_0)$, $(q_0, k, true, (x_i:=p_i)_{1 \le i \le k}, q_1)$, $O(q_1)=(sum, x_1,\dots, x_k)$.
\end{example}

We focus on the following decision problems of SNT.
\begin{description}
\item[(Commutativity).] Given a SNT $\Ss$, decide whether $\Ss$ is commutative, that is, whether for each data word $w$ and each permutation $w'$ of $w$, the output of $\Ss$ over $w$ is equal to that of $\Ss$ over $w'$.
%
\item[(Equivalence).] Given two SNTs $\Ss_1,\Ss_2$, decide whether $\Ss_1$ and $\Ss_2$ are equivalent, that is, whether over each data word $w$, the output of $\Ss_1$ on $w$ is defined iff that of $\Ss_2$ on $w$ is defined, moreover, if the outputs of $\Ss_1$ and $\Ss_2$ are defined, then the output of $\Ss_1$ is equal to that of $\Ss_2$.
%
\item[(Non-zero output reachability).] Given a SNT $\Ss$, decide whether $\Ss$ has a non-zero output, that is, whether there is an input $w$ such that the output of $\Ss$ on $w$ is non-zero. 
\end{description}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
\yfc{can we describe the following Triangle-counting algorithm using the model?}
\zhilin{Could you describe how to implement the algorithm in MapReduce framework?}
\yfc{this is based on the sample code in Spark, I found antoher sample code in Hadoop, maybe fits the model better, check https://github.com/vertica/Graph-Analytics----Triangle-Counting/blob/master/src/com/vertica/mr/graphs/TriangleCounter.java}

\zhilin{I will describe my understanding of the algorithm in the following} 

The task comprises of three MapReduce jobs. 
\begin{description}
\item[Job1] Map: Filter out the pairs $(v1,v2)$ such that $v1 > v2$. Reduce: on the input $(v, w_1 \dots w_k)$ (where $v < w_i$ for each $i$), output the list $((v,w_1),0), \dots, ((v,w_k),0), ((w_1,w_2),1), \dots, ((w_{k-1},w_k),1)$.
\item[Job2] Map: Identity function. Reduce: on the input $((v1,v2),i_1 ... i_k)$, if $i_j=0$ for some $j$, then output $(1, i_1+...i_k)$, otherwise, output $(1,0)$.
\item[Job3] Map: Identity function. Reduce: on the input $(1,n_1 \dots n_k)$, ouput $((n_1+\dots + n_k),null)$.
\end{description}

\zhilin{The most challenging one is Job1. The reducer in Job1 need output each distinct pair $((w_i, w_j),1)$ for a list $w_1 \dots w_n$. For this transduction, at first we need extend the transducer to output a list of $(key, value)$ pairs, instead of a single $(key,value)$ pair. Moreover, the relatively complex transduction from lists to lists seems exceeding the capability of streaming transducers.}

\newcommand{\numTri}[1]{\triangle_{#1}}
Let $G = (V, E)$ be an undirected graph without self-loops or multiple
edges. For $u, v \in V$, $\{ u, v \} \in E$ denotes that $u$ and $v$
are adjacent. A  \emph{triangle} in $G$ is formed by $u, v, w \in V$ with $\{ u, v \},
\{ u, w \}, \{ v, w \} \in E$. 
We want to count the number of triangles in a given graph.

Suppose that the graph is described as a list of edges.

For each edge $\{ u, v \} \in E$, the algorithm sends the sets $\{ u \}$
and $\{ v \}$ to $v$ and $u$ respectively. If several messages are
sent to a vertex, they are merged by unions.
\yfc{So maybe we need to also support the data type ``set''}

After this operation, we get a list of pairs $(u, U)$, where $u \in V$ and $U$ is the set $\{ v : \{ u, v \} \in E \}$.

Then for each edge $\{ u, w \} \in E$, again we send the size of the set $| U \cap W |$ to both $u$ and $w$, where $U$ and $W$ are
the set of vertices adjacent to $u$ and $v$ respectively. 
\yfc{This is difficult in our model. We need to first traverse E (the first input list) and then get the corresponding set U and W from the 2nd list. Then count the size of their intersection. Maybe can be implemented in a slightly different way.}

Observe that for every $s \in U \cap W$, we have $\{ s, u \}, \{ s, w \}, \{ u, w
\} \in E$. Let $\numTri{\{u, v\}}$ denote the number of triangles
containing the edge $\{ u, w \}$. Then $\numTri{\{u, w\}}$ is sent to
both $u$ and $w$. If several messages are sent to $w$, they are merged
by summation. After this operation we get a list of pairs $(u, \sum_{\{ u, w \} \in E} \numTri{\{u, w\}})$.

Now consider a vertex $v$ in a triangle of $u, v, w$. The triangle is
counted in both $\numTri{\{ u, v \}}$ and $\numTri{\{ w, v \}}$. Hence
we need to divide the the number by 2 to get the number of triangles containing $v$. }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Consider the permutation $\tau_2$ and $\tau_n$ in \cite{CHSW15}. We can define two streaming data string transducers $\Ss$ and $\Ss'$ (note that $\Ss'$ is independent from $n$)  for $\tau_2$ and $\tau_n$. Then the commutativity of a given SNT $\Tt$ is reduced to the equivalence of $\Tt$ and $\Ss \circ \Tt$ as well as the equivalence of $\Tt$ and $\Ss'\circ \Tt$. Note that an equivalent SNT can be defined for $\Ss \circ \Tt$ and $\Ss' \circ \Tt$ respectively.

\begin{proposition}
The commutativity of SNTs is reduced to the equivalence of SNTs in linear time. 
\end{proposition}

\begin{proposition}
From SNT $\Ss_1$ and $\Ss_2$, a SNT $\Ss_3$ can be constructed in polynomial time such that $\Ss_1$ is not equivalent to $\Ss_2$ iff there is a data word $w$ such that the output of $\Ss_3$ over $w$ is nonzero. 
\end{proposition}

Therefore, the equivalence problem of SNTs is reduced to the non-zero output reachability problem of SNTs.

\section{Decision Problems for SNTs}

In this section, we consider the non-zero output problem of SNT$_{\pm}$. Recall that we assume that the SNTs are deterministic, copyless, independently evolving and generalized flat.

%equivalence, commutativity.
%
%Cost register automata may be relevant \cite{ADD+13}. 
%\yfc{The paper assumes finite input alphabet}

%Let us start with the following simple model, called \SDSIT$_{\pm}$, where the assignment expressions used in assignments are defined by the rules $e::= y \mid e+e \mid e - e$. Note that only $+,-$ are used here and constants are forbidden. Moreover, without loss of generality, we assume that for a \SDSIT$_{\pm}$, it only ouputs a single integer (instead of a tuple of integers).


%Suppose $\Ss_1=(Q_1, K, X_1, Y_1, \delta_1, q_{0,1}, O_1)$ and $\Ss_1=(Q_2, K, X_2, Y_2, \delta_2, q_{0,2}, O_2)$ are two generalized flat SDSIT$_{\pm}$. Without loss of generality, we assume that the state spaces (resp. the set of data variables, the set of output variables) of $\Ss_1$ and $\Ss_2$ are disjoint. Moreover, the SDSIT$_{\pm}$ $\Ss$ constructed from $\Ss_1$ and $\SS_2$ (cf. Proposition~\ref{prop-equiv-reduce}), satisfies the following property: 
%\begin{quote}
%\it the output variables in $Y_1$ are updated independently of those in $Y_2$: For each transition $((q_1,q_2),g,\eta,(q'_1,q'_2))$ in $\Ss$, for each $y_1 \in Y_1$(resp. $y_2 \in Y_2$), no variables from $Y_2$ (resp. $Y_1$) occurs in $\eta(y_1)$ (resp. $\eta(Y_2)$). \hfill ($\ast$)
%\end{quote}

%In the rest of this paper, we will assume that the SDSIT$_{\pm}$ $\Ss$ in the non-zero reachability problem satisfies that the set of output variables of $\Ss$ is $Y_1 \uplus Y_2$ and $Y_1,Y_2$ satisfy the constraint $(\ast)$.


\subsection{Normalization}

Suppose $\Ss=(Q,X,Y,\delta,q_0,O)$ is a SNT. Let $c_{min}$ and $c_{max}$ denote the minimum resp. maximum constant occurring in the transitions of $\Ss$. 


A SNT $\Ss=(Q,X,Y,\delta,q_0,O)$ is said to be \emph{normalized} if the following two constraints are satisfied.
\begin{itemize}
\item For each transition $(q,g,\eta,q') \in \delta$, if $\eta(x)=cur$ for some $x \in X$, then the guard $g$ implies $\bigwedge \limits_{x \in X \setminus \{cur\}} cur \neq x$.  Intuitively, when the current data value is stored into some register, it is required that the data value is distinct from all the data values that have already been stored in the register.
%
\item For each transition $(q, g, \eta, q')$ in $\Ss$, $g$ includes one of the following formulae as a conjunct: $cur < c_{min}$, or $cur = c$ for $c_{min} \le c \le c_{max}$, or $cur > c_{max}$.
\end{itemize}


\begin{proposition}
From each SNT, an equivalent normalized SNT can be constructed (with a possibly exponential blow-up). 
\end{proposition}

From now on, we assume that all SNTs are normalized.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Analysis of a single cycle}

Let $\Ss = (Q,X,Y,\delta,q_0,O)$ be a (normalized) SNT such that $X=\{cur, x_1,\dots, x_k\}$ and $Y = \{y_1,\dots,y_l\}$. Moreover, in this and next subsection, we assume that the guards in $\Ss$ contain no comparisons with constants. Later on, we will consider the more general situation.

Suppose that $C=q_0 \xrightarrow{(g_1,\eta_1)} q_1 \dots q_{n-1} \xrightarrow{(g_n, \eta_n)} q_n$ is a path in $\Ss$ such that $q_n = q_0$.  

Suppose the initial values of the $k$ control variables are $d_1,\dots, d_k$ and the $n$ data values introduced when traversing the cycle once are $d_{k+1},\dots,d_{k+n}$ (These data values may repeat). Then the guards and the assignments in the cycle induce an equivalence relation $\sim$ on $\{1,\dots, k+n\}$ so that  $i \sim j$ iff it can be inferred from the guards and assignments that $d_i = d_j$. Since $\Ss$ is normalized, we know that for each pair of indices $i,j: 1 \le i < j \le k+n$ such that $i \sim j$, it holds that $j \ge k+1$. Let $I_1,\dots, I_{k+r}$ be an enumeration of the equivalence classes of $\sim$ on $\{1,\dots, k+n\}$ such that $\min(I_1) < \dots < \min(I_{k+r})$. Then for each $j: 1 \le j \le k$, $\min(I_j)=j$.

In the following, for $\ell =1,2,\dots$, we will define the assignment function $\chi_\ell$ with the domain $X \cup Y$ to describe the values of the control and data variables after traversing the cycle for $i$ times. 

Suppose the initial values of the $k$ control variables are $d^0_1,\dots,d^0_k$. Moreover, suppose that the $r$ data values $d^1_{1},\dots,d^1_{r}$ are introduced when traversing the cycle for the first time, with one data value for each of $I_{1},\dots,I_{r}$. 
In addition, suppose that the initial values of $y_1,\dots, y_l$ are $o_1,\dots,o_l$. 

The assignment function $\chi_1$ is of the following form,
\begin{itemize}
\item there is an injective mapping $\pi: \{1,\dots,k\} \rightarrow \{1,\dots, k+r\}$ such that for each $x_j \in X$, if $\pi(j) \le k$, then $\pi(j)=j$ and $\chi_1(x_j)=d^0_{j}$, otherwise, $\chi_1(x_j)=d^1_{\pi(j)-k}$,
% 
\item for each $y_j \in Y$, $\chi_1(y_j) = \alpha_{j,0} + \alpha_{j,1} o_j + \beta_{j,1} d^0_1 + \dots + \beta_{j,k} d^0_k + \gamma_{j,1} d^1_1 +\dots + \gamma_{j,r} d^1_{r}$ for some constants $\alpha_{j,0},\alpha_{j,1}, \beta_{j,1},\dots,\beta_{j,k}, \gamma_{j,1},\dots,\gamma_{j,r}$ such that $\alpha_{j,1} \in \{0,+1,-1\}$ (as a result of the ``copyless'' and ``independently evolving'' constraint).
\end{itemize}

Let $J_1$ be set of indices $j$ such that $\pi(j)= j$ and $J_2 = \{1,\dots,k\} \setminus J_1$. Intuitively, the values of the variables from $J_1$ are  unchanged after traversing the cycle once, and the values of the variables from  $J_2$ are changed. Then $(J_1,J_2)$ forms a partition of $\{1,\dots,k\}$. Moreover, let $J_3=\{\pi(j)-k \mid j \in J_2\}$ and $J_4 = \{1,\dots,r\} \setminus J_3$. Then $(J_3,J_4)$ forms a partition of $\{1,\dots,r\}$.

Let $d^2_{1},\dots,d^2_{r}$ be the data values introduced when traversing the cycle for the second time. Then $\chi_2$ is defined as follows,
\begin{itemize}
\item for each $j \in J_1$, $\chi_2(x_j)=\chi_1(x_j)=d^0_j$, and for each $j \in J_2$, $\chi_2(x_j) =d^2_{\pi(j)-k}$, 
%
\item for each $y_j \in Y$, $\chi_2(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_1(y_j) + \beta_{j,1} \chi_1(x_1) + \dots + \beta_{j,k} \chi_1(x_k) + \gamma_{j,1} d^2_1 +\dots + \gamma_{j,r} d^2_{r}$.
\end{itemize}

By expanding the expressions $\chi_1(y_j), \chi_1(x_1),\dots,\chi_1(x_k)$, we get the following expression,
\[
\begin{array}{l c l}
\chi_2(y_j)  & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + \alpha^2_{j,1} o_j + (\alpha_{j,1} \beta_{j,1}) d^0_{1} +\dots + (\alpha_{j,1}\beta_{j,k}) d^0_{k} + \\
& & (\alpha_{j,1} \gamma_{j,1}) d^1_1 + \dots (\alpha_{j,1} \gamma_{j,r}) d^1_r + \sum \limits_{j' \in J_1} \beta_{j,j'} d^0_{j'} + \sum \limits_{j' \in J_2} \beta_{j,j'} d^1_{\pi(j')-k} + \\
& &  \gamma_{j,1} d^2_1 + \dots + \gamma_{j,r} d^2_{r}\\
& = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + \alpha^2_{j,1} o_j + \sum \limits_{j' \in J_1} (\beta_{j,j'} + \alpha_{j,1}  \beta_{j,j'}) d^0_{j'} + \sum \limits_{j' \in J_2} (\alpha_{j,1}\beta_{j,j'}) d^0_{j'} +\\
& &  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\alpha_{j,1}\gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (\alpha_{j,1} \gamma_{j,j'}) d^1_{j'} +\\
& & \gamma_{j, 1} d^2_{1} + \dots + \gamma_{j,r} d^2_{r}.
\end{array} 
\]

Let $d^3_{1},\dots,d^3_{r}$ be the data values introduced when traversing the cycle for the third time. Then $\chi_3$ is defined as follows, 
\begin{itemize}
\item for each $j \in J_1$, $\chi_3(x_j)=\chi_2(x_j)=d^0_j$, and for each $j \in J_2$, $\chi_3(x_j) =d^3_{\pi(j)-k}$, 
%
\item for each $y_j \in Y$, $\chi_3(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_2(y_j) + \beta_{j,1} \chi_2(x_1) + \dots + \beta_{j,k} \chi_2(x_k) + \gamma_{j,1} d^3_{1} + \dots + \gamma_{j,r} d^3_{r}$.
\end{itemize}

By expanding the expressions $\chi_2(y_j), \chi_2(x_1),\dots,\chi_2(x_k)$, we get the following expression,
\[
\begin{array}{l c l}
\chi_3(y_j)  & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+\alpha^2_{j,1} \alpha_{j,0}) + \alpha^3_{j,1} o_j + \sum \limits_{j' \in J_1} (\beta_{j,j'}+\alpha_{j,1}\beta_{j,j'} + \alpha^2_{j,1}  \beta_{j,j'}) d^0_{j'} + \\
& & \sum \limits_{j' \in J_2} (\alpha^2_{j,1}\beta_{j,j'}) d^0_{j'} +  \sum \limits_{j' \in J_3} (\alpha_{j,1}\beta_{j, \pi^{-1}(j'+k)}+\alpha^2_{j,1}\gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (\alpha^2_{j,1} \gamma_{j,j'}) d^1_{j'} +\\
& & \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\alpha_{j,1}\gamma_{j,j'}) d^2_{j'} + \sum \limits_{j' \in J_4} (\alpha_{j,1} \gamma_{j,j'}) d^2_{j'} +\\
& & \gamma_{j, 1} d^3_{1} + \dots + \gamma_{j,r} d^3_{r}.
\end{array} 
\]

In general, for $\ell \ge 2$, we have the following expression,
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \dots +\alpha^{\ell-1}_{j,1} \alpha_{j,0}) + \alpha^\ell_{j,1} o_j + \\
& & \sum \limits_{j' \in J_1} (\beta_{j,j'}+\alpha_{j,1}\beta_{j,j'} + \dots +\alpha^{\ell-1}_{j,1}  \beta_{j,j'}) d^0_{j'} + \\
%
& & \sum \limits_{j' \in J_2} (\alpha^{\ell-1}_{j,1}\beta_{j,j'}) d^0_{j'} +  \sum \limits_{j' \in J_3} (\alpha^{\ell-2}_{j,1}\beta_{j, \pi^{-1}(j'+k)}+\alpha^{\ell-1}_{j,1}\gamma_{j,j'}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_4} (\alpha^{\ell-1}_{j,1} \gamma_{j,j'}) d^1_{j'} + \dots + \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\alpha_{j,1}\gamma_{j,j'}) d^{\ell-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_4} (\alpha_{j,1} \gamma_{j,j'}) d^{\ell-1}_{j'} + \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]

Since $\alpha_{j,1} \in \{0,+1,-1\}$, for $\ell \ge 4$, we observe the following fact.
\begin{itemize}
\item If $\alpha_{j,1}=0$, then
\[\chi_\ell(y_j)=\alpha_{j,0}+ \sum \limits_{j' \in J_1} \beta_{j,j'} d^0_{j'}+ \sum \limits_{j' \in J_3} \beta_{j, \pi^{-1}(j'+k)} d^{\ell-1}_{j'} +\gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.\]
%
\item If $\alpha_{j,1}=+1$, then 
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & (\alpha_{j,0}\ell) + o_j +  \sum \limits_{j' \in J_1} (\beta_{j,j'} \ell) d^0_{j'} + \sum \limits_{j' \in J_2} \beta_{j,j'} d^0_{j'} + \\
& &   \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+\gamma_{j,j'}) d^1_{j'} +  \sum \limits_{j' \in J_4} \gamma_{j,j'} d^1_{j'} + \dots  \\
& &  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}+ \gamma_{j,j'}) d^{\ell-1}_{j'} +  \sum \limits_{j' \in J_4} \gamma_{j,j'} d^{\ell-1}_{j'} + \\
& & \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]
%
\item If $\alpha_{j,1}=-1$ and $\ell$ is even, then
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & o_j +  \sum \limits_{j' \in J_2} (-\beta_{j,j'}) d^0_{j'} +  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)} - \gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (-\gamma_{j,j'}) d^1_{j'} + \\
& &  \sum \limits_{j' \in J_3} (-\beta_{j, \pi^{-1}(j'+k)}+ \gamma_{j,j'}) d^2_{j'} +   \sum \limits_{j' \in J_4} \gamma_{j,j'} d^2_{j'} + \dots + \\
& & \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)} - \gamma_{j,j'}) d^{\ell-1}_{j'} +  \sum \limits_{j' \in J_4} (- \gamma_{j,j'}) d^{\ell-1}_{j'} + \\
& & \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]
\item If $\alpha_{j,1}=-1$ and $\ell$ is odd, then
\[
\begin{array}{l c l}
\chi_\ell(y_j)  & = & \alpha_{j,0}  - o_j +  \sum \limits_{j' \in J_1} \beta_{j,j'} d^0_{j'} +  \sum \limits_{j' \in J_2} \beta_{j,j'} d^0_{j'} +  \\
& & \sum \limits_{j' \in J_3} (-\beta_{j, \pi^{-1}(j'+k)}+\gamma_{j,j'}) d^1_{j'} + \sum \limits_{j' \in J_4} (\gamma_{j,j'}) d^1_{j'} + \\
& &  \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)} - \gamma_{j,j'}) d^2_{j'} +  \sum \limits_{j' \in J_4} (-\gamma_{j,j'}) d^2_{j'} + \dots + \\
& & \sum \limits_{j' \in J_3} (\beta_{j, \pi^{-1}(j'+k)}-\gamma_{j,j'}) d^{\ell-1}_{j'} +  \sum \limits_{j' \in J_4} (-\gamma_{j,j'}) d^{\ell-1}_{j'} + \\
& & \gamma_{j, 1} d^\ell_{1} + \dots + \gamma_{j,r} d^\ell_{r}.
\end{array} 
\]
\end{itemize}

From the analysis above, we know that in $\chi_\ell(y_j)$, 
\begin{itemize}
\item the coefficient of $o_j$ is from $\{0,+1,-1\}$, 
%
\item the constant coefficient is either $\alpha_{j,0}$, or $\alpha_{j,0} \ell$, or $0$, 
%
\item for each data value $d^0_{j'}$, the coefficient of $d^0_{j'}$ is either $\pm \beta_{j,j'}$, or $0$, or $\beta_{j,j'} \ell$,
%
\item for each data value $d^i_{j'}$ with $i > 0$, the coefficient of $d^i_{j'}$ is either $0$, or $\beta_{j, \pi^{-1}(j'+k)}$, or $\beta_{j, \pi^{-1}(j'+k)}+\gamma_{j,j'}$, or $\pm \gamma_{j,j'}$, or $\pm(\beta_{j, \pi^{-1}(j'+k)}-\gamma_{j,j'})$.
\end{itemize}

To summarize, we get the following intuition.
\begin{itemize}
\item For the control variables with indices from $J_1$, they can be dealt with the same as the constant coefficients, that is, dealt with as integer counters.

\item For the other control variables as well as those newly introduced data values, their coefficients are from a bounded domain and can be dealt with easily.
\end{itemize}

\subsection{Algorithm for a generalized lasso}

In this subsection, we present a decision algorithm for a generalized lasso, that is, the transition graph comprises a handle $q_0 q_1 \dots q_m$ and a collection of simple cycles $C_1,\dots,C_n$ which share the unique state $q_m$. Moreover, we assume that $O(q_m) = a_0 + a_1 x_1 + \dots + a_k x_k + a'_1 y_1 + \dots + a'_l y_l$ and $O(q)$ is undefined for all the other states $q$.

In the following, we will illustrate the argument for the case $n=2$, that is, there are only two cycles.

Let $d_1,\dots, d_m$ denote the $m$ data values met when traversing the handle. The guards and assignments of the transitions in the handle induce an equivalence relation on $\{1,\dots,m\}$ such that $i \sim j$ if the guards and assignments imply that $d_i = d_j$. For each $i: 1\le i \le m$, let $[i]$ denote the equivalence class containing $i$. Suppose the equivalence relation $\sim$ has $s$ equivalence classes, say $[i_1],\dots,[i_s]$ such that $i_1 < \dots < i_s$. Let $d^0_1,\dots,d^0_{s}$ denote the $s$ distinct data values introduced when traversing the cycle, corresponding to $[i_1],\dots,[i_s]$ respectively. 

We show by induction that for each $i: 1 \le i \le m$ and each variable $x_j$ (resp. $y_j$), an arithmetic expression $e_{i,x_j}$ (resp. $e_{i,y_j}$) corresponding to $x_j$(resp. $y_j$) after going through the state sequence $q_0 \dots q_i$ can be constructed. Let $(q_{i}, g_{i}, \eta_{i}, q_{i+1})$ be the $i$-th transition for each $i: 0 \le i < m$.

For each $j: 1 \le j \le k$, if $\eta_1(x_j)=cur$, then $e_{1,x_j}=d^0_1$, otherwise, $e_{1,x_j}=\bot$.

For each $j: 1 \le j \le l$, $e_{1,y_j} = (\eta_{1}(y_j))[d^0_1/cur]$. 

For each $i: 1 < i \le m$, 
\begin{itemize}
\item for each $j: 1 \le j \le k$, $e_{i,x_j}=d^0_{s'}$ if $\eta_i(x_j)=cur$ and $[i] = [i_{s'}]$, and $e_{i,x_j}=e_{i-1,x_j}$ otherwise,
%
\item for each $j: 1 \le j \le l$, $e_{i,y_j} = \theta_i(\eta_i(y_j))$, where $\theta_i(x_{j'})=e_{i-1,x_{j'}}$, $\theta_i(y_{j'})=e_{i-1, y_{j'}}$, and $\theta_i(cur)=d^0_{s'}$, where $[i]=[i_{s'}]$.
\end{itemize}

Then for each $j: 1 \le j \le k$, $e_{m,x_j}=d^0_{\pi_0(j)}$ for some injective mapping $\pi_0: \{1,\dots,k\} \rightarrow \{1,\dots,s\}$, and for each $j: 1 \le j \le l$, $e_{m,y_j} = c_{0,j} + c_{1,j} d^0_1 + \dots + c_{s,j} d^0_s$ for some integer constants $c_{0,j},\dots, c_{s,j}$. We use $\chi_0$ to denote the assignment function such that $\chi_0(x_j)=e_{m,x_j}$ and $\chi_0(y_j)=e_{m,y_j}$. Note here we ignore the situations that $e_{m,x_j} = \bot$ for simplicity.

\smallskip

\noindent {\bf Step I}. Decide whether $\chi_0(O(q_m))$ is not identical to zero (it is easy to do so, just check the coefficients of $d^0_1, \dots, d^0_s$). If the answer is yes, then the decision procedure terminates and returns the answer $true$. Otherwise, the decision procedure continues.

\smallskip

For the cycle $C_b$ (where $b=1,2$), the assignment function $\chi_{b,\ell}$ can be defined to describe the values of the control and output variables after traversing the cycle $C_b$ for $\ell$ times.

Suppose that for $b=1,2$, the initial values of the $k$ control variables are $d^0_{\pi_0(1)},\dots,d^0_{\pi_0(k)}$. Moreover, suppose that the $r_b$ data values $d^1_{1}, \dots, d^1_{r_b}$ are introduced when traversing the cycle for the first time, with one data value for each of $I_{1},\dots,I_{r_b}$. 
In addition, suppose that the initial values of $y_1,\dots, y_l$ are $o_1,\dots,o_l$. 

Then for $b=1,2$, the assignment function $\chi_{b,1}$ is of the following form,
\begin{itemize}
\item there is an injective mapping $\pi_b: \{1,\dots,k\} \rightarrow \{1,\dots, k+r_b\}$ such that for each $x_j \in X$, if $\pi_b(j) \le k$, then $\pi_b(j)=j$ and $\chi_{b,1}(x_j)=d^0_{\pi_0(j)}$, otherwise, $\chi_{b,1}(x_j)=d^1_{\pi_b(j)-k}$,
% 
\item for each $y_j \in Y$, $\chi_{b,1}(y_j) = \alpha_{b,(j,0)} + \alpha_{b,(j,1)} o_j + \beta_{b,(j,1)} d^0_{\pi_0(1)} + \dots + \beta_{b,(j,k)} d^0_{\pi_0(k)} + \gamma_{b,(j,1)} d^1_1 +\dots + \gamma_{b,(j,r_b)} d^1_{r_b}$ such that $\alpha_{b,(j,1)} \in \{0,+1,-1\}$.
\end{itemize}

Let $J_{b,1}$ be set of indices $j \in \{1,\dots,k+r_b\}$ such that $\pi_b(j)= j$ and $J_{b,2} = \{1,\dots,k\} \setminus J_{b,1}$. Intuitively, the values of the variables from $J_1$ are  unchanged after traversing the cycle once, and the values of the variables from  $J_{b,2}$ are changed. Then $(J_{b,1}, J_{b,2})$ forms a partition of $\{1,\dots,k\}$. Moreover, let $J_{b,3}=\{\pi_b(j)-k \mid j \in J_{b,2}\}$ and $J_{b,4} = \{1,\dots,r_b\} \setminus J_{b,3}$. Then $(J_{b,3}, J_{b,4})$ forms a partition of $\{1,\dots,r_b\}$.

We will present the argument for the situation that $J_{1,1} \cap J_{2,1} \neq \emptyset$, $J_{1,1} \setminus J_{2,1} \neq \emptyset$, and $J_{2,1} \setminus J_{1,1} \neq \emptyset$.

A \emph{cycle scheme} $\schm$ is a sequence $\schm=(1,\ell_1) (2, \ell_2 ) \dots (((m-1) \bmod 2)+1, \ell_m)$ such that $\ell_1,\dots, \ell_m \ge 1$. The number $m$ is called the length of the cycle scheme $\schm$. In principle, for each cycle scheme $\schm$, the expressions $\chi_{\schm}(y_j)$ can be defined to describe the values of $y_j$ after traversing the cycles according to $\schm$.

%\begin{proposition}\label{prop-mult-cycle}
%From a cycle scheme $\schm=(1,\ell_1) (2, \ell_2 ) \dots (((m-1) \bmod 2)+1, \ell_m)$, for each $j: 1 \le j \le l$, an expression $\chi_{\schm}(y_j)$ can be constructed from $\chi_{(1,\ell_1)}(y_j),\dots,\chi_{(((m-1) \bmod 2)+1, \ell_m)}(y_j)$ by collecting all the data variables therein and some linear combinations of their coefficients.
%\end{proposition}

In the following, we first show how to construct the expressions $\chi_{(1,\ell_1)(2,\ell_2)}$ for a cycle scheme $(1,\ell_1)(2,\ell_2)$ such that $\ell_1,\ell_2 \ge 2$, to describe the values of the control and data variables after traversing $C_1$ for $\ell_1$ times and $C_2$ for $\ell_2$ times.

At first, from the analysis of cycles, we know that
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)}(y_j)  & = & (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) + \alpha^{\ell_1}_{1,(j,1)} o_j + \\
& & \sum \limits_{j' \in J_{1,1}} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{1,2}} (\alpha^{\ell_1-1}_{1,(j,1)}\beta_{1,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')}) d^1_{j'} + \dots + \sum \limits_{j' \in J_{1,3}} (\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha_{1,(j,1)} \gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \gamma_{1,(j, 1)} d^{\ell_1}_{1} + \dots + \gamma_{1,(j,r_1)} d^{\ell_1}_{r_1},
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi_{(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)}) + \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{2,1}} (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{2,2}} (\alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+\\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{j'} +  \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{r_2}.
\end{array} 
\]

The coefficients of $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ can be obtained those of $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ as follows: For each $i: 1 \le i \le \ell_1$ and $j': 1 \le j' \le r_1$, let $d^i_{j'}$ denote the data values introduced when traversing $C_1$, and for each  $i: 1 \le i \le \ell_2$ and $j': 1 \le j' \le r_2$, let $d^{i}_{(1, \ell_1),j'}$ denote the data values introduced when traversing $C_2$ for $\ell_2$ times (after traversing $C_1$ for $\ell_1$ times).
\begin{itemize}
\item The coefficient of $o_j$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\theta_1\theta_2$, where $\theta_1$ and $\theta_2$ are the coefficient of $o_j$ in $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.
%
\item The constant coefficient of $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1,\theta_2$ are the constant coefficient of $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.
%
\item For each $j': 1 \le j' \le k$, suppose $\chi_{(1,\ell_1)}(x_{j'})=d^{i}_{j'}$, then the coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1,\theta_2$ are the  coefficient of $d^i_{j'}$ in $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.  
%
%\item For $j' \in J_{1,2}$, the coefficient of $d^{\ell_1}_{\pi_1(j')-k}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1$ is the  coefficient of $d^{\ell_1}_{\pi_1(j')-k}$ in $\chi_{(1,\ell_1)}(y_j)$ and $\theta_2$ is the coefficient of $d^0_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$.
%
\item For each pair $(i,j')$ such that $d^i_{j'} \not \in \{\chi_{(1,\ell_1)}(x_{j''}) \mid 1 \le j'' \le k\}$, the coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta$, where $\theta$ is the  coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)}(y_j)$.
%
\item For each pair $(i,j')$ such that $1 \le i \le \ell_2$ and $j' \in J_{2,3} \cup J_{2,4}$, the coefficient of $d^{i}_{(1, \ell_1),j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\theta$, where $\theta$ is the  coefficient of $d^{i}_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$, where $d^{i}_{(1, \ell_1),j'}$ is the data variable corresponding to $d^{i}_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$, decorated with $(1,\ell_1)$.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
More specifically, 
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)} + \\
%
& & \alpha^{\ell_2}_{2,(j,1)} (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) ) + \alpha^{\ell_1}_{1,(j,1)} \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{1,1} \cap J_{2,1}} (\alpha^{\ell_2}_{2,(j,1)} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) + \\
%
& & (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')})) d^0_{j'}  + \\
%
& & \sum \limits_{j' \in J_{1,2} \cap J_{2,1}} (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j,\pi_1(j')-k)} + \beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots + \\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^{\ell_1}_{\pi_1(j')-k} + \\
%
& & \sum \limits_{j' \in J_{1,1} \cap J_{2,2}}  (\alpha^{\ell_2}_{2,(j,1)} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')})+ \\
& & \alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{j'} +\\
%
& & \sum \limits_{j' \in J_{1,2} \cap J_{2,2}}  (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j,\pi_1(j')-k)}+ \alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^{\ell_1}_{\pi_1(j')-k}  +\\
%
& & \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')})) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')})) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_2}_{2,(j,1)}(\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')})) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha_{1,(j,1)} \gamma_{1,(j,j')})) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j'+k \not \in \pi_1(J_{1,2})} (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j, j')}) d^{\ell_1}_{j'}+ \\
%
& & \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{(1,\ell_1),j'} +  \\
%
& & \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{(1,\ell_1),j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{(1,\ell_1), j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{(1,\ell_1), j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{(1,\ell_1), 1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{(1,\ell_1), r_2}.
\end{array} 
\]
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\smallskip

\noindent {\bf Step II}. For $b=1,2$, let 
\[
\begin{array}{l c l}
\chi_{(b,\ell_b)}(O(q_m)) & = & a_0 + a_1 \chi_{(b,\ell_b)}(x_1) + \dots a_k \chi_{(b,\ell_b)}(x_k) + \\
& & a'_1 \chi_{(b,\ell_b)}(y_1) + \dots + a'_l \chi_{(b,\ell_b)}(y_l).
\end{array}
\] 

Then $\chi_{(b,\ell_b)}(O(q_m))$ is a linear combination of the variables $d^0_1,\dots, d^0_s$ and $d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$.

For each $j' \in J_{b,1}$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{(b,\ell_b)}(O(q_m))$ is 

\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\beta_{b,(j,j')}.\]

In general, for each $j' \in J_{1,1}$ and each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$), the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \ \ \  (\ast)\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast)$ is of the form 
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j  s_j (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')},\]
where $s_j \in \{0,+1,-1\}$.

The expression $(\ast)$ can be rewritten as $\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')}$ for some integer constant $\mu_{\schm,(1,j')},\nu_{\schm,(1,j')}$ (possibly $\mu_{\schm,(1,j')}=0$). 

If there are a cycle scheme $\schm$ starting from $C_1$  and $j' \in J_{1,1}$ such that $\mu_{\schm,(1,j')} \neq 0$, then return $true$. Note that in this case, we can let $\ell_1$ and $d^0_{\pi_0(j')}$ sufficiently large so that $(\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')})d^0_{\pi_0(j')}$ dominates $\chi_{\schm}(O(q_m))$ and $\chi_{\schm}(O(q_m))$ becomes non-zero. We would like to remark that although there are infinitely many cycle schemes $\schm$, the constants $\mu_{\schm,(1,j')}$ can only have values from a bounded domain. Therefore, it is decidable whether there exist such a desired cycle scheme $\schm$ starting from $C_1$ and $j' \in J_{1,1}$.

The similar discussion can be applied to $C_2$ and $J_{2,1}$.

If there are no desired cycle schemes $\schm$ and $j'$ for $C_1$ and $J_{1,1}$, as well as for  $C_2$ and $J_{2,1}$, then the decision procedure continues.

The constant coefficient in $\chi_{(b,\ell_b)}(O(q_m))$ is 

\[a_0 + \sum \limits_{1 \le j \le l} a'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)}.\]

In general, for each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$), the constant coefficient in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a_0 + \sum \limits_{1 \le j \le l} a'_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)}. \ \ \  (\ast\ast)\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast\ast)$ is of the form 
\[a_0 + \sum \limits_{1 \le j \le l} a'_j  s'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)},\]
where $s'_j \in \{0,+1,-1\}$.

The expression $(\ast\ast)$ can be rewritten as $\mu_{\schm,(1,0)} \ell_1 + \nu_{\schm,(1,0)}$ for some integer constant $\mu_{\schm,(1,0)},\nu_{\schm, (1,0)}$ (possibly $\mu_{\schm,(1,0)}=0$). 

If there are a cycle scheme $\schm$ starting from $C_1$ such that $\mu_{\schm,(1,0)} \neq 0$, then return $true$. Note that in this case, we can let $\ell_1$ sufficiently large so that $\mu_{\schm,(1,0)} \ell_1 + \nu_{\schm,(1,0)}$ dominates $\chi_{\schm}(O(q_m))$ and $\chi_{\schm}(O(q_m))$ becomes non-zero. We would like to remark that although there are infinitely many cycle schemes $\schm$, the constants $\mu_{\schm,(1,0)}$ can only have values from a bounded domain. Therefore, it is decidable whether there exist such a desired cycle scheme $\schm$ starting from $C_1$.

A similar discussion for the constant coefficient can be applied to the cycle schemes starting from $C_2$.

If the decision procedure has not returned yet, then we go to Step III. 

\smallskip

\noindent {\bf Step III}. For each cycle scheme $\schm=(1,\ell_1) (2,\ell_2) \dots (1+ (t-1) \bmod 2,\ell_t)$ or $\schm=(2,\ell_1) (1,\ell_2) \dots (1+ (t-1) \bmod 2,\ell_t)$, we can ignore all the expressions of the form $c\ \ell_1,\dots, c\ \ell_m$ (where $c$ is an integer constant) in $\chi_{\schm}(y_j)$, since these expressions will disappear for sure in $\chi_{\schm}(O(q_m))$, according to the analysis above. From this observation, we can show that the constant coefficient as well as the coefficients for $d^0_{\pi_0(j')}$ with $j' \in J_{1,1} \cap J_{2,1}$ in $\chi_{\schm}(y_1),\dots,\chi_{\schm}(y_l), \chi_{\schm}(O(q_m))$ can be calculated by a $\intnum$-VAS (cf. \cite{HH14}), that is, an integer vector addition system. Moreover, all the other coefficients in $\chi_{\schm}(y_1),\dots,\chi_{\schm}(y_l), \chi_{\schm}(O(q_m))$ are from a bounded domain, no matter how long the scheme $\schm$ is.  

Therefore, in this case, the non-zero output reachability problem is reduced to the non-zero reachability problem of $\intnum$-VAS, that is, given an index $i$, decide whether a vector $\vec{z}$ where $z_i$ is non-zero can be reached.  It is not hard to see that the non-zero reachability problem of $\intnum$-VAS can be reduced to the coverability problem of $\intnum$-VAS. From the fact that the coverability of $\intnum$-VAS is NP-complete (\cite{HH14}),  we conclude that the non-zero output reachability of SNS$\pm$ whose transition graph is a generalized lasso is decidable.


\subsection{Comparison with constants}

We now consider the situation that the guards include the comparisons with constants, that is, the atomic formulae of the form $cur\ o\ c$, where $c$ is an integer constant. 

For this situation, we adapt the algorithm for a generalized lasso into Step I', II' and III' below.

\smallskip

\noindent {\bf Step I'}. Decide whether $\chi_0(O(q_m))$ is not identical to zero. If the answer is yes, then the decision procedure terminates and returns the answer $true$. Otherwise, the decision procedure continues.

When decide whether $\chi_0(O(q_m))$ is not identical to zero, it is unsound to just consider the coefficients of $d^0_1,\dots,d^0_s$, since some of the data values may be integer constants as well. 

From the analysis, we know that 
\[
\begin{array}{l c l }
\chi_0(O(q_m)) & = & a_0 + a_1 \chi_0(x_1) + \dots + a_k \chi_0(x_k) + a'_1 \chi_0(y_1) + \dots a'_l \chi_0(y_l).\\
& = & (a_0+a'_1 c_{0,1} + \dots + a'_l c_{0,l}) + \sum \limits_{j \not \in rng(\pi_0)}  (a'_1 c_{j,1}+\dots + a'_l c_{j,l}) d^0_j+\\
& & \sum \limits_{j \in rng(\pi_0)} (a_{\pi_0^{-1}(j)}+ a'_1 c_{j,1}+\dots + a'_l c_{j,l}) d^0_j.
\end{array}
\]

From the guards and assignments of the transitions in the handle, we know that some of $d^0_1,\dots,d^0_s$ are just integer constants. Let $J_0 \subseteq \{1,\dots,s\}$ denote the subset of indices for these data values. For $d^0_j$ such that $j \not \in J_0$, we know that either $d^0_j < c_{\min}$ or $d^0_j > c_{\max}$, since the SNT is assumed to be normalized.

Then to decide whether $\chi_0(O(q_m))$ is identical to zero, we will first check whether the coefficient of $d^0_j$ in $\chi_0(O(q_m))$ for some $j \not \in J_0$ is non-zero. If this is the case, the return ``$true$''. Otherwise, $\chi_0(O(q_m))$ is in fact an integer constant, and we just check whether it is equal to zero. If it is not equal to zero, then return ``true''. Otherwise, we continue the procedure.

For $b=1,2$, we know that $\chi_{b,1}(y_j) = \alpha_{b,(j,0)} + \alpha_{b,(j,1)} o_j + \beta_{b,(j,1)} d^0_{\pi_0(1)} + \dots + \beta_{b,(j,k)} d^0_{\pi_0(k)} + \gamma_{b,(j,1)} d^1_1 +\dots + \gamma_{b,(j,r_b)} d^1_{r_b}$.

Moreover, from the guards and assignments in the transitions of the handle and $C_b$, we know that some of $d^0_{\pi_0(1)}, d^0_{\pi_0(k)}, d^1_1,\dots, d^1_{r_b}$ are integer constants. From this, we know that for the data values $d^0_1,\dots, d^0_s, d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$ introduced when traversing $C_b$ for $\ell_b$ times, which ones are integer constants.

\smallskip

\noindent {\bf Step II'}. For $\chi_{(b,\ell_b)}(O(q_m))$, we then do the analysis for the coefficient of $d^0_{\pi_0(j')}$ that is not a constant, similar to that in Step II.  Moreover, we consider the sum of the constant coefficient and all the components $c\ d^{i}_{j'}$ in  $\chi_{(b,\ell_b)}(O(q_m))$ such that $d^i_{j'}$ is a constant, and do the analysis for it, similar to that for the constant coefficient in Step II.

\smallskip

\noindent {\bf Step III'}. We will do the same analysis as in Step III.


\subsection{Generalized flat}

We will illustrate the argument by the following scenario:  
\begin{quote}
$q_0\dots q_{m} (C_1,\dots,C_n) q'_0 \dots q'_{m'} (C'_1,\dots,C'_{n'})$ is a path scheme of the transducer, where each pair of $C_1,\dots,C_n$ share the unique common state $q_m$, $q'_0 = q_m$, and each pair of $C'_1,\dots,C'_{n'}$ share the common state $q'_{m'}$. Moreover, $O(q'_{m'})$ is defined and $O(q)$ is undefined for all the other states $q$.
\end{quote}

For simplicity, we assume that $n = n' = 2$.

We will illustrate the argument for the situation that there are no comparisons with constants in the guards.

For the handle $q_0 \dots q_m$, we can obtain a mapping $\chi_0$ to describe the value of the control and data variables after traversing the handle. Suppose for each $j: 1 \le j \le l$,  $\chi_0(y_j) = c_{0,j} + c_{1,j} d^0_1 + \dots + c_{s,j} d^0_s$. Moreover, we assume that there is an injective mapping $\pi_0$ such that for each $j: 1 \le j \le k$, $\chi_0(x_j) = d^0_{\pi_0(j)}$.

Suppose that the mapping $\chi_{1,\ell_1}$ and $\chi_{2,\ell_2}$ to describe the values of the control and data variables after traversing the cycle $C_1$ and $C_2$ for $\ell_1$ and $\ell_2$ times are as in the analysis of generalized lasso above.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
 that is,
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)}(y_j)  & = & (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) + \alpha^{\ell_1}_{1,(j,1)} o_j + \\
& & \sum \limits_{j' \in J_{1,1}} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{1,2}} (\alpha^{\ell_1-1}_{1,(j,1)}\beta_{1,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')}) d^1_{j'} + \dots + \sum \limits_{j' \in J_{1,3}} (\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha_{1,(j,1)} \gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \gamma_{1,(j, 1)} d^{\ell_1}_{1} + \dots + \gamma_{1,(j,r_1)} d^{\ell_1}_{r_1},
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi_{(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)}) + \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{2,1}} (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{2,2}} (\alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+\\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{j'} +  \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{r_2}.
\end{array} 
\]
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Moreover, suppose the initial values of the control variables are $d'_1,\dots,d'_k$ and the initial values of the data variables are $o'_1,\dots,o'_l$, then for the handle $q'_0 \dots q'_{m'}$, let $\chi'_0$ be the mapping to describe the values of the control and data variables after traversing the handle, 
\[
\chi'_0(y_j) = c'_{0,j} + c'_{1,j} (d^0_1)' + \dots + c'_{s',j} (d^0_{s'})'+c''_{0,j} o'_j + c''_{1,j} d'_1 + \dots c''_{k,j} d'_k,
\] 
where $(d^0_1)' ,\dots, (d^0_{s'})'$ are the data values introduced when traversing the handle. Let $\pi'_0: \{1,\dots,k\} \rightarrow \{1,\dots,k+s'\}$ be an injective mapping such that $\chi'_0(x_j) = d'_{j}$ if $\pi'_0(j) \le j$ (in this case $\pi'_0(j)=j$), and $\chi'_0(x_j) = (d^0_{\pi'_0(j)-k})'$ otherwise.


Moreover, suppose $d''_1,\dots,d''_k$ are the initial values of the control variables and $o''_1,\dots,o''_l$ are the initial values of the data variables, then $\chi'_{1,\ell'_1}$ and $\chi'_{2,\ell'_2}$, which describe the values of the control and data variables after traversing the cycle $C'_1$ and $C'_2$ for $\ell_1$ and $\ell_2$ times respectively, are as follows, 
%
\[
\begin{array}{l c l}
\chi'_{(1,\ell'_1)}(y_j)  & = & (\alpha'_{1,(j,0)} + \alpha'_{1,(j,1)} \alpha'_{1,(j,0)}+ \dots +(\alpha'_{1,(j,1)})^{\ell'_1-1} \alpha'_{1,(j,0)}) + (\alpha'_{1,(j,1)})^{\ell'_1} o''_j + \\
& & \sum \limits_{j' \in J'_{1,1}} (\beta'_{1,(j,j')}+\alpha'_{1,(j,1)}\beta'_{1,(j,j')} + \dots +(\alpha'_{1,(j,1)})^{\ell'_1-1}  \beta'_{1,(j,j')}) d''_{j'} + \\
%
& & \sum \limits_{j' \in J'_{1,2}} ( (\alpha'_{1,(j,1)})^{\ell'_1-1} \beta'_{1,(j,j')}) d''_{j'} +  \sum \limits_{j' \in J'_{1,3}} ( (\alpha'_{1,(j,1)})^{\ell'_1-2} \beta'_{1,(j, \pi^{-1}(j'+k))}+\\
%
& &  (\alpha'_{1,(j,1)})^{\ell'_1-1} \gamma'_{1,(j,j')}) (d^1_{j'})' +  \sum \limits_{j' \in J'_{1,4}} ( (\alpha'_{1,(j,1)})^{\ell'_1-1} \gamma'_{1,(j,j')}) (d^1_{j'})' + \dots +  \\
%
& & \sum \limits_{j' \in J'_{1,3}} (\beta'_{1,(j, \pi^{-1}(j'+k))}+\alpha'_{1,(j,1)}\gamma'_{1,(j,j')}) (d^{\ell'_1-1}_{j'})' +\\
& & \sum \limits_{j' \in J'_{1,4}} (\alpha'_{1,(j,1)} \gamma'_{1,(j,j')}) (d^{\ell'_1-1}_{j'})' + \gamma'_{1,(j, 1)} (d^{\ell'_1}_{1})' + \dots + \gamma'_{1,(j,r_1)} (d^{\ell'_1}_{r'_1})',
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi'_{(2,\ell'_2)}(y_j)  & = & (\alpha'_{2,(j,0)} + \alpha'_{2,(j,1)} \alpha'_{2,(j,0)}+ \dots +(\alpha'_{2,(j,1)})^{\ell'_2-1} \alpha'_{2,(j,0)}) + (\alpha'_{2,(j,1)})^{\ell'_2} o''_j + \\
& & \sum \limits_{j' \in J'_{2,1}} (\beta'_{2,(j,j')}+\alpha'_{2,(j,1)}\beta'_{2,(j,j')} + \dots +(\alpha'_{2,(j,1)})^{\ell'_2-1}  \beta'_{2,(j,j')}) d''_{j'} + \\
%
& & \sum \limits_{j' \in J'_{2,2}} ( (\alpha'_{2,(j,1)})^{\ell'_2-1} \beta'_{2,(j,j')}) d''_{j'} +  \sum \limits_{j' \in J'_{2,3}} ( (\alpha'_{2,(j,1)})^{\ell'_2-2} \beta'_{2,(j, \pi^{-1}(j'+k))}+\\
%
& &  (\alpha'_{2,(j,1)})^{\ell'_2-1} \gamma'_{2,(j,j')}) (d^2_{j'})' +  \sum \limits_{j' \in J'_{2,4}} ( (\alpha'_{2,(j,1)})^{\ell'_2-1} \gamma'_{2,(j,j')}) (d^2_{j'})' + \dots +  \\
%
& & \sum \limits_{j' \in J'_{2,3}} (\beta'_{2,(j, \pi^{-1}(j'+k))}+\alpha'_{2,(j,1)}\gamma'_{2,(j,j')}) (d^{\ell'_2-1}_{j'})' +\\
& & \sum \limits_{j' \in J'_{2,4}} (\alpha'_{2,(j,1)} \gamma'_{2,(j,j')}) (d^{\ell'_2-1}_{j'})' + \gamma'_{2,(j, 1)} (d^{\ell'_2}_{1})' + \dots + \gamma'_{2,(j,r_1)} (d^{\ell'_2}_{r'_2})'.
\end{array} 
\]

\noindent {\bf Step I''}. We can do the same analysis for the handle $q_0 \dots q_m$ as for generalized lasso.

\smallskip 
\noindent {\bf Step II''}. Let $\chi$ Consider
\[
\begin{array}{l c l}
\chi'_{0}(O(q'_{m'})) & = & a_0 + a_1 \chi'_0(x_1) + \dots a_k \chi'_0(x_k) + \\
& & a'_1 \chi'_0(y_1) + \dots + a'_l \chi'_0(y_l) \\
&  = &  (a_0+\sum \limits_{1 \le j \le l} a'_j c'_{0,j}) + \sum \limits_{\pi'_0(j)=j} (a_j + \sum \limits_{1 \le j' \le l} a'_{j'} c''_{j,j'}) d'_j  + \\
& & \sum \limits_{\pi'_0(j) \neq j} \sum \limits_{1 \le j' \le l} (a'_{j'} c''_{j,j'}) d'_j + \sum \limits_{1\le j \le l} (a'_{j} c''_{0,j}) o'_j + \\
& & \sum \limits_{1 \le j \le s', j \in rng(\pi'_0)} (\sum \limits_{1 \le j' \le l} (a_{(\pi'_0)^{-1}(j)} + a'_{j'} c'_{j,j'})) (d^0_j)' +\\ & & \dots  + \sum \limits_{1 \le j \le s', j \not \in rng(\pi'_0)} (\sum \limits_{1 \le j' \le l} (a'_{j'} c'_{j,j'})) (d^0_j)'.
\end{array}
\] 

Then we can think $q_m$ as a state with the output expression $O(q_m)=\chi'_{0}(O(q'_{m'}))$, where $d'_1,\dots,d'_k, o'_1,\dots, o'_l$ denote the values of the control and data variables. 

Let $a''_0$ be the constant coefficient of $\chi'_{0}(O(q'_{m'}))$, $a''_1,\dots,a''_k,a'''_1,\dots,a'''_l$ be the coefficient of $d'_1,\dots,d'_k,o'_1,\dots,o'_l$ of $\chi'_{0}(O(q'_{m'}))$ respectively.

Similarly to the analysis of generalized lassos, $\chi_{(b,\ell_b)}(O(q_m))$ is a linear combination of the variables $d^0_1,\dots, d^0_s$ and $d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$. For each $j' \in J_{b,1}$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{(b,\ell_b)}(O(q_m))$ is 
%
\[a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\beta_{b,(j,j')}.\]
%

In general, for each $j' \in J_{1,1}$ and each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$) of $(C_1,C_2)$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \ \ \  (\ast')\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast')$ is of the form 
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j  s_j (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')},\]
where $s_j \in \{0,+1,-1\}$.

The expression $(\ast')$ can be rewritten as $\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')}$ for some integer constant $\mu_{\schm,(1,j')},\nu_{\schm,(1,j')}$ (possibly $\mu_{\schm,(1,j')}=0$). 

If $\mu_{\schm,(1,j')} \neq 0$, then return ``$true$''. 

Otherwise, for each cycle scheme $\schm'=(1,\ell'_1)(2,\ell'_2) \dots (1+(t'-1) \bmod 2,\ell'_{t'})$ (where $t' \ge 1$) of $(C'_1,C'_2)$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm (q'_0 \dots q'_{m'})\schm'}(O(q'_{m'}))$ includes the following expression as a component,
\[
\begin{array}{l c l}
a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)} (\alpha'_{1,(j,1)})^{\ell'_{1}} (\alpha'_{2,(j,1)})^{\ell'_{2}} \dots (\alpha'_{1,(j,1)})^{\ell'_{t'}}) \\
\hspace{16mm} (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \hspace{2cm}. (\ast'')
\end{array}
\]

The a similar analysis can be applied to $(\ast'')$ by considering all the cycle shcemes of $(C'_1,C'_2)$.

Moreover, we can apply a similar analysis for the cycle $C'_1,C'_2$ as for $C_1,C_2$, by using the output expressions $O(q'_{m'})$.

If the procedure does not return yet, then we go to Step III''.

\smallskip

\noindent {\bf Step III''}. Similar to Step III, for the path scheme, we can simulate the updates of the coefficients of the data values for the data variables as well as the output expression by a $\intnum$-VAS.

\section{Case Studies}
\section{Discussions}

From the analysis of the commutativity of reducers in \cite{XZZ+14}, the commutativity of a reducer in a sequential composition oa map-reduce jobs may depend on some implicit data properties guaranteed by the preceding map-reduce jobs. Therefore, to analyze the commutativity of a reducer in a sequential composition of map-reduce jobs, we may need model both mappers and reducers and do a backward analysis.

\bibliographystyle{abbrv}
\bibliography{data}


\begin{appendix}



\end{appendix}

\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



