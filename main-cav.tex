\documentclass[runningheads,a4paper]{llncs}

\usepackage{latexsym}
\usepackage{setspace}
\usepackage{cancel}

\usepackage{graphicx}
\usepackage{appendix}
\usepackage{amssymb}
%\usepackage{dsfont}
\usepackage{amsmath}
%\usepackage{amsthm}
%\usepackage{cancel}
%\usepackage{verbatim}
%\usepackage{chngpage}
%\usepackage{fullpage}

\usepackage{color}

\usepackage{mathrsfs}

%\newtheorem{definition}{Definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{example}{Example}
%\newtheorem{question}{Open Question}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{Algo}{Algorithm}
%\newtheorem{remark}[theorem]{Remark}

\def\arr#1{\stackrel{#1}{\longrightarrow}}

\def\Aa{{\mathscr{A} }}

\def\Bb{{\mathscr{B} }}

\def\Cc{{\mathscr{C} }}

\def\Dd{{\mathbb{D} }}

\def\Ee{{\mathcal{E} }}

\def\Ff{{\mathcal{F} }}

\def\Zz{{\mathcal{Z} }}

\def\Nn{{\mathbb{N} }}

\def\Ss{{\mathcal{S} }}

\def\Tt{{\mathcal{T} }}

\def\Ii{{\mathbb{Z} }}

\def\Jj{{\mathcal{J}}}

\def\Vv{{\mathcal{V}}}

\def\Rr{{\mathcal{R} }}

\def\Ll{{\mathcal{L}}}


\def\treeset{{\mathscr{T}}}

\def\contextset{{\mathcal{C}}}

\def\theory{{\mathcal{L}}}

\def\termset{{\mathcal{T}}}

\def\formulaset{{\mathcal{F}}}

\newcommand\univ{\mathsf{Univ}}

\newcommand\op{\mathfrak{o}}

\newcommand\dv{\mathtt{x}}

\newcommand\ydv{\mathtt{y}}

\newcommand\cv{\mathtt{z}}

\newcommand\thla{\mathcal{LIA}}

\newcommand\thdif{\mathcal{DIF}}

\newcommand\thord{\mathcal{ORD}}

\newcommand\thset{\mathcal{SET}}

\newcommand\thmset{\mathcal{MUS}}

\newcommand\natnum{{\mathbb{N} }}

\newcommand\intnum{{\mathbb{Z} }}

\newcommand{\hide}[1]{}
\newcommand{\yfc}[1]{\color{blue} {YF: #1 :FY} \color{black}}
\newcommand{\zhilin}[1]{\color{cyan} {ZL: #1 :LZ} \color{black}}
\newcommand{\lei}[1]{\color{green} {LE: #1 :EL} \color{black}}
\newcommand{\SDSIT}{SDSIT}
\newcommand{\Name}{Streaming data string to integer transducer}
\newcommand{\name}{streaming data string to integer transducer}
%\def\Ss{{$\mathcal{A}$\ }}

\title{The~Commutativity~Problem~of~the~Map-Reduce Framework: A Transducer-based Approach}
%\title{Deciding Commutative of Reducers}
\author{}
\institute{}

%\author{Yu-Fang Chen, Lei Song, Zhilin Wu}

\begin{document}

\maketitle

\begin{abstract}

Map-Reduce is a popular programming model for data parallel computation. 
In Map-Reduce, the \emph{reducer} produces an output from a list of inputs. Due the scheduling policy and the settings of machines, the input may arrive the reducers with different orders. The \emph{communtative problem} of reducers asks if the output of a reducer independent of the order of its inputs. The problem is in general undecidable due to Rice's theorem and thus is seemingly uninteresting. However, the Map-Reduce model is usually used for data analytics and thus requires very simple data and control flow. 
By exploiting the simplicity of the required program flows, we propose a commutative decidable language for reducers.
We show that the language is expressive enough for common data analytics operations.
\end{abstract}

\section{Introduction}
%What is Map-Reduce
Map-Reduce is a very popular framework for data parallel computation. It has been adopt in various widely used cloud computing frameworks such as Hadoop~\cite{Hadoop} and Spark~\cite{Spark}. In a typical Map-Reduce program, a \emph{mapper} takes a key-value pair as input and output a list of key-value pairs. The load balance mechanism of the Map-Reduce framework will process the key-value pairs and sends the pairs with the same key to the same \emph{reducer}, in the form of the key and a list of values. The reducer reads the input list and output a key-value pair.



%The communitativity problem

%The reason for studying syntatical restrictions 

%data analytics

%At a first glance, the commutativity problem for arbitrary reducers appears to be un- decidable by the Riceâ€™s theorem. Yet reducers are seldom Turing machines in practice. Most real-world reducers simply iterate through their input list and compute their out- puts; they do not have complicated control or data flows. Therefore, one wonders if the commutativity problem for such reducers can be decided for practical purposes.

\cite{CHSW15}

\section{Preliminaries}

Let $\Ii$ denote the set of integers. Let $X$ denote a finite set of variables ranging over $\Ii$ and $x,y$ are variables in $X$. Then a guard over $X$ is the formulae defined by the rules, $g::= x = y \mid x < y \mid g \vee g \mid \neg g$. Let $Y$ be another set of variables over $\Ii$. An arithmetic expression over $Y$ is defined by the rules, $e::= y \mid c \mid e + e \mid e-e \mid e * e \mid e / e$, where $y \in Y$ and $c$ is a constant over $\Ii$. Let $\Ee_Y$ denote the set of arithmetic expressions over $Y$. An assignment $\eta$ for $Y$ with respect to $X$ is a partial function from $Y$ to $\Ee_{X \cup Y}$, the set of arithmetic expressions over $X \cup Y$.

A data string is a sequences of vectors of data values, that is, sequences $\vec{d}_1\vec{d}_1\dots \vec{d}_n$, where $\vec{d}_i \in \Ii^+$.

A (deterministic) streaming data string to integer transducer (SDSIT) $\Ss$ is a tuple $(Q, K, X, Y, \delta, q_0, O)$ such that 
\begin{itemize}
\item $Q$ is a finite set of states,
\item $K \in \Nn$ is the maximum number of data values in each position, 
\item $X$ is a finite set of data variables which is used to store some data values that have been met,
\item $Y$ is a finite set of output variables, which is used to aggregate some information for the output,
\item $\delta$ comprises the tuples $(q, k, g, \eta, q')$, where $q,q'\in Q $, $1 \le k \le K$ is the number of data values in the current position, $g$ is a guard over $X \cup \{p_1,\dots,p_k\}$ ($p_1,\dots,p_k$ denote the $k$ data values in the current position), $\eta$ is (1) an assignment for $Y$ with respect to $\Ee_{X \cup Y}$ or (2) an assignment for $X$ with respect to $X \cup \{p_1,\dots,p_k\}$, 
%\zhilin{I am wondering whether we should add constraints e.g. $p_1 > 5$, which is not available in the original definition of streaming transducer}\lei{Constraints like $x > p_1$ is also not allowed? For me, it makes more sense to include such constraints.}
\item $q_0 \in Q$ is the initial state,
\item $O$ is the output function, which is a partial function from $Q$ to $(X \cup Y)^{\le K}$.
\end{itemize}
It is required that the following constraints are satisfied: 
\begin{description}
\item[1 (copyless).] For each $q \in Q$ and $y \in Y$, there is at most one occurrence of $y$ in $O(q)$, moreover, for each $(q,k, g, \eta, q') \in \delta$ and each $y \in Y$, $y$ appears at most once in the collection of expressions $\{\eta(y') \mid y' \in Y\}$; 
\item [2 (deterministic).] For every pair of distinct tuples $(q,k, g_1, \eta_1,q'_1), (q, k, g_2,\eta_2,q'_2) \in \delta$, it holds that $g_1$ and $g_2$ are mutually exclusive, that is, $g_1 \wedge g_2$ is unsatisfiable.
\end{description}
Note that the ``copyless'' constraint forbids the use of the expressions of the form $y+y$ in the output expressions or in the assignments.

The semantics of a \SDSIT $\Ss$  is given by a transduction as follows: A configuration of $\Ss$ is a pair $(q,\beta)$, where $q \in Q$ and $\beta$ is a valuation of $X \cup Y$, that is, a partial function from $X \cup Y$ to $\Ii$. When reading a data string $w=\vec{d}_1 \dots \vec{d}_n$, $\Ss$ runs over $w$ from left to right. Let $(q, \beta)$ be the configuration of $\Ss$ reached after running over $w$, then the output of $\Ss$ is $\beta(O(q))$, if $O(q)$ is defined, and the output is undefined otherwise. \zhilin{Formal semantics to be written}

\zhilin{To model reducers in the MapReduce framework, we may assume that the first element in a data string is a single data value which is a key.}

\begin{example}[Max, average]
The max transducer over sequences of integers is given by the transitions $(q_0, 1, x < p_1, x:=p_1, q_0)$, where $x:= p_1$ assigns $p_1$ to $x$, and $(q_0, 1, x \ge p_1 , \emptyset, q_0)$, and the output function $O(q_0)=x$. The average transducer over sequences of integers is given by the transition $(q_0, 1, true, (sum:=sum + p_1, len := len +1), q_0)$, and $O(q_0)=sum / len$. 
\end{example}

\begin{example}[Example inspired by Pagerank]
The following transducer sum all the data values, except the last position, then it outputs a concatenation of the sum and the last tuple: $(q_0, 1, true, sum:= sum + p_1, q_0)$, $(q_0, k, true, (x_i:=p_i)_{1 \le i \le k}, q_1)$, $O(q_1)=(sum, x_1,\dots, x_k)$.
\end{example}
\hide{
\yfc{can we describe the following Triangle-counting algorithm using the model?}
\zhilin{Could you describe how to implement the algorithm in MapReduce framework?}
\yfc{this is based on the sample code in Spark, I found antoher sample code in Hadoop, maybe fits the model better, check https://github.com/vertica/Graph-Analytics----Triangle-Counting/blob/master/src/com/vertica/mr/graphs/TriangleCounter.java}

\zhilin{I will describe my understanding of the algorithm in the following} 

The task comprises of three MapReduce jobs. 
\begin{description}
\item[Job1] Map: Filter out the pairs $(v1,v2)$ such that $v1 > v2$. Reduce: on the input $(v, w_1 \dots w_k)$ (where $v < w_i$ for each $i$), output the list $((v,w_1),0), \dots, ((v,w_k),0), ((w_1,w_2),1), \dots, ((w_{k-1},w_k),1)$.
\item[Job2] Map: Identity function. Reduce: on the input $((v1,v2),i_1 ... i_k)$, if $i_j=0$ for some $j$, then output $(1, i_1+...i_k)$, otherwise, output $(1,0)$.
\item[Job3] Map: Identity function. Reduce: on the input $(1,n_1 \dots n_k)$, ouput $((n_1+\dots + n_k),null)$.
\end{description}

\zhilin{The most challenging one is Job1. The reducer in Job1 need output each distinct pair $((w_i, w_j),1)$ for a list $w_1 \dots w_n$. For this transduction, at first we need extend the transducer to output a list of $(key, value)$ pairs, instead of a single $(key,value)$ pair. Moreover, the relatively complex transduction from lists to lists seems exceeding the capability of streaming transducers.}

\newcommand{\numTri}[1]{\triangle_{#1}}
Let $G = (V, E)$ be an undirected graph without self-loops or multiple
edges. For $u, v \in V$, $\{ u, v \} \in E$ denotes that $u$ and $v$
are adjacent. A  \emph{triangle} in $G$ is formed by $u, v, w \in V$ with $\{ u, v \},
\{ u, w \}, \{ v, w \} \in E$. 
We want to count the number of triangles in a given graph.

Suppose that the graph is described as a list of edges.

For each edge $\{ u, v \} \in E$, the algorithm sends the sets $\{ u \}$
and $\{ v \}$ to $v$ and $u$ respectively. If several messages are
sent to a vertex, they are merged by unions.
\yfc{So maybe we need to also support the data type ``set''}

After this operation, we get a list of pairs $(u, U)$, where $u \in V$ and $U$ is the set $\{ v : \{ u, v \} \in E \}$.

Then for each edge $\{ u, w \} \in E$, again we send the size of the set $| U \cap W |$ to both $u$ and $w$, where $U$ and $W$ are
the set of vertices adjacent to $u$ and $v$ respectively. 
\yfc{This is difficult in our model. We need to first traverse E (the first input list) and then get the corresponding set U and W from the 2nd list. Then count the size of their intersection. Maybe can be implemented in a slightly different way.}

Observe that for every $s \in U \cap W$, we have $\{ s, u \}, \{ s, w \}, \{ u, w
\} \in E$. Let $\numTri{\{u, v\}}$ denote the number of triangles
containing the edge $\{ u, w \}$. Then $\numTri{\{u, w\}}$ is sent to
both $u$ and $w$. If several messages are sent to $w$, they are merged
by summation. After this operation we get a list of pairs $(u, \sum_{\{ u, w \} \in E} \numTri{\{u, w\}})$.

Now consider a vertex $v$ in a triangle of $u, v, w$. The triangle is
counted in both $\numTri{\{ u, v \}}$ and $\numTri{\{ w, v \}}$. Hence
we need to divide the the number by 2 to get the number of triangles containing $v$. }


\section{Closure properties}

Boolean operations.

Union, intersection, complement

composition: It seems that \SDSIT are not closed under composition, similar to that of streaming transducers.

\section{Decision problems}

equivalence, commutativity.

Cost register automata may be relevant \cite{ADD+13}. 
\yfc{The paper assumes finite input alphabet}

Let us start with the following simple model, called \SDSIT$_{\pm}$, where the assignment expressions used in assignments are defined by the rules $e::= y \mid e+e \mid e - e$. Note that only $+,-$ are used here and constants are forbidden. Moreover, without loss of generality, we assume that for a \SDSIT$_{\pm}$, it only ouputs a single integer (instead of a tuple of integers).

\begin{proposition}
From two \SDSIT$_{\pm}$ $\Aa,\Bb$, a \SDSIT$_{\pm}$ $\Cc$ can be constructed in polynomial time such that $\Aa$ is not equivalent to $\Bb$ iff there is a data word $w$ such that the output of $\Cc$ over $w$ is nonzero. 
\end{proposition}

Therefore, the equivalence problem of \SDSIT$_{\pm}$ is reduced to the problem whether another \SDSIT$_{\pm}$ can produce a non-zero output.

\medskip

\noindent {\bf NON-ZERO OUTPUT PROBLEM}: Given a \SDSIT$_{\pm}$ $\Aa$, decide whether there is a data word $w$ such that the output of $\Aa$ over $w$ is non-zero. 


To even simplify the problem, we may start with the flat \SDSIT$_{\pm}$, where there are no nested-loops in the transition structure, aka flat counter automata.

\noindent {\bf Reduction of commutativity to equivalence of \SDSIT}.

Consider the permutation $\tau_2$ and $\tau_n$ in \cite{CHSW15}. We can define two streaming transducers $\Ss$ and $\Ss'$ (note that $\Ss'$ is independent from $n$)  for $\tau_2$ and $\tau_n$.

Then the commutativity of a given \SDSIT $\Tt$ is reduced to the equivalence of $\Tt$ and $\Ss \circ \Tt$ as well as the equivalence of $\Tt$ and $\Ss'\circ \Tt$. Note that an equivalent \SDSIT can be defined for $\Ss \circ \Tt$ and $\Ss' \circ \Tt$ respectively. Therefore, we get the following result.

\begin{proposition}
The commutativity of \SDSIT is reduced to the equivalence of \SDSIT in linear time.
\end{proposition}

We then focus on the equivalence problem of generalized flat SDSIT$_{\pm}$.

A SDSIT$_{\pm}$ is called \emph{generalized flat} if each nontrivial SCC (strongly-connected component) of the transition graph is a collection of edge-disjoint simple cycles such that there is a unique state which is shared by each pair of distinct cycles in the collection.

Let $\Ss_1$ and $\Ss_2$ be two generalized flat SDSIT$_{\pm}$.

\begin{proposition}\label{prop-equiv-reduce}
The equivalence problem of two generalized flat SDSIT$_{\pm}$ be reduced to the non-zero output problem of a generalized flat SDSIT$_{\pm}$.
\end{proposition}

%Suppose $\Ss_1=(Q_1, K, X_1, Y_1, \delta_1, q_{0,1}, O_1)$ and $\Ss_1=(Q_2, K, X_2, Y_2, \delta_2, q_{0,2}, O_2)$ are two generalized flat SDSIT$_{\pm}$. Without loss of generality, we assume that the state spaces (resp. the set of data variables, the set of output variables) of $\Ss_1$ and $\Ss_2$ are disjoint. Moreover, the SDSIT$_{\pm}$ $\Ss$ constructed from $\Ss_1$ and $\SS_2$ (cf. Proposition~\ref{prop-equiv-reduce}), satisfies the following property: 
%\begin{quote}
%\it the output variables in $Y_1$ are updated independently of those in $Y_2$: For each transition $((q_1,q_2),g,\eta,(q'_1,q'_2))$ in $\Ss$, for each $y_1 \in Y_1$(resp. $y_2 \in Y_2$), no variables from $Y_2$ (resp. $Y_1$) occurs in $\eta(y_1)$ (resp. $\eta(Y_2)$). \hfill ($\ast$)
%\end{quote}

%In the rest of this paper, we will assume that the SDSIT$_{\pm}$ $\Ss$ in the non-zero reachability problem satisfies that the set of output variables of $\Ss$ is $Y_1 \uplus Y_2$ and $Y_1,Y_2$ satisfy the constraint $(\ast)$.

For simplicity, from now on, we assume that $K=1$, that is, there is at most one data value over each position, and we will omit the number $K$ in the definition of SDSIT$_{\pm}$.


Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a generalized flat SDSIT$_{\pm}$.  Suppose $X=\{x_1,\dots,x_k\}$ and $Y=\{y_1,\dots,y_l\}$. In addition, we assume that all the output variables are \emph{independently evolving} in the sense that for each transition $(q, g, \eta, q')$, it holds that for each $y \in Y$, only $y$ can occur in $\eta(y)$ and no other output variables can occur in $\eta(y)$.  

From now on, we assume that all generalized flat SDSIT$_{\pm}$ considered in this paper satisfy the  ``independently evolving'' constraint. Moreover, recall that we assume that for each transition $(q,g,\eta,q')$, 
\begin{itemize}
\item $g$ is of the form $cur\ o\ x $, where $cur$ denote the current data value, $x \in X$,  and $o \in \{=,\neq,<, \le, >, \ge\}$,
%
\item for each $x \in X$, if $\eta(x)$ is defined, then $\eta(x)=cur$ and  $g$ is not of the form $cur = x'$ with $x' \in X$. 
\end{itemize}

%$c \in \intnum$,  or $cur\ o\ c$

%In the following, we focus on the non-zero reachability problem of generalized flat SDSIT$_{\pm}$ such that $|Y_1| = |Y_2|=1$. The more general case is open. \zhilin{See appendix for an incomplete analysis of a lasso in the general case}

We start the analysis with paths and cycles.

\subsection{Paths and cycles}

Suppose that $q_0 \xrightarrow{(g_1,\eta_1)} q_1 \dots q_{n-1} \xrightarrow{(g_n, \eta_n)} q_n$ is a path in $\Ss$. Suppose that the initial values of $x_1,\dots, x_k$ and $y_1,\dots, y_l$ are $d_1,\dots, d_k$ and $o_1,\dots,o_l$ respectively. Moreover, let $d_{k+1},\dots,d_{k+n}$ denote the $n$ data values in the path. Then the guards and the assignments in the path induce an equivalence relation $\sim$ on $\{1,\dots, k+n\}$ so that  $i \sim j$ iff it can be inferred from the guards and assignments that $d_i = d_j$. Since all the guards are of the form $cur\ o\ x_j$ for $x_j \in X$, we know that for each pair of indices $i,j: 1 \le i < j \le k+n$ such that $i \sim j$, it holds that $j \ge k+1$. Let $I_1,\dots, I_r$ be an enumeration of the equivalence classes of $\sim$ on $\{1,\dots,k+n\}$ such that $\min(I_1) < \dots < \min(I_r)$. Then we know that $r \ge k$ and for each $j: 1 \le j \le k$, it holds that $\min(I_j)=j$.

From the path, an assignment function $\chi$ with the domain $X \cup Y$ can be defined to describe the values of the data and output variables after traversing the path, such that 
\begin{itemize}
\item for each $x_j \in X$, $\chi(x_j) \in \{d_{\min(I_1)}, \dots, d_{\min(I_r)}\}$, 
\item and for each $y_j \in Y$, $\chi(y_j) = \alpha_{j,0} + \alpha_{j,1} o_j + \beta_{j,1} d_{\min(I_1)} + \dots + \beta_{j,r} d_{\min(I_r)}$ for some constants $\alpha_{j,0},\alpha_{j,1}, \beta_{j,1},\dots,\beta_{j,r}$ such that $\alpha_{j,1} \in \{0,+1,-1\}$ (as a result of the ``copyless'' and ``independently evolving'' constraint).
\end{itemize}

Next we consider cycles. Let $C = q_0 \xrightarrow{(g_1,\eta_1)} q_1 \dots q_{n-1} \xrightarrow{(g_n, \eta_n)} q_n$ be a path in $\Ss$ such that $q_n = q_0$.

Then similar to the analysis of the paths above, an assignment function $\chi_1$ with the domain $X \cup Y$ can be defined to describe the values of the data and output variables after traversing the cycle for the first time,
\begin{itemize}
\item for each $x_j \in X$, $\chi_1(x_j) \in \{d_{\min(I_1)}, \dots, d_{\min(I_r)}\}$, 
\item and for each $y_j \in Y$, $\chi_1(y_j) = \alpha_{j,0} + \alpha_{j,1} o_j + \beta_{j,1} d^1_{\min(I_1)} + \dots + \beta_{j,r} d^1_{\min(I_r)}$ for some constants $\alpha_{j,0},\alpha_{j,1}, \beta_{j,1},\dots,\beta_{j,r}$ such that $\alpha_{j,1} \in \{0,+1,-1\}$.
\end{itemize}

\begin{lemma}
If the cycle can be traversed once with some initial values for data and output variables, then it can also be executed twice with the same initial values.
\end{lemma}

We define a graph $G_C$ as follows.
\begin{itemize}
\item The set of vertices is $\{1, \dots, k\}$.
%
\item The set of arcs is defined by the rules: 
%\begin{itemize}
%\item 
For each $x_j \in X$ such that $\chi_1(x_j) = d_{\min(I_s)}$ and $1\le \min(I_s) \le k$, add an arc $(\min(I_s), j)$.
%
%\item 
%For each pair of distinct indices $s,s'$, if the guards and assignments of the cycle imply that $d_{\min(I_s)} \neq d_{\min(I_{s'})}$, then add an arc $(\min(I_s), neq, \min(I_{s'}))$.
%\end{itemize}
\end{itemize}

As a result of the constraints on the guards and assignments, we have the following result.

\begin{proposition}
The in-degree of out-degree of each vertex in $G_C$ is at most one.
\end{proposition}

\begin{proof}
It is easy to observe that the in-degree of each vertex is at most one. When the current data value is stored into some data variable, the data value is not required to be equal to that stored in some other data variable. Therefore, the value of a data variable cannot be copied to some other data variable. From this, we deduce that the out-degree of each vertex is at most one.
\end{proof}

From the proposition, we know that each connected component of $G_C$ is either a single cycle, or a single path.

Let $N$ be the least natural number satisfying the following conditions: $N$ is a common multiple of the length of all the cycles in $G_C$ and $N$ is no less than the length of all the simple paths in $G_C$.

\smallskip

The idea: It is sufficient to traverse the loop at most $N$ times.

We illustrate the argument for this fact with the following example: There are six data variables, $x_1,\dots,x_5$ such that  $G_C$ comprises a cycle $x_1x_2x_3$ and a path $x_4 x_5$. Without loss of generality, we assume that $\chi_1(x_4)=d^1_{\min(I_6)}=d^1_6$. We will show that it is sufficient to traverse the loop for three times.

Let $\chi_2$ be the assignment function that describes the values of the data and output variables after traversing the loop twice. Then for each $j: 1 \le j \le k$, $\chi_2(x_j)=d^2_j$, and for each $j: 1 \le j \le l$, 
\[\chi_2(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_1(y_j) + \beta_{j,1} d^2_{\min(I_1)} + \dots + \beta_{j,r} d^2_{\min(I_r)},\]
where $d^2_{\min(I_1)}=d^2_1 = \chi_1(x_3)=d^1_3$, $d^2_{\min(I_2)}=d^2_2 = \chi_1(x_1)=d^1_1$, $d^2_{\min(I_3)}=d^2_3 = \chi_1(x_2)=d^1_2$, $d^2_{\min(I_4)}=d^2_4 = d^1_{\min(I_6)}=d^1_6$, and $d^2_{\min(I_5)}=\chi_1(x_4)=d^1_4$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_1(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_2(y_j) & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + \alpha^2_{j,1} o_j + (\alpha_{j,1} \beta_{j,1}) d^1_{\min(I_1)} +  \dots + (\alpha_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
& &  \beta_{j,1} d^1_3 + \beta_{j,2} d^1_1 + \beta_{j,3} d^1_2 + \beta_{j,4} d^1_6 + \beta_{j,5} d^1_4 + \beta_{j,6} d^2_{\min(I_6)} + \dots + \beta_{j,r} d^2_{\min(I_r)}\\
& = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + (\alpha_{j,1})^2 o_j + (\alpha_{j,1} \beta_{j,1} + \beta_{j,2}) d^1_1 + (\alpha_{j,1}\beta_{j,2}+\beta_{j,3})d^1_2+\\
& & (\alpha_{j,1}\beta_{j,3}+\beta_{j,1})d^1_3 +  (\alpha_{j,1}\beta_{j,4}+\beta_{j,5})d^1_4 + (\alpha_{j,1}\beta_{j,5})d^1_5 + (\alpha_{j,1}\beta_{j,6}+\beta_{j,4})d^1_6 + \\
& & (\alpha_{j,1}\beta_{j,7}) d^1_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^1_{\min(I_r)} + \beta_{j,6} d^2_{\min(I_6)} + \dots + \beta_{j,r} d^2_{\min(I_r)}.
\end{array}
\] 

Let $\chi_3$ be the assignment function that describes the values of the data and output variables after traversing the loop for the third time. Then for each $j: 1 \le j \le k$, $\chi_3(x_j)=d^3_j$, and for each $j: 1 \le j \le l$, 
\[\chi_3(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_2(y_j) + \beta_{j,1} d^3_{\min(I_1)} + \dots + \beta_{j,r} d^3_{\min(I_r)},\]
where $d^3_{\min(I_1)}=d^3_1 = \chi_2(x_3)=d^2_3=d^1_2$, $d^3_{\min(I_2)}=d^3_2 = \chi_2(x_1)=d^2_1=d^1_3$, $d^3_{\min(I_3)}=d^3_3 = \chi_2(x_2)=d^2_2=d^1_1$, $d^3_{\min(I_4)}=d^3_4 = d^2_{\min(I_6)}=d^2_6$, and $d^3_{\min(I_5)}=\chi_2(x_4)=d^2_4=d^1_6$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_2(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_3(y_j) & = & 
%
%(\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}) + (\alpha_{j,1})^3 o_j + (\alpha^2_{j,1} \beta_{j,1}) d^1_{\min(I_1)} +  \dots + (\alpha^2_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
%& &  (\alpha_{j,1}\beta_{j,1}) d^1_3 + (\alpha_{j,1}\beta_{j,2}) d^1_1 + (\alpha_{j,1}\beta_{j,3}) d^1_2 + (\alpha_{j,1}\beta_{j,4}) d^1_6 + (\alpha_{j,1}\beta_{j,5}) d^1_4 + \\
%& & (\alpha_{j,1}\beta_{j,6}) d^2_{\min(I_6)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+\beta_{j,1} d^1_2 + \beta_{j,2}  d^1_3 + \beta_{j,3} d^1_1 + \beta_{j,4} d^2_6 + \\
%& & \beta_{j,5} d^1_6 + \beta_{j,6} d^3_{\min(I_6)} + \dots + \beta_{j,r} d^3_{\min(I_r)}\\
%
%& = & 
(\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}) + \alpha^3_{j,1} o_j + (\alpha^2_{j,1} \beta_{j,1}+ \alpha_{j,1}\beta_{j,2} + \beta_{j,3} ) d^1_1 + \\
& & (\alpha^2_{j,1} \beta_{j,2}+\alpha_{j,1}\beta_{j,3} + \beta_{j,1} ) d^1_2 + (\alpha^2_{j,1} \beta_{j,3} + \alpha_{j,1}\beta_{j,1} + \beta_{j,2}  ) d^1_3 + (\alpha^2_{j,1} \beta_{j,4}+\alpha_{j,1}\beta_{j,5}) d^1_4 +\\
& & (\alpha^2_{j,1} \beta_{j,5}) d^1_5 + (\alpha^2_{j,1} \beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5})d^1_6 + (\alpha^2_{j,1} \beta_{j,7}) d^1_{\min(I_7)}+ \dots + (\alpha^2_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
& & (\alpha_{j,1}\beta_{j,6}+\beta_{j,4}) d^2_{6} + (\alpha_{j,1}\beta_{j,7}) d^2_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+  \\
& &  \beta_{j,6} d^3_{\min(I_6)} + \dots + \beta_{j,r} d^3_{\min(I_r)}.
\end{array}
\] 

Let $\chi_4$ be the assignment function that describes the values of the data and output variables after traversing the loop for the third time. Then for each $j: 1 \le j \le k$, $\chi_4(x_j)=d^4_j$, and for each $j: 1 \le j \le l$, 
\[\chi_4(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_3(y_j) + \beta_{j,1} d^4_{\min(I_1)} + \dots + \beta_{j,r} d^4_{\min(I_r)},\]
where $d^4_{\min(I_1)}=d^4_1 = \chi_3(x_3)=d^3_3=d^1_1$, $d^4_{\min(I_2)}=d^4_2 = \chi_3(x_1)=d^3_1=d^1_2$, $d^4_{\min(I_3)}=d^4_3 = \chi_3(x_2)=d^3_2=d^1_3$, $d^4_{\min(I_4)}=d^4_4 = d^3_{\min(I_6)}=d^3_6$, and $d^4_{\min(I_5)}=\chi_3(x_4)=d^3_4=d^2_6$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_3(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_4(y_j) & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}+\alpha^3_{j,1} \alpha_{j,0}) + \alpha^4_{j,1}  o_j + (\alpha^3_{j,1} \beta_{j,1}+ \alpha^2_{j,1}\beta_{j,2} + \alpha_{j,1}\beta_{j,3} + \beta_{j,1}) d^1_1 + \\
& & (\alpha^3_{j,1} \beta_{j,2}+\alpha^2_{j,1}\beta_{j,3} + \alpha_{j,1}\beta_{j,1} + \beta_{j,2}) d^1_2 + (\alpha^3_{j,1} \beta_{j,3} + \alpha^2_{j,1}\beta_{j,1} + \alpha_{j,1}\beta_{j,2} +\beta_{j,3}) d^1_3 + \\
& & (\alpha^3_{j,1} \beta_{j,4}+\alpha^2_{j,1}\beta_{j,5}) d^1_4 + (\alpha^3_{j,1} \beta_{j,5}) d^1_5 + (\alpha^3_{j,1} \beta_{j,6}+\alpha^2_{j,1}\beta_{j,4}+\alpha_{j,1}\beta_{j,5})d^1_6 + \\
& & (\alpha^3_{j,1} \beta_{j,7}) d^1_{\min(I_7)}+ \dots + (\alpha^3_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + 
 (\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4} + \beta_{j,5}) d^2_{6} + \\
 & & (\alpha^2_{j,1}\beta_{j,7}) d^2_{\min(I_7)} + \dots + (\alpha^2_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+  (\alpha_{j,1}\beta_{j,6}+\beta_{j,4}) d^3_{6} +  \\
 & & (\alpha_{j,1}\beta_{j,7}) d^3_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^3_{\min(I_r)} + \beta_{j,6} d^4_{\min(I_6)} + \dots +  \beta_{j,r} d^4_{\min(I_r)}.
\end{array}
\] 

Consider the coefficient of $o_j, d^1_5, d^1_{\min(I_7)},\dots,d^1_{\min(I_r)}$.
\begin{itemize}
\item $\alpha^4_{j,1}o_j = \alpha^2_{j,1}o_j$, $(\alpha^3_{j,1} \beta_{j,5}) d^1_5 = (\alpha_{j,1} \beta_{j,5}) d^1_5$,
\item $(\alpha^3_{j,1} \beta_{j,7}) d^1_{\min(I_7)}= (\alpha_{j,1} \beta_{j,7}) d^1_{\min(I_7)}$, $\dots$, $(\alpha^3_{j,1} \beta_{j,r}) d^1_{\min(I_r)}= (\alpha_{j,1} \beta_{j,r}) d^1_{\min(I_r)}$.
\end{itemize}
Therefore, all these coefficients are the same as those in $\chi_2(y_j)$.

Let us check the constant coefficient and the coefficients of $d^1_1,d^1_2,d^1_3,d^1_4,d^1_5$ and $d^1_6,d^2_6,\dots$.

\begin{itemize}
\item The constant coefficient and the coefficient of $d^1_1$, $d^1_2$, $d^1_3$ can be seen as integer counters.  

\item The coefficient of $d^1_4$ is $\alpha_{j,1} \beta_{j,4}+\beta_{j,5}, \alpha_{j,1}(\alpha_{j,1} \beta_{j,4}+\beta_{j,5}), \alpha^2_{j,1}(\alpha_{j,1} \beta_{j,4}+\beta_{j,5}), \dots$.

\item The coefficient of $d^1_5$ is $\beta_{j,5},\alpha_{j,1}\beta_{j,5}, \alpha^2_{j,1}\beta_{j,5},\alpha^3_{j,1}\beta_{j,5},\dots$.

\item The coefficient of $d^1_6$ (resp. $d^2_6,d^3_6,\dots$) is $\beta_{j,6}, \alpha_{j,1}\beta_{j,6}+\beta_{j,4}, \alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}, \alpha_{j,1}(\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}),\alpha^2_{j,1}(\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}),\dots$.
\end{itemize}
Since $\alpha_{j,1} \in\{0,+1,-1\}$, the values of the coefficients of $d^1_4,d^1_5$ and $d^1_6,d^2_6,d^3_6,\dots$ are from a bounded domain.

From this example, we get the following intuition.
%
\begin{itemize}
\item For the data variables belonging to some cycle of $G_C$, they can be dealt with the same as the constant coefficients, that is, dealt with as integer counters.

\item For the other data variables as well as those newly introduced data values, their coefficients are from a bounded domain and can be dealt with easily.
\end{itemize}


\subsection{The analysis of a lasso with independently evolving multiple output variables}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. 

We assume that $X=\emptyset$, thus all the guards in the transitions are trivial. Let $Y=\{y_1,\dots,y_l\}$. In addition, we assume that all the output variable are \emph{independently evolving} in the sense that for each transition $(q,g, \eta, q')$, it holds that for each $y \in Y$, only $y$ can occur in $\eta(y)$ and no other output variables can occur in $\eta(y)$. 

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

In the following, we will illustrate that if only the non-zero output problem is concerned, then no matter what the initial values of the output variables are, it is sufficient to traverse the loop for a bounded number of times.

%Suppose $O(q_n) = a_0 + a_1 y_1 + \dots + a_l y_l$. As a result of the ``copyless'' constraint, we know that $|a_1|, \dots, |a_l| \le 1$.

Let us traverse the loop for the first time. Then for each $1 \le j \le l$, an expression 
\[f^1_{j} = \beta_{j,0} + \beta_{j} o_{j} + \gamma_{j,1} d^1_1 + \dots + \gamma_{j,m} d^1_m\] 
can be constructed to describe the value of the variable $y_{j}$ after traversing the loop for the first time, where $o_1,\dots,o_l$ denote the initial value of the output variables and $d^1_1, \dots, d^1_m$ denote the data values introduced when traversing the loop for the first time. Note that as a result of ``independently evolving'' constraint, for each $j: 1 \le j \le l$, $f^1_{j}$ contains only $o_{j}$ and no other output variables. Moreover, because of ``copyless'' constraint, $\beta_j \in \{0,+1,-1\}$.

Suppose $O(q_n)=a_0 + a_1 o_1 + \dots a_l o_l$. 

Let $\chi_1$ be the assignment $\chi_1(y_j)=f^1_j$ for each $j: 1\le j \le l$.
Then $\chi_1(O(q_n)) = a_0+ a_1 f^1_1 + \dots a_l f^1_l$ is the following expression,
\[
(a_0 + \sum \limits_{1 \le j \le l} (a_j\beta_{j,0})) +  (a_1 \beta_1) o_1 + \dots + (a_l \beta_l) o_l + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^1_m.
\]

If $(\sum \limits_{1 \le j \le l} a_j \gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j \gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.

We then traverse the loop for the second time. Then for each $1 \le j \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^2_{j} = \beta_{j,0} + \beta_{j} f^1_{j} + \gamma_{j,1} d^2_1 + \dots + \gamma_{j,m} d^2_m$, where $d^2_1, \dots, d^2_m$ denote the data values introduced when traversing the loop for the second time. 

By expanding the expressions $f^1_1,\dots, f^1_l$, we get the following expression for $f^2_{j}$ (where $1 \le j \le l$),
\[
%\begin{array}{l}
f^2_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0}) + (\beta_{j})^2 o_{j} +
%\\
(\beta_{j}\gamma_{j,1}) d^1_1 +\dots + (\beta_{j}\gamma_{j,m}) d^1_m  + 
%\\
\gamma_{j,1} d^2_1 + \dots + \gamma_{j,m} d^2_m.
%\end{array}
\]

Let $\chi_2$ be the assignment $\chi_2(y_j)=f^2_j$ for each $j: 1\le j \le l$.
Then $\chi_2(O(q_n)) = a_0+ a_1 f^2_1 + \dots a_l f^2_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0})) +  (a_1 (\beta_1)^2) o_1 + \dots + (a_l (\beta_l)^2) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j \beta_{j}\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_{j}\gamma_{j,m}) d^1_m + \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^2_m.
\end{array}
\]

If $(\sum \limits_{1 \le j \le l} a_j \beta_j\gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j \beta_j\gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.


We continue traversing the loop for the third time. Then for each $1 \le j \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^3_{j} = \beta_{j,0} + \beta_{j} f^2_j  + \gamma_{j,1} d^3_1 + \dots + \gamma_{j,m} d^3_m$, where $d^3_1, \dots, d^3_m$ denote the data values introduced when traversing the loop for the third time. 

By expanding the expressions $f^2_1,\dots,f^2_l$, we get the following expression for $f^3_{j}$ (where $1\le j \le l$),
\[
\begin{array}{l}
f^3_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0}) + (\beta_{j})^3 o_{j} +
%\\
((\beta_{j})^2\gamma_{j,1}) d^1_1 +\dots + ((\beta_{j})^2\gamma_{j,m}) d^1_m  + \\
%\\
(\beta_j \gamma_{j,1}) d^2_1 + \dots + (\beta_j \gamma_{j,m}) d^2_m + \gamma_{j,1} d^3_1 + \dots + \gamma_{j,m} d^3_m.
\end{array}
\]

Let $\chi_3$ be the assignment $\chi_3(y_j)=f^3_j$ for each $j: 1\le j \le l$.
Then $\chi_3(O(q_n)) = a_0+ a_1 f^3_1 + \dots a_l f^3_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0})) +  (a_1 (\beta_1)^3) o_1 + \dots + (a_l (\beta_l)^3) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,m}) d^1_m + \\
(\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,m}) d^2_m \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^3_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^3_m. 
\end{array}
\]

Since for each $j: 1 \le j \le l$, $\beta_j \in \{0,+1,-1\}$, we know that for each $j: 1 \le j \le l$, $(\beta_j)^3=\beta_j$. Therefore, $(a_1 (\beta_1)^3) o_1 + \dots + (a_l (\beta_l)^3) o_l = (a_1 \beta_1) o_1 + \dots + (a_l \beta_l) o_l$.

If $(\sum \limits_{1 \le j \le l} a_j (\beta_j)^2\gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j (\beta_j)^2\gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.


We continue traversing the loop for the fourth time. Then for each $1 \le j \le l$, the resulting value of the variable $y_j$ is described by the expression 
\[
\begin{array}{l}
f^4_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0}+(\beta_j)^3 \beta_{j,0}) + (\beta_{j})^4 o_{j} +
\\
((\beta_{j})^3\gamma_{j,1}) d^1_1 +\dots + ((\beta_{j})^3 \gamma_{j,m}) d^1_m  + 
((\beta_{j})^2\gamma_{j,1}) d^2_1 +\dots + ((\beta_{j})^2 \gamma_{j,m}) d^2_m \\
(\beta_j \gamma_{j,1}) d^3_1 + \dots + (\beta_j \gamma_{j,m}) d^3_m + \gamma_{j,1} d^4_1 + \dots + \gamma_{j,m} d^4_m.
\end{array}
\]

Let $\chi_4$ be the assignment $\chi_4(y_j)=f^4_j$ for each $j: 1\le j \le l$.
Then $\chi_4(O(q_n)) = a_0+ a_1 f^4_1 + \dots a_l f^4_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0} + (\beta_j)^3 \beta_{j,0})) +  (a_1 (\beta_1)^4) o_1 + \dots + (a_l (\beta_l)^4) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,m}) d^1_m + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,m}) d^2_m + \\
(\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,1}) d^3_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,m}) d^3_m \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^4_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^4_m. 
\end{array}
\]

Since for each $j: 1\le j \le l$, $(\beta_j)^3=\beta_j$, we deduce that $(\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,i}) = (\sum \limits_{1 \le j \le l} a_j \beta_{j} \gamma_{j,i}) =0$ for each $i: 1\le i \le m$.

Since $\beta_j \in \{0,+1,-1\}$, we know that for each $j: 1\le j \le l$, $(\beta_j)^4=(\beta_j)^2$. Therefore, $(a_1 (\beta_1)^4) o_1 + \dots + (a_l (\beta_l)^4) o_l=(a_1 (\beta_1)^2) o_1 + \dots + (a_l (\beta_l)^2) o_l$.

Therefore, if the constant coefficient is ignored, then it is sufficient to traverse the loop for \emph{three times}.

For the consideration of the constant coefficient, let us assume that for each $j: 1 \le j \le l$, 
$o_j = \alpha_{j,0} + \alpha_{j,1} d_1+ \dots + \alpha_{j,n}d_n$, where $d_1,\dots,d_n$ are the data values introduced in the handle.

Then the constant coefficient after traversing the loop for $r$ times ($r \ge 1$) is described by the following expression,
\[a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}).\]

Since for each $j: 1 \le j \le l$, $\beta_j \in \{0,+1,-1\}$, we know that 
\begin{itemize}
\item if if $\beta_j=0$, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}=\beta_{j,0}$,
%
\item if $\beta_j=1$, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}=r\beta_{j,0} + \alpha_{j,0}$,
%
\item if $\beta_j = -1$ and $r$ is odd, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}= \beta_{j,0} - \alpha_{j,0}$,

\item if $\beta_j = -1$ and $r$ is even, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}= 2\beta_{j,0} + \alpha_{j,0}$.
\end{itemize}

Therefore, the non-zero output problem is reduced to the following problem: 
\begin{quote}
\it Given an expression of the form $c_0+c_1 r$, where $c_0 ,c_1$ are constants, and $r$ is a variable ranging over natural numbers, decide whether there exists $r$ such that $c_0+ c_1 r$ is non-zero. 
\end{quote}

\zhilin{I stopped here}


\subsection{Flat transducer with independently evolving output variables}

Let $\Ss=(Q, K, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. Suppose $X=\{x_1,\dots,x_k\}$ and $Y=\{y_1,\dots,y_l\}$. For simplicity, we assume that $K = 1$, that is, each position holds one data value.

A path scheme is a path in the SCC graph, which corresponds to a sequence of SCCs in the transition graph such that for each pair of consecutive SCCs in the sequence, say $C_1$ and $C_2$, there is an edge from $C_1$ to $C_2$.

Let us fix a path scheme, say $C_0 \dots C_n$.

For simplicity, let us start with the easy case that for each $i: 0 \le i < n$, $C_i$ is a single state and $C_n$ contains more than one node, that is, $C_0 \dots C_n$ is $q_0 \dots q_{n-1} q_n (C^1_n,\dots,C^m_n)$, where $C^1_{n},\dots, C^m_n$ are the collection of simple cycles in $C_n$ which share a unique state $q_{n}$. Moreover, we assume that $O(q_n)$ is defined and $O$ is undefined in each of the other states of $C_n$.

Without loss of generality, assume that each state in $C_0 \dots C_n$ is reachable. It is known that the state reachability problem of flat register automata is PSPACE-complete (\cite{DL09}). 

%Recall that we assume that $\Ss$ is copyless.

We show by induction that for each $i: 1 \le i \le n$ and each variable $x_j$ (resp. $y_j$), an arithmetic expression $e_{i,x_j}$ (resp. $e_{i,y_j}$) corresponding to $x_j$(resp. $y_j$) after going through the state sequence $q_0 \dots q_i$ can be constructed. Let $(q_{i}, 1, g_{i}, \eta_{i}, q_{i+1})$ be the $i$-th transition for each $i: 0 \le i < n$.

For each $j: 1 \le j \le k$, if $\eta_1(x_j)=p_1$, then $e_{1,x_j}=d_1$, otherwise, $e_{1,x_j}=\bot$.

For each $j: 1 \le j \le l$, $e_{1,y_j} = (\eta_{1,y_j}[d_1/p_1])$. 

For each $i: 1 < i \le n$, 
\begin{itemize}
\item for each $j: 1 \le j \le k$, $e_{i,x_j}=d_i$ if $\eta_i(x_j)=p_1$, and $e_{i,x_j}=e_{i-1,x_j}$ otherwise,
%
\item for each $j: 1 \le j \le l$, $e_{i,y_j} = \theta_i(\eta_i(y_j))$, where $\theta_i(x_{j'})=e_{i-1,x_{j'}}$ and $\theta_i(y_{j'})=e_{i-1, y_{j'}}$, and $\theta_i(p_1)=d_i$.
\end{itemize}

Then for each $j$, $e_{n,y_j} = c_{0,j} + c_{1,j} d_1 + \dots + c_{n,j} d_n$, where $c_{0,j},\dots, c_{n,j}$ are integer constants.

\smallskip

\noindent {\bf Step 1}: Decide whether $\theta_{n+1}(O(q_n))$ is not identical to zero (it is easy to do so, just check the coefficients of $d_1,\dots,d_n$), where $\theta_{n+1}(x_j)=e_{n,x_j}$ and $\theta_{n+1}(y_j)=e_{n,y_j}$. If the answer is yes, then we are done. Otherwise, we will continue checking the cycles of $C_n$.

Similarly, for each cycle $C^i_n = q'_0 q'_1 \dots q'_{l_i}$ such that $q'_0 = q'_{l_i}=q_n$, we can construct expressions $e'_{i,x_j}$ and $e'_{i,y_j}$ where the variables $x_1,\dots,x_k,y_1,\dots,y_l$ and the data value variables $d'_1,\dots,d'_{l_i}$ occur. Note that $x_1,\dots,x_k,y_1,\dots,y_l$ denote the values of these variables before executing the transitions in the cycle.

\smallskip

\noindent {\bf Step 2}: Iterate the following procedure for $i = 1, \dots, m$.
\begin{enumerate}
\item Consider $\theta'_i(O(q_n))$, where $\theta'_i(x_j)=e'_{i,x_j}$ and $\theta'_i(y_j)=e'_{i,y_j}$. 
%
\item If there is $j: 1 \le j \le l_i$ such that the coefficient of $d'_j$ in $\theta'_i(O(q_n))$ is nonzero, then we are done. 
\end{enumerate}

\smallskip

\noindent {\bf Step 3}: Let $\theta''_0=\theta_{n+1}$ and $\theta''_i = \theta''_{i-1}(\theta'_i)$ for $i = 1, \dots, m$.  Continue iterating the following procedure for $i = 1, \dots, m$:   If in $\theta''_i(O(q_n))$, the constant coefficient or the coefficient of some $d_{i'}$ for some $i': 1 \le i' \le n$ is nonzero, then we are done. 

\zhilin{These three steps are basically what I thought. But Step 3 is incorrect. Since we may need iterate over a cycle for multiple times to reach nonzero output. For some special cases, e.g. difference constraints or octagon constraints, we can use Presburger formula to summarize the effect of a cycle}.

\zhilin{My current feeling is that the problem is indeed more difficult than what we thought. Therefore, let us focus on the problem at present. We will try to work for CAV. If in the end we do not work out a submittable version, then we will target another conference.}

\subsection{Generalized flat transducer with independently evolving output variables}

\section{Discussions}

From the analysis of the commutativity of reducers in \cite{XZZ+14}, the commutativity of a reducer in a sequential composition oa map-reduce jobs may depend on some implicit data properties guaranteed by the preceding map-reduce jobs. Therefore, to analyze the commutativity of a reducer in a sequential composition of map-reduce jobs, we may need model both mappers and reducers and do a backward analysis.

\bibliographystyle{abbrv}
\bibliography{data}


\begin{appendix}



\end{appendix}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{The analysis of a lasso with only one output variable for each transducer}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. Suppose $Y=Y_1 \cup Y_2$, $Y_1 \cap Y_2 = \emptyset$, $Y_1=\{y_1\}$ and $Y_2 = \{y_2\}$. We will do the analysis step by step.

At first, we assume that $X=\emptyset$, thus all the guards in the transitions are trivial.

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

We use $d_1,\dots,d_n$ to denote the $n$ data values for the handle.

Then for $j=1,2$, an expression $e_{j}=\alpha_{j,0}+ \alpha_{j,1}d_1 + \dots \alpha_{j,n}d_n$ can be constructed to describe the value of $y_{j}$ after going through the handle, where the coefficients $\alpha_{j,0},\dots, \alpha_{j,n}$ are obtained from the transitions in the handle. Note here we ignore the special situations that the value of $y_{j}$ is undefined after going through the handle. Because of the ``copyless'' constraint, it holds that $\alpha_{j,1},\dots,\alpha_{j,n} \in \{0,+1,-1\}$.

Let $\theta$ be the assignment function such that $\theta(y_1)=e_1$ and $\theta(y_2)=e_2$.

Suppose $O(q_n)=a_0+a_1 y_{1} + a_2 y_2$. Then $\theta(O(q_n))$, that is, the expression obtained by replacing $y_1,y_2$ with $e_1,e_2$, is $a_0+a_1 e_{1} + a_2 e_2$, which can be rearranged into the following expression,
\[
(a_0 + \alpha_{1,0}+\alpha_{2,0}) + (a_1 \alpha_{1,1}+a_2 \alpha_{2,1}) d_1 + \dots + (a_1 \alpha_{1,n}+a_2 \alpha_{2,n}) d_n.
\]
Let $\mu_0,\dots,\mu_n$ denote the coefficients of the expression. 
If $\mu_i \neq 0$ for some $i: 1 \le i \le n$, then we know that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

Otherwise, we continue analyzing the loop. 

Similarly to the handle, for each $j=1,2$, an expression $f_1 = \beta_{1,0} + \beta_{1,1} \theta(y_1) + \gamma_{1,1} d'_1 + \dots + \gamma_{1,m} d'_m$ can be constructed to describe the value of the variable $y_{1}$ after going through the loop, where $\theta(y_{1})$ denote the initial value of the output variable $y_1$ and $d'_1, \dots, d'_m$ denote the data values occurring in the loop. Similarly, an expression $f_2 = \beta_{2,0} + \beta_{2,1} \theta(y_2) + \gamma_{2,1} d'_1 + \dots + \gamma_{2,m} d'_m$ can be constructed for $y_2$. As a result of the ``copyless'' constraint again, we know that $\beta_{j,1}, \gamma_{j,1},\dots,\gamma_{j,m} \in \{0,+1,-1\}$ for $j=1,2$.

Let $\chi$ be the assignment function such that $\chi(y_1)=f_1$ and $\chi(y_2)=f_2$.

Then $\chi(O(q_n)) = a_0 + a_1 f_1 + a_2 f_2$ can be rearranged into the following expression,
\[
(a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} ) + (a_1 \beta_{1,1})\theta(y_1)+(a_2 \beta_{2,1} )\theta(y_2) + 
 (a_1\gamma_{1,1} + a_2 \gamma_{2,1}) d'_1 + \dots + (a_1\gamma_{1,m} + a_2 \gamma_{2,m}) d'_m.
\]


If $a_1 \gamma_{1,i} +a_2 \gamma_{2,i} \neq 0$ for some $i: 1 \le i \le m$, then we are done.


Otherwise, let $a'_0, a'_1,a'_2$ be the coefficients in the expression above, that is, $\chi(O(q_n))=a'_0 + a'_1 \theta(y_1)+ a'_2 \theta(y_2)$.

By expanding the expressions $\theta(y_1)=e_1$ and $\theta(y_2)=e_2$ in $\chi(O(q_n))$, we get the following expression,

\[
(a'_0 + \alpha_{1,0}+\alpha_{2,0}) + (a'_1 \alpha_{1,1}+a'_2 \alpha_{2,1}) d_1 + \dots + (a'_1 \alpha_{1,n}+a'_2 \alpha_{2,n}) d_n.
\]

For each $i: 0 \le i \le n$, let $\mu'_i$ denote the $i$-th coefficient of the expression. 
%
Intuitively, $\theta(O(q_n)) = \mu_0 + \mu_1 d_1 + \dots + \mu_n d_n$ and $\chi(O(q_n)) = \mu'_0 + \mu'_1 d_1 + \dots \mu'_n d_n$.

If $\mu'_i \neq 0$ for some $i: 0 \le i \le n$, then we are done. 

Otherwise, we iterate the loop once more.  Then we get the output $a'_0 + a'_1 \chi(y_1)+ a'_2 \chi(y_2)$, which can be rearranged into
\[
 (a'_0 + a'_1 \beta_{1,0} + a'_2 \beta_{2,0} ) + (a'_1 \beta_{1,1})\theta(y_1)+(a'_2 \beta_{2,1} )\theta(y_2) + 
 (a'_1\gamma_{1,1} + a'_2 \gamma_{2,1}) d'_1 + \dots + (a'_1\gamma_{1,m} + a'_2 \gamma_{2,m}) d'_m.
\]

By expanding the expressions $a'_0 = a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0}$, $a'_1=a_1 \beta_{1,1}$, $a'_2=a_2 \beta_{2,1}$, as well as $\theta(y_1)$ and $\theta(y_2)$, we get the following expression,
\[
\begin{array}{l}
 (a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} + \alpha_{1,0} + \alpha_{2,0}) + \\
 ((a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,1}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,1})d_1 + \\
 \multicolumn{1}{c}{\dots} \\
  ((a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,n}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,n})d_n \\
 (a_1 \beta_{1,1}\gamma_{1,1} + a_2 \beta_{2,1} \gamma_{2,1}) d'_1 + 
 \dots + (a_1 \beta_{1,1}\gamma_{1,m} + a_2 \beta_{2,1} \gamma_{2,m}) d'_m.
\end{array}
\]

From the fact that $\mu_0=\mu_1 = \dots \mu_n =0$ and $\mu'_0=\mu'_1=\dots = \mu'_n=0$, we get the following equations, 
\[
\begin{array}{l c l}
a_0 + \alpha_{1,0}+\alpha_{2,0} & = & 0,\\
a_1 \alpha_{1,1} + a_2 \alpha_{2,1} & = & 0,\\
\multicolumn{3}{c}{\dots}  \\
a_1 \alpha_{1,n} + a_2 \alpha_{2,n} & = & 0, \\
a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + \alpha_{1,0}+ \alpha_{2,0}  & =  & 0,\\
a_1\beta_{1,1} \alpha_{1,1} + a_2 \beta_{2,1} \alpha_{2,1} & = & 0,\\
\multicolumn{3}{c}{\dots}  \\
a_1\beta_{1,1} \alpha_{1,n} + a_2 \beta_{2,1} \alpha_{2,n}  & = & 0.
\end{array}
\] 

If $\beta_{1,1} \neq \beta_{2,1}$ and $a_1 \beta_{1,0} \neq 0$, then from $a_1 \beta_{1,0} + a_2 \beta_{2,0} =0$, we deduce that 
\[a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} + \alpha_{1,0} + \alpha_{2,0} = a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} \neq 0.\]
In this case, we conclude that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

Similarly, if $\beta_{1,1} \neq \beta_{2,1}$ and $a_1 \gamma_{1,i} \neq 0$ for some $i: 1 \le i \le m$, then from $a_1 \gamma_{1,i} + a_2 \gamma_{2,i} =0$, we deduce that 
$(a_1 \beta_{1,1}\gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i}) \neq 0$. In this case, we also conclude that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

In the following, we assume that $\beta_{1,1} = \beta_{2,1}$ or $a_1 \beta_{1,0} = 0$ or for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$.

If $\beta_{1,1} = \beta_{2,1}$, then it is easy to see that $a'_0 + a'_1 \chi(y_1)+ a'_2 \chi(y_2) = 0$ and we can conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

Therefore, in the following, we assume that $\beta_{1,1} \neq \beta_{2,1}$. Then $a_1 \beta_{1,0} = 0$ or for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$. 

If $|\beta_{1,1}| =|\beta_{2,1}|$ and for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$, then we can conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

Therefore, in the following, we assume that $|\beta_{1,1}| \neq |\beta_{2,1}|$ or there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$. 
\begin{enumerate}
\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} = 0$, there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$,
\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} = 0$, for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$,
%\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} \neq 0$, for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$,
\item $|\beta_{1,1}| = |\beta_{2,1}|$ (but $\beta_{1,1} \neq \beta_{2,1}$), $a_1 \beta_{1,0} = 0$, there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$.
\end{enumerate}

For the first case above, we have $\beta_{1,1}=0$ and $\beta_{2,1} = \pm 1$, or vice versa. Then $a_1 \beta_{1,1} \gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i} \neq 0$. Therefore, we conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

For the second case above, we have $\beta_{1,1}=0$ and $\beta_{2,1} = \pm 1$, or vice versa. Then for each $i: 1 \le i \le n$, $(a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,i}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,i} = a_2  \alpha_{2,i}$ or $a_1 \alpha_{1,i}$. If there is $i: 1 \le i \le n$ such that $a_1 \alpha_{1,i} \neq 0$, then we conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero. Otherwise, we conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

For the third case above, we have that $\beta_{1,1} = 1$ and $\beta_{2,1} =-1$ or vice versa. Then $a_1 \beta_{1,1}\gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i} = 2a_1 \gamma_{1,i}$ or $-2a_1 \gamma_{1,i}$. We conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.



\section{Analysis of a lasso with multiple output variables}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. 

We assume that $X=\emptyset$, thus all the guards in the transitions are trivial. Let $Y=\{y_1,\dots,y_l\}$.

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

In the following, we will illustrate that if only the non-zero output problem is concerned, then no matter what the initial values of the output variables are, it is sufficient to traverse the loop for a bounded number of times.

%Suppose $O(q_n) = a_0 + a_1 y_1 + \dots + a_l y_l$. As a result of the ``copyless'' constraint, we know that $|a_1|, \dots, |a_l| \le 1$.

Let us traverse the loop for the first time. Then for each $1 \le j_1 \le l$, an expression 
\[f^1_{j_1} = \beta_{j_1,0} + \beta_{j_1,1} o_1 + \dots + \beta_{j_1,l} o_l + \gamma_{j_1,1} d^1_1 + \dots + \gamma_{j_1,m} d^1_m\] 
can be constructed to describe the value of the variable $y_{j_1}$ after traversing the loop for the first time, where $o_1,\dots,o_l$ denote the initial value of the output variables and $d^1_1, \dots, d^1_m$ denote the data values introduced when traversing the loop for the first time. 

As a result of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+\dots +|\beta_{l,i}| \le 1$.


We then traverse the loop for the second time. Then for each $1 \le j_2 \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^2_{j_2} = \beta_{j_2,0} + \beta_{j_2,1} f^1_1 + \dots + \beta_{j_2,l} f^1_l + \gamma_{j_2,1} d^2_1 + \dots + \gamma_{j_2,m} d^2_m$, where $d^2_1, \dots, d^2_m$ denote the data values introduced when traversing the loop for the second time. 

By expanding the expressions $f^1_1,\dots, f^1_l$, we get the following expression for $f^2_{j_2}$ (where $1 \le j_2 \le l$),
\[
\begin{array}{l}
f^2_{j_2} = (\beta_{j_2,0} + \sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, 0}) + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,1}) o_1 + \dots + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,l}) o_l +  \\
(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,1}) d^1_1 +\dots + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,m}) d^1_m  + \\
\gamma_{j_2,1} d^2_1 + \dots + \gamma_{j_2,m} d^2_m.
\end{array}
\]

Note that because of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+ \dots |\beta_{l,i}| \le 1$, thus the absolute value of $\sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, i}$ is at most one. 

We continue traversing the loop for the third time. Then for each $1 \le j_3 \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^3_{j_3} = \beta_{j_3,0} + \beta_{j_3,1} f^2_1 + \dots + \beta_{j_3,l} f^2_l + \gamma_{j_3,1} d^3_1 + \dots + \gamma_{j_3,m} d^3_m$, where $d^3_1, \dots, d^3_m$ denote the data values introduced when traversing the loop for the third time. 

By expanding the expressions $f^2_1,\dots,f^2_l$, we get the following expression for $f^3_{j_3}$ (where $1\le j_3 \le l$),
\[
\begin{array}{l}
f^3_{j_3} = (\beta_{j_3,0} + \sum \limits_{1 \le j_2 \le l} \beta_{j_3,j_2} (\beta_{j_2,0} + \sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, 0})) +\\
%
 (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,1})) o_1 + \dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,l})) o_l +  \\
 %
(\sum \limits_{1 \le j_2 \le l}\beta_{j_3, j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,1})) d^1_1 +\dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,m})) d^1_m  + \\
(\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}\gamma_{j_2,1}) d^2_1 +\dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}\gamma_{j_2,m}) d^2_m  + \\
\gamma_{j_3,1} d^3_1 + \dots + \gamma_{j_3,m} d^3_m.
\end{array}
\]

Note that because of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+ \dots |\beta_{l,i}| \le 1$, thus the absolute value of $\sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, i}$ is at most one. 

