%!TEX root = main-cav.tex

\section{Introduction}
%What is Map-Reduce
MapReduce is a  popular framework for data parallel computations. It has been adopt in various cloud computing frameworks such as Hadoop~\cite{Hadoop} and Spark~\cite{Spark}. In a typical MapReduce program, a \emph{mapper} reads from data sources and outputs a list of key-value pairs. 
The load balance mechanism of the Map-Reduce framework reorganizes the key-value pairs $(k, v_1), (k,v_2)\ldots(k,v_n)$ with the same key $k$ to a pair $(k,l)$, where $l$ is a list of values $v_1,v_2,\ldots,v_n$, and sends $(k,l)$ to a \emph{reducer}. The reducer then iterates through the list and output a key-value pair.

To be more concrete, taking the ``word-counting'' MapReduce program as an example. It counts the occurrences of each word in a set of documents. The mappers read the documents and output for each document a list in the form of $(word_1, count_1), (word_2, count_2), \ldots, (word_n, count_n)$, where $count_k$ is the number of occurrences of $word_k$ in the document being processed. These lists will be reorganized into the form of $(word_1, list_1), (word_2,list_2), \ldots, (word_n,list_n)$ and sent to the reducers, where $list_k$ is a list of integers recording the number of occurrences of $word_k$ in the set of documents. Note that the \emph{order} of the integers in the lists can differ in different executions due to network latency, load balancing, etc.
This results in the \emph{commutativity problem}.

%The communitativity problem and its importance
We say that a reducer is \emph{commutativity} if its output is independent of the order of its inputs. The commutativity problem asks if a reducer is commutativity. A study from Microsoft~\cite{XZZ+14} reports that 58\% of the 507 reducers submit to their MapReduce platform are non-commutative, which may lead to very tricky and hard-to-find bugs.
As an evidence, those reducers already went through serious code review, testing, and experiments with real data for more than three months. Still, among them 5 reducers containing very subtle bugs caused by non-commutativity (confirmed by the programmers). 
Moreover, having the commutativity property makes reproducing a bug found by program testing easier.

%The reason for studying syntatical restrictions 
The reducer commutative problem in general is undecidable by Rice's theorem. However, in practice, the reducers are seldom Turing machines. They are usually used for data analytics and have very simple control structures. Many of them just iterate through the input list and compute the output with very simple operations.
We want to study if the commutative problem of real-world reducers are decidable.

%The tacas 2015 undecidability result
A simple programming language of reducers over integers has been considered in~\cite{CHSW15}, where the only loop structure allowed is an iteration over the input list and it is not allowed to reset the iterator to the list head. They show that the commutative problem of programs written by such a simple language is undecidable by a reduction from the satisfiability problem of Diophantine equations. Under scrutiny, we found that the language is still too expressive for typical data analytics programs. For example, it allows arbitrary multiplications of variables, which is a key element in the undecidability proof. 

%our languge
By observing the behavioral pattern of reducer programs for data analytics, we characterize the essential components in a programming language for reducers. %However, we found that even only with the essential parts of the language, the commutativity problem is still undecidable. 
We found that the commutativity problem becomes decidable if we partition variables into \emph{control variables} and \emph{data variables}. Data variables cannot be used in transition guards and control variables can store only elements in the input list (e.g., it is not allowed to store the sum of two variables in a control variable). 
We believe such concepts provide good insights for reducer programming language design.

%%%SNTs
We define a formalism named \emph{streaming numerical transducers (SNT)} and use it to create a decision procedure for the reducer commutative problem.
The design of SNTs is inspired by the streaming transducer model~\cite{RP11}.
It generalizes register automata~\cite{KF94,NSV04} to allow quantifier-free Presburgh arithmetic over variables and input values, with restrictions on the structure of the transition systems.
We show that the equivalence, commutative, and non-zeroness problems of SNTs are decidable.
Moreover, SNTs can be composed to form a commutative/equivalence proof of reducer programs that read the input list multiple times (Section~\ref{sec_cases}).
The study of SNT is interesting on its own right. As far as we know, this is the \emph{first} automata model over infinite alphabet where quantifier-free Presburgh arithmetic over variables and input values is allowed. Moreover, the model can be applied to the verification of other interesting classes of programs, programs with unbounded list as input.

The rest of the paper is organized as follows. Section~\ref{sec:preliminaries} defines notations we use in the paper. Section~\ref{sec:language} describes our design of the verifiable programming language for reducers. Section~\ref{sec:def-snt} describes design of the \emph{streaming numerical transducer} (SNT) model, including the formal definition and Section~\ref{sec:dec-snt} describes the decision procedure of SNTs. Sec~\ref{sec:cases} demonstrates how to use our framework to verify the commutativity property over more challenging data analytics programs. We conclude the paper in Section~\ref{sec:conclusion}. 