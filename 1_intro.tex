%!TEX root = main-cav.tex

\section{Introduction}
%What is MapReduce
MapReduce is a  popular framework for data parallel computation. It has been adopted in various cloud computing platforms including Hadoop~\cite{Hadoop} and Spark~\cite{Spark}. In a typical MapReduce program, a \emph{mapper} reads from data sources and outputs a list of key-value pairs. 
The scheduler of the MapReduce framework reorganizes the pairs $(k, v_1), (k,v_2)\ldots(k,v_n)$ with the same key $k$ to a pair $(k,l)$, where $l$ is a list of values $v_1,v_2,\ldots,v_n$, and sends $(k,l)$ to a \emph{reducer}. The reducer then iterates through the list and outputs a key-value pair~\footnote{We focus on the Hadoop style reducer in this work.}.
More specifically, taking the ``word-counting'' program as an example. It counts the occurrences of each word in a set of documents. The mappers read the documents and output for each document a list in the form of $(word_1, count_1)$, $(word_2, count_2)$, $\ldots$ , $(word_n, count_n)$, where $count_k$ is the number of occurrences of $word_k$ in the document being processed. These lists will be reorganized into the form of $(word_1, list_1), (word_2,list_2), \ldots, (word_n,list_n)$ and sent to the reducers, where $list_k$ is a list of integers recording the number of occurrences of $word_k$s. Note that the \emph{order} of the integers in the lists can differ in different executions due to the scheduling policy. This results in the \emph{commutativity problem}.

%The communitativity problem and its importance
A reducer is said to be \emph{commutative} if its output is independent of the order of its inputs. The commutativity problem asks if a reducer is commutative. A study from Microsoft~\cite{XZZ+14} reports that 58\% of the 507 reducers submitted to their MapReduce platform are non-commutative, which may lead to very tricky and hard-to-find bugs.
As an evidence, those reducers already went through serious code review, testing, and experiments with real data for months. Still, among them 5 reducers containing very subtle bugs caused by non-commutativity (confirmed by the programmers). 
%Moreover, having the commutativity property makes reproducing a bug found by program testing easier.

%The reason for studying syntatical restrictions 
The reducer commutativity problem in general is undecidable. However, in practice, MapReduce programs are usually used for data analytics and have very simple control structures. Many of them just iterate through the input list and compute the output with very simple operations. We want to study if the commutativity problem of real-world reducers is decidable. It has been shown in~\cite{CHSW15} that even with a simple programming language where the only loop structure allowed is to go over the input list once, the commutativity problem is already undecidable. Under scrutiny, we found that the language is still too expressive for typical data analytics programs. For example, it allows arbitrary multiplications of variables, which is a key element in the undecidability proof.

%The tacas 2015 undecidability result
%A simple programming language of reducers over integers has been considered in~\cite{CHSW15}, where the only loop structure allowed is an iteration over the input list and it is not allowed to reset the iterator to the list head. They show that the commutative problem of programs written by such a simple language is undecidable by a reduction from the satisfiability problem of Diophantine equations. Under scrutiny, we found that the language is still too expressive for typical data analytics programs. For example, it allows arbitrary multiplications of variables and input values, which is a key element in the undecidability proof. 
%our languge

\smallskip

\noindent {\it Contributions}.
By observing the behavioral patterns of reducer programs for data analytics, we first design a programming language for reducers to characterize the essential features of them. %However, we found that even only with the essential parts of the language, the commutativity problem is still undecidable. 
We found that the commutativity problem becomes decidable if we partition variables into \emph{control variables} and \emph{data variables}. Control variables can occur in transition guards, but can only store values directly from the input list (e.g., it is not allowed to store the sum of two input values in a control variable). On the other hand, data variables are used to aggregate some information for outputs (e.g. sum of the values from the input list), but cannot be used in transition guards. This distinction is inspired by the streaming transducer model~\cite{RP11}, which, we believe, provides good insights for reducer programming language design in the MapReduce framework. Moreover, we assume that there are no nested loops in the language for reducers, which is a typical situation for MapReduce programs in practice.

%%%SNTs
We then introduce a formalism called \emph{streaming numerical transducers (SNT)} and obtain a decision procedure for the commutativity problem of the aforementioned language for reducers.
Similar to the language for reducers, SNTs distinguish between control variables and data variables. Although conceptually SNTs are similar to streaming transducers over data words introduced in \cite{RP11}, they are intrinsically different in the following sense: The outputs of SNTs are integers and the integer variables therein are manipulated by linear arithmetic operations. On the other hand, the outputs of streaming transducers are data words, and the data word variables are manipulated by concatenation operations. SNTs in this paper are assumed to be \emph{generalized flat}, which generalizes the ``flat'' automata (c.f. \cite{LS06}) in the sense that each nontrivial strongly connected component (SCC) of the transition graph is a collection of cycles, instead of one single cycle. Generalized flat transition graphs are sufficient to capture the transition structures of the programs in the aforementioned language for reducers.

The decision procedure for the commutativity problem is obtained by reducing to the equivalence problem of SNTs, which is further reduced to the non-zero output problem. The non-zero output problem asks whether given an SNT, there exists some input data word $w$ such that the output of the SNT on $w$ is defined and non-zero.  For the non-zero output problem of SNTs, we apply a nontrivial combinatorial analysis of the evolvement of the integer variables during the runs of SNTs (Section~\ref{sec-sum}). The key idea of the decision procedure is that, generally speaking, if only the non-zero output problem is concerned, the different cycles in the SCCs can be dealt with \emph{independently} (Section~\ref{sec-glasso} and \ref{sec-gflat}). 
%
As a further evidence of the usefulness of SNTs for MapReduce programs, we demonstrate that SNTs can be composed to model and analyze the reducer programs that read the input list multiple times (Section~\ref{sec:cases}). 

As a novel formalism over infinite alphabets, the model of SNTs is interesting in its own right: On the one hand, SNTs are expressive in the sense that they include linear arithmetic operations on integer variables, while at the same time admit rather general transition graphs, that is, generalized flat transition graphs. On the other hand, despite this strong expressibility, it turns out that the commutativity problem, the equivalence problem, and the non-zero output problem of SNTs are still decidable.  
%The model of SNTs and the decision procedure are interesting in their own right.

\smallskip

\noindent {\it Related work}.
SNTs can be seen as generalizations of register automata~\cite{KF94,NSV04} where registers correspond to the control variables in our terminology. Although register automata can have very general transition graphs beyond the generalized flat ones, they do not allow arithmetic operations on the variables.
There have been many automata models that contain arithmetic operations. Counter automata contain counters whose values can be updated by arithmetic operations (see \cite{Iba78,CJ98,LS06,HH14,FGH13}, to cite a few) in each transition.  Intuitively, the major difference between SNTs and counter automata is that SNTs work on data words and can apply arithmetic operations to an unbounded number of independent integer values, whereas  counter automata contain a bounded number of counters which involve only  a bounded number of values. Cost register automata (CRA)~\cite{ADD+13} also contain arithmetic operations, where the costs are stored into registers for which arithmetic operations can be applied. The equivalence of CRAs with addition is decidable. SNTs are different from CRAs since the inputs of CRAs are words on finite alphabets, while those of SNTs are data words. 
Moreover, SNT allows guards over variables with infinite domain but CRA does not. 
%
%As far as we know, this is the \emph{first} automata model over infinite alphabet allowing quantifier-free Presburgh arithmetics over variables and values from an unbounded input tape. Moreover, the model can be applied to the verification of other interesting classes of programs, e.g., programs with unbounded list as the input.
%As far as we know, the SNT model  is different from all other automata models. 
%
There have been several transducer models on data words: Streaming transducers~\cite{RP11} mentioned before and symbolic transducers~\cite{VHL+12}. Symbolic transducers have data words as both inputs and outputs. They can put guards on the input value in one position of data words, but are incapable of comparing and aggregating multiple input values in different positions. In \cite{FNFT15}, the authors considered a model where the only comparison that can be performed between data values are equalities, and the reducers are essentially register automata/transducers. Their model can describe a system with multiple layers of mappers and reducers.

The rest of the paper is organized as follows. Section~\ref{sec:preliminaries} defines the notations used in this paper. Section~\ref{sec:language} describes our design of the programming language for reducers. Section~\ref{sec:def-snt} defines SNTs. Section~\ref{sec:dec-snt} describes the decision procedure of SNTs. Sec~\ref{sec:cases} discusses how to use our framework to verify the commutativity property of the more challenging data analytics programs. We conclude this paper in Section~\ref{sec:conclusion}. 