%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
\yfc{can we describe the following Triangle-counting algorithm using the model?}
\zhilin{Could you describe how to implement the algorithm in MapReduce framework?}
\yfc{this is based on the sample code in Spark, I found antoher sample code in Hadoop, maybe fits the model better, check https://github.com/vertica/Graph-Analytics----Triangle-Counting/blob/master/src/com/vertica/mr/graphs/TriangleCounter.java}

\zhilin{I will describe my understanding of the algorithm in the following} 

The task comprises of three MapReduce jobs. 
\begin{description}
\item[Job1] Map: Filter out the pairs $(v1,v2)$ such that $v1 > v2$. Reduce: on the input $(v, w_1 \dots w_k)$ (where $v < w_i$ for each $i$), output the list $((v,w_1),0), \dots, ((v,w_k),0), ((w_1,w_2),1), \dots, ((w_{k-1},w_k),1)$.
\item[Job2] Map: Identity function. Reduce: on the input $((v1,v2),i_1 ... i_k)$, if $i_j=0$ for some $j$, then output $(1, i_1+...i_k)$, otherwise, output $(1,0)$.
\item[Job3] Map: Identity function. Reduce: on the input $(1,n_1 \dots n_k)$, ouput $((n_1+\dots + n_k),null)$.
\end{description}

\zhilin{The most challenging one is Job1. The reducer in Job1 need output each distinct pair $((w_i, w_j),1)$ for a list $w_1 \dots w_n$. For this transduction, at first we need extend the transducer to output a list of $(key, value)$ pairs, instead of a single $(key,value)$ pair. Moreover, the relatively complex transduction from lists to lists seems exceeding the capability of streaming transducers.}

\newcommand{\numTri}[1]{\triangle_{#1}}
Let $G = (V, E)$ be an undirected graph without self-loops or multiple
edges. For $u, v \in V$, $\{ u, v \} \in E$ denotes that $u$ and $v$
are adjacent. A  \emph{triangle} in $G$ is formed by $u, v, w \in V$ with $\{ u, v \},
\{ u, w \}, \{ v, w \} \in E$. 
We want to count the number of triangles in a given graph.

Suppose that the graph is described as a list of edges.

For each edge $\{ u, v \} \in E$, the algorithm sends the sets $\{ u \}$
and $\{ v \}$ to $v$ and $u$ respectively. If several messages are
sent to a vertex, they are merged by unions.
\yfc{So maybe we need to also support the data type ``set''}

After this operation, we get a list of pairs $(u, U)$, where $u \in V$ and $U$ is the set $\{ v : \{ u, v \} \in E \}$.

Then for each edge $\{ u, w \} \in E$, again we send the size of the set $| U \cap W |$ to both $u$ and $w$, where $U$ and $W$ are
the set of vertices adjacent to $u$ and $v$ respectively. 
\yfc{This is difficult in our model. We need to first traverse E (the first input list) and then get the corresponding set U and W from the 2nd list. Then count the size of their intersection. Maybe can be implemented in a slightly different way.}

Observe that for every $s \in U \cap W$, we have $\{ s, u \}, \{ s, w \}, \{ u, w
\} \in E$. Let $\numTri{\{u, v\}}$ denote the number of triangles
containing the edge $\{ u, w \}$. Then $\numTri{\{u, w\}}$ is sent to
both $u$ and $w$. If several messages are sent to $w$, they are merged
by summation. After this operation we get a list of pairs $(u, \sum_{\{ u, w \} \in E} \numTri{\{u, w\}})$.

Now consider a vertex $v$ in a triangle of $u, v, w$. The triangle is
counted in both $\numTri{\{ u, v \}}$ and $\numTri{\{ w, v \}}$. Hence
we need to divide the the number by 2 to get the number of triangles containing $v$. }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{The analysis of a lasso with only one output variable for each transducer}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. Suppose $Y=Y_1 \cup Y_2$, $Y_1 \cap Y_2 = \emptyset$, $Y_1=\{y_1\}$ and $Y_2 = \{y_2\}$. We will do the analysis step by step.

At first, we assume that $X=\emptyset$, thus all the guards in the transitions are trivial.

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

We use $d_1,\dots,d_n$ to denote the $n$ data values for the handle.

Then for $j=1,2$, an expression $e_{j}=\alpha_{j,0}+ \alpha_{j,1}d_1 + \dots \alpha_{j,n}d_n$ can be constructed to describe the value of $y_{j}$ after going through the handle, where the coefficients $\alpha_{j,0},\dots, \alpha_{j,n}$ are obtained from the transitions in the handle. Note here we ignore the special situations that the value of $y_{j}$ is undefined after going through the handle. Because of the ``copyless'' constraint, it holds that $\alpha_{j,1},\dots,\alpha_{j,n} \in \{0,+1,-1\}$.

Let $\theta$ be the assignment function such that $\theta(y_1)=e_1$ and $\theta(y_2)=e_2$.

Suppose $O(q_n)=a_0+a_1 y_{1} + a_2 y_2$. Then $\theta(O(q_n))$, that is, the expression obtained by replacing $y_1,y_2$ with $e_1,e_2$, is $a_0+a_1 e_{1} + a_2 e_2$, which can be rearranged into the following expression,
\[
(a_0 + \alpha_{1,0}+\alpha_{2,0}) + (a_1 \alpha_{1,1}+a_2 \alpha_{2,1}) d_1 + \dots + (a_1 \alpha_{1,n}+a_2 \alpha_{2,n}) d_n.
\]
Let $\mu_0,\dots,\mu_n$ denote the coefficients of the expression. 
If $\mu_i \neq 0$ for some $i: 1 \le i \le n$, then we know that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

Otherwise, we continue analyzing the loop. 

Similarly to the handle, for each $j=1,2$, an expression $f_1 = \beta_{1,0} + \beta_{1,1} \theta(y_1) + \gamma_{1,1} d'_1 + \dots + \gamma_{1,m} d'_m$ can be constructed to describe the value of the variable $y_{1}$ after going through the loop, where $\theta(y_{1})$ denote the initial value of the output variable $y_1$ and $d'_1, \dots, d'_m$ denote the data values occurring in the loop. Similarly, an expression $f_2 = \beta_{2,0} + \beta_{2,1} \theta(y_2) + \gamma_{2,1} d'_1 + \dots + \gamma_{2,m} d'_m$ can be constructed for $y_2$. As a result of the ``copyless'' constraint again, we know that $\beta_{j,1}, \gamma_{j,1},\dots,\gamma_{j,m} \in \{0,+1,-1\}$ for $j=1,2$.

Let $\chi$ be the assignment function such that $\chi(y_1)=f_1$ and $\chi(y_2)=f_2$.

Then $\chi(O(q_n)) = a_0 + a_1 f_1 + a_2 f_2$ can be rearranged into the following expression,
\[
(a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} ) + (a_1 \beta_{1,1})\theta(y_1)+(a_2 \beta_{2,1} )\theta(y_2) + 
 (a_1\gamma_{1,1} + a_2 \gamma_{2,1}) d'_1 + \dots + (a_1\gamma_{1,m} + a_2 \gamma_{2,m}) d'_m.
\]


If $a_1 \gamma_{1,i} +a_2 \gamma_{2,i} \neq 0$ for some $i: 1 \le i \le m$, then we are done.


Otherwise, let $a'_0, a'_1,a'_2$ be the coefficients in the expression above, that is, $\chi(O(q_n))=a'_0 + a'_1 \theta(y_1)+ a'_2 \theta(y_2)$.

By expanding the expressions $\theta(y_1)=e_1$ and $\theta(y_2)=e_2$ in $\chi(O(q_n))$, we get the following expression,

\[
(a'_0 + \alpha_{1,0}+\alpha_{2,0}) + (a'_1 \alpha_{1,1}+a'_2 \alpha_{2,1}) d_1 + \dots + (a'_1 \alpha_{1,n}+a'_2 \alpha_{2,n}) d_n.
\]

For each $i: 0 \le i \le n$, let $\mu'_i$ denote the $i$-th coefficient of the expression. 
%
Intuitively, $\theta(O(q_n)) = \mu_0 + \mu_1 d_1 + \dots + \mu_n d_n$ and $\chi(O(q_n)) = \mu'_0 + \mu'_1 d_1 + \dots \mu'_n d_n$.

If $\mu'_i \neq 0$ for some $i: 0 \le i \le n$, then we are done. 

Otherwise, we iterate the loop once more.  Then we get the output $a'_0 + a'_1 \chi(y_1)+ a'_2 \chi(y_2)$, which can be rearranged into
\[
 (a'_0 + a'_1 \beta_{1,0} + a'_2 \beta_{2,0} ) + (a'_1 \beta_{1,1})\theta(y_1)+(a'_2 \beta_{2,1} )\theta(y_2) + 
 (a'_1\gamma_{1,1} + a'_2 \gamma_{2,1}) d'_1 + \dots + (a'_1\gamma_{1,m} + a'_2 \gamma_{2,m}) d'_m.
\]

By expanding the expressions $a'_0 = a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0}$, $a'_1=a_1 \beta_{1,1}$, $a'_2=a_2 \beta_{2,1}$, as well as $\theta(y_1)$ and $\theta(y_2)$, we get the following expression,
\[
\begin{array}{l}
 (a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} + \alpha_{1,0} + \alpha_{2,0}) + \\
 ((a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,1}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,1})d_1 + \\
 \multicolumn{1}{c}{\dots} \\
  ((a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,n}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,n})d_n \\
 (a_1 \beta_{1,1}\gamma_{1,1} + a_2 \beta_{2,1} \gamma_{2,1}) d'_1 + 
 \dots + (a_1 \beta_{1,1}\gamma_{1,m} + a_2 \beta_{2,1} \gamma_{2,m}) d'_m.
\end{array}
\]

From the fact that $\mu_0=\mu_1 = \dots \mu_n =0$ and $\mu'_0=\mu'_1=\dots = \mu'_n=0$, we get the following equations, 
\[
\begin{array}{l c l}
a_0 + \alpha_{1,0}+\alpha_{2,0} & = & 0,\\
a_1 \alpha_{1,1} + a_2 \alpha_{2,1} & = & 0,\\
\multicolumn{3}{c}{\dots}  \\
a_1 \alpha_{1,n} + a_2 \alpha_{2,n} & = & 0, \\
a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + \alpha_{1,0}+ \alpha_{2,0}  & =  & 0,\\
a_1\beta_{1,1} \alpha_{1,1} + a_2 \beta_{2,1} \alpha_{2,1} & = & 0,\\
\multicolumn{3}{c}{\dots}  \\
a_1\beta_{1,1} \alpha_{1,n} + a_2 \beta_{2,1} \alpha_{2,n}  & = & 0.
\end{array}
\] 

If $\beta_{1,1} \neq \beta_{2,1}$ and $a_1 \beta_{1,0} \neq 0$, then from $a_1 \beta_{1,0} + a_2 \beta_{2,0} =0$, we deduce that 
\[a_0 + a_1 \beta_{1,0} + a_2 \beta_{2,0} + a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} + \alpha_{1,0} + \alpha_{2,0} = a_1 \beta_{1,1} \beta_{1,0} + a_2 \beta_{2,1} \beta_{2,0} \neq 0.\]
In this case, we conclude that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

Similarly, if $\beta_{1,1} \neq \beta_{2,1}$ and $a_1 \gamma_{1,i} \neq 0$ for some $i: 1 \le i \le m$, then from $a_1 \gamma_{1,i} + a_2 \gamma_{2,i} =0$, we deduce that 
$(a_1 \beta_{1,1}\gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i}) \neq 0$. In this case, we also conclude that there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

In the following, we assume that $\beta_{1,1} = \beta_{2,1}$ or $a_1 \beta_{1,0} = 0$ or for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$.

If $\beta_{1,1} = \beta_{2,1}$, then it is easy to see that $a'_0 + a'_1 \chi(y_1)+ a'_2 \chi(y_2) = 0$ and we can conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

Therefore, in the following, we assume that $\beta_{1,1} \neq \beta_{2,1}$. Then $a_1 \beta_{1,0} = 0$ or for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$. 

If $|\beta_{1,1}| =|\beta_{2,1}|$ and for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$, then we can conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

Therefore, in the following, we assume that $|\beta_{1,1}| \neq |\beta_{2,1}|$ or there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$. 
\begin{enumerate}
\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} = 0$, there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$,
\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} = 0$, for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$,
%\item $|\beta_{1,1}| \neq |\beta_{2,1}|$, $a_1 \beta_{1,0} \neq 0$, for each $i: 1 \le i \le m$, $a_1 \gamma_{1,i} = 0$,
\item $|\beta_{1,1}| = |\beta_{2,1}|$ (but $\beta_{1,1} \neq \beta_{2,1}$), $a_1 \beta_{1,0} = 0$, there is $i: 1 \le i \le m$ such that $a_1 \gamma_{1,i} \neq 0$.
\end{enumerate}

For the first case above, we have $\beta_{1,1}=0$ and $\beta_{2,1} = \pm 1$, or vice versa. Then $a_1 \beta_{1,1} \gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i} \neq 0$. Therefore, we conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.

For the second case above, we have $\beta_{1,1}=0$ and $\beta_{2,1} = \pm 1$, or vice versa. Then for each $i: 1 \le i \le n$, $(a_1 \beta_{1,1} \beta_{1,1})\alpha_{1,i}+(a_2 \beta_{2,1} \beta_{2,1} ) \alpha_{2,i} = a_2  \alpha_{2,i}$ or $a_1 \alpha_{1,i}$. If there is $i: 1 \le i \le n$ such that $a_1 \alpha_{1,i} \neq 0$, then we conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero. Otherwise, we conclude that there are no inputs $w$ such that the output of $\Ss$ on $w$ is nonzero.

For the third case above, we have that $\beta_{1,1} = 1$ and $\beta_{2,1} =-1$ or vice versa. Then $a_1 \beta_{1,1}\gamma_{1,i} + a_2 \beta_{2,1} \gamma_{2,i} = 2a_1 \gamma_{1,i}$ or $-2a_1 \gamma_{1,i}$. We conclude that  there is an input $w$ such that the output of $\Ss$ on $w$ is nonzero.



\section{Analysis of a lasso with multiple output variables}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. 

We assume that $X=\emptyset$, thus all the guards in the transitions are trivial. Let $Y=\{y_1,\dots,y_l\}$.

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

<<<<<<< HEAD
We then focus on the equivalence problem of generalized flat \SDSIT$_{\pm}$.

A \SDSIT$_{\pm}$ is called \emph{generalized flat} if each nontrivial SCC (strongly-connected component) of the transition graph is a collection of edge-disjoint simple cycles such that there is a unique state which is shared by each pair of distinct cycles in the collection.

Let $\Ss_1$ and $\Ss_2$ be two generalized flat \SDSIT$_{\pm}$.

\begin{proposition}\label{prop-equiv-reduce}
The equivalence problem of two generalized flat \SDSIT$_{\pm}$ be reduced to the non-zero output problem of a generalized flat \SDSIT$_{\pm}$.
\end{proposition}

%Suppose $\Ss_1=(Q_1, K, X_1, Y_1, \delta_1, q_{0,1}, O_1)$ and $\Ss_1=(Q_2, K, X_2, Y_2, \delta_2, q_{0,2}, O_2)$ are two generalized flat \SDSIT$_{\pm}$. Without loss of generality, we assume that the state spaces (resp. the set of data variables, the set of output variables) of $\Ss_1$ and $\Ss_2$ are disjoint. Moreover, the \SDSIT$_{\pm}$ $\Ss$ constructed from $\Ss_1$ and $\SS_2$ (cf. Proposition~\ref{prop-equiv-reduce}), satisfies the following property: 
%\begin{quote}
%\it the output variables in $Y_1$ are updated independently of those in $Y_2$: For each transition $((q_1,q_2),g,\eta,(q'_1,q'_2))$ in $\Ss$, for each $y_1 \in Y_1$(resp. $y_2 \in Y_2$), no variables from $Y_2$ (resp. $Y_1$) occurs in $\eta(y_1)$ (resp. $\eta(Y_2)$). \hfill ($\ast$)
%\end{quote}

%In the rest of this paper, we will assume that the \SDSIT$_{\pm}$ $\Ss$ in the non-zero reachability problem satisfies that the set of output variables of $\Ss$ is $Y_1 \uplus Y_2$ and $Y_1,Y_2$ satisfy the constraint $(\ast)$.

For simplicity, from now on, we assume that $K=1$, that is, there is at most one data value over each position, and we will omit the number $K$ in the definition of \SDSIT$_{\pm}$.
=======
In the following, we will illustrate that if only the non-zero output problem is concerned, then no matter what the initial values of the output variables are, it is sufficient to traverse the loop for a bounded number of times.

%Suppose $O(q_n) = a_0 + a_1 y_1 + \dots + a_l y_l$. As a result of the ``copyless'' constraint, we know that $|a_1|, \dots, |a_l| \le 1$.

Let us traverse the loop for the first time. Then for each $1 \le j_1 \le l$, an expression 
\[f^1_{j_1} = \beta_{j_1,0} + \beta_{j_1,1} o_1 + \dots + \beta_{j_1,l} o_l + \gamma_{j_1,1} d^1_1 + \dots + \gamma_{j_1,m} d^1_m\] 
can be constructed to describe the value of the variable $y_{j_1}$ after traversing the loop for the first time, where $o_1,\dots,o_l$ denote the initial value of the output variables and $d^1_1, \dots, d^1_m$ denote the data values introduced when traversing the loop for the first time. 

As a result of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+\dots +|\beta_{l,i}| \le 1$.


We then traverse the loop for the second time. Then for each $1 \le j_2 \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^2_{j_2} = \beta_{j_2,0} + \beta_{j_2,1} f^1_1 + \dots + \beta_{j_2,l} f^1_l + \gamma_{j_2,1} d^2_1 + \dots + \gamma_{j_2,m} d^2_m$, where $d^2_1, \dots, d^2_m$ denote the data values introduced when traversing the loop for the second time. 

By expanding the expressions $f^1_1,\dots, f^1_l$, we get the following expression for $f^2_{j_2}$ (where $1 \le j_2 \le l$),
\[
\begin{array}{l}
f^2_{j_2} = (\beta_{j_2,0} + \sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, 0}) + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,1}) o_1 + \dots + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,l}) o_l +  \\
(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,1}) d^1_1 +\dots + (\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,m}) d^1_m  + \\
\gamma_{j_2,1} d^2_1 + \dots + \gamma_{j_2,m} d^2_m.
\end{array}
\]
>>>>>>> f2cb40ca9967a5ef6cc325a5ecf49fb6ef047542

Note that because of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+ \dots |\beta_{l,i}| \le 1$, thus the absolute value of $\sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, i}$ is at most one. 

We continue traversing the loop for the third time. Then for each $1 \le j_3 \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^3_{j_3} = \beta_{j_3,0} + \beta_{j_3,1} f^2_1 + \dots + \beta_{j_3,l} f^2_l + \gamma_{j_3,1} d^3_1 + \dots + \gamma_{j_3,m} d^3_m$, where $d^3_1, \dots, d^3_m$ denote the data values introduced when traversing the loop for the third time. 

By expanding the expressions $f^2_1,\dots,f^2_l$, we get the following expression for $f^3_{j_3}$ (where $1\le j_3 \le l$),
\[
\begin{array}{l}
f^3_{j_3} = (\beta_{j_3,0} + \sum \limits_{1 \le j_2 \le l} \beta_{j_3,j_2} (\beta_{j_2,0} + \sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, 0})) +\\
%
 (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,1})) o_1 + \dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\beta_{j_1,l})) o_l +  \\
 %
(\sum \limits_{1 \le j_2 \le l}\beta_{j_3, j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,1})) d^1_1 +\dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}(\sum \limits_{1 \le j_1 \le l}\beta_{j_2,j_1}\gamma_{j_1,m})) d^1_m  + \\
(\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}\gamma_{j_2,1}) d^2_1 +\dots + (\sum \limits_{1 \le j_2 \le l}\beta_{j_3,j_2}\gamma_{j_2,m}) d^2_m  + \\
\gamma_{j_3,1} d^3_1 + \dots + \gamma_{j_3,m} d^3_m.
\end{array}
\]

<<<<<<< HEAD
%In the following, we focus on the non-zero reachability problem of generalized flat \SDSIT$_{\pm}$ such that $|Y_1| = |Y_2|=1$. The more general case is open. \zhilin{See appendix for an incomplete analysis of a lasso in the general case}
=======
Note that because of the ``copyless'' constraint, we know that for each $i: 1 \le i \le l$, $|\beta_{1,i}|+ \dots |\beta_{l,i}| \le 1$, thus the absolute value of $\sum \limits_{1 \le j_1 \le l} \beta_{j_2,j_1} \beta_{j_1, i}$ is at most one. 
>>>>>>> f2cb40ca9967a5ef6cc325a5ecf49fb6ef047542
















We illustrate the argument for this fact with the following example: There are six data variables, $x_1,\dots,x_5$ such that  $G_C$ comprises a cycle $x_1x_2x_3$ and a path $x_4 x_5$. Without loss of generality, we assume that $\chi_1(x_4)=d^1_{\min(I_6)}=d^1_6$. We will show that it is sufficient to traverse the loop for three times.

Let $\chi_2$ be the assignment function that describes the values of the data and output variables after traversing the loop twice. Then for each $j: 1 \le j \le k$, $\chi_2(x_j)=d^2_j$, and for each $j: 1 \le j \le l$, 
\[\chi_2(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_1(y_j) + \beta_{j,1} d^2_{\min(I_1)} + \dots + \beta_{j,r} d^2_{\min(I_r)},\]
where $d^2_{\min(I_1)}=d^2_1 = \chi_1(x_3)=d^1_3$, $d^2_{\min(I_2)}=d^2_2 = \chi_1(x_1)=d^1_1$, $d^2_{\min(I_3)}=d^2_3 = \chi_1(x_2)=d^1_2$, $d^2_{\min(I_4)}=d^2_4 = d^1_{\min(I_6)}=d^1_6$, and $d^2_{\min(I_5)}=\chi_1(x_4)=d^1_4$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_1(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_2(y_j) & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + \alpha^2_{j,1} o_j + (\alpha_{j,1} \beta_{j,1}) d^1_{\min(I_1)} +  \dots + (\alpha_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
& &  \beta_{j,1} d^1_3 + \beta_{j,2} d^1_1 + \beta_{j,3} d^1_2 + \beta_{j,4} d^1_6 + \beta_{j,5} d^1_4 + \beta_{j,6} d^2_{\min(I_6)} + \dots + \beta_{j,r} d^2_{\min(I_r)}\\
& = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}) + (\alpha_{j,1})^2 o_j + (\alpha_{j,1} \beta_{j,1} + \beta_{j,2}) d^1_1 + (\alpha_{j,1}\beta_{j,2}+\beta_{j,3})d^1_2+\\
& & (\alpha_{j,1}\beta_{j,3}+\beta_{j,1})d^1_3 +  (\alpha_{j,1}\beta_{j,4}+\beta_{j,5})d^1_4 + (\alpha_{j,1}\beta_{j,5})d^1_5 + (\alpha_{j,1}\beta_{j,6}+\beta_{j,4})d^1_6 + \\
& & (\alpha_{j,1}\beta_{j,7}) d^1_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^1_{\min(I_r)} + \beta_{j,6} d^2_{\min(I_6)} + \dots + \beta_{j,r} d^2_{\min(I_r)}.
\end{array}
\] 

Let $\chi_3$ be the assignment function that describes the values of the data and output variables after traversing the loop for the third time. Then for each $j: 1 \le j \le k$, $\chi_3(x_j)=d^3_j$, and for each $j: 1 \le j \le l$, 
\[\chi_3(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_2(y_j) + \beta_{j,1} d^3_{\min(I_1)} + \dots + \beta_{j,r} d^3_{\min(I_r)},\]
where $d^3_{\min(I_1)}=d^3_1 = \chi_2(x_3)=d^2_3=d^1_2$, $d^3_{\min(I_2)}=d^3_2 = \chi_2(x_1)=d^2_1=d^1_3$, $d^3_{\min(I_3)}=d^3_3 = \chi_2(x_2)=d^2_2=d^1_1$, $d^3_{\min(I_4)}=d^3_4 = d^2_{\min(I_6)}=d^2_6$, and $d^3_{\min(I_5)}=\chi_2(x_4)=d^2_4=d^1_6$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_2(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_3(y_j) & = & 
%
%(\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}) + (\alpha_{j,1})^3 o_j + (\alpha^2_{j,1} \beta_{j,1}) d^1_{\min(I_1)} +  \dots + (\alpha^2_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
%& &  (\alpha_{j,1}\beta_{j,1}) d^1_3 + (\alpha_{j,1}\beta_{j,2}) d^1_1 + (\alpha_{j,1}\beta_{j,3}) d^1_2 + (\alpha_{j,1}\beta_{j,4}) d^1_6 + (\alpha_{j,1}\beta_{j,5}) d^1_4 + \\
%& & (\alpha_{j,1}\beta_{j,6}) d^2_{\min(I_6)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+\beta_{j,1} d^1_2 + \beta_{j,2}  d^1_3 + \beta_{j,3} d^1_1 + \beta_{j,4} d^2_6 + \\
%& & \beta_{j,5} d^1_6 + \beta_{j,6} d^3_{\min(I_6)} + \dots + \beta_{j,r} d^3_{\min(I_r)}\\
%
%& = & 
(\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}) + \alpha^3_{j,1} o_j + (\alpha^2_{j,1} \beta_{j,1}+ \alpha_{j,1}\beta_{j,2} + \beta_{j,3} ) d^1_1 + \\
& & (\alpha^2_{j,1} \beta_{j,2}+\alpha_{j,1}\beta_{j,3} + \beta_{j,1} ) d^1_2 + (\alpha^2_{j,1} \beta_{j,3} + \alpha_{j,1}\beta_{j,1} + \beta_{j,2}  ) d^1_3 + (\alpha^2_{j,1} \beta_{j,4}+\alpha_{j,1}\beta_{j,5}) d^1_4 +\\
& & (\alpha^2_{j,1} \beta_{j,5}) d^1_5 + (\alpha^2_{j,1} \beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5})d^1_6 + (\alpha^2_{j,1} \beta_{j,7}) d^1_{\min(I_7)}+ \dots + (\alpha^2_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + \\
& & (\alpha_{j,1}\beta_{j,6}+\beta_{j,4}) d^2_{6} + (\alpha_{j,1}\beta_{j,7}) d^2_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+  \\
& &  \beta_{j,6} d^3_{\min(I_6)} + \dots + \beta_{j,r} d^3_{\min(I_r)}.
\end{array}
\] 

Let $\chi_4$ be the assignment function that describes the values of the data and output variables after traversing the loop for the third time. Then for each $j: 1 \le j \le k$, $\chi_4(x_j)=d^4_j$, and for each $j: 1 \le j \le l$, 
\[\chi_4(y_j) = \alpha_{j,0} + \alpha_{j,1} \chi_3(y_j) + \beta_{j,1} d^4_{\min(I_1)} + \dots + \beta_{j,r} d^4_{\min(I_r)},\]
where $d^4_{\min(I_1)}=d^4_1 = \chi_3(x_3)=d^3_3=d^1_1$, $d^4_{\min(I_2)}=d^4_2 = \chi_3(x_1)=d^3_1=d^1_2$, $d^4_{\min(I_3)}=d^4_3 = \chi_3(x_2)=d^3_2=d^1_3$, $d^4_{\min(I_4)}=d^4_4 = d^3_{\min(I_6)}=d^3_6$, and $d^4_{\min(I_5)}=\chi_3(x_4)=d^3_4=d^2_6$.

For each $j: 1 \le j \le l$, 
by expanding the expression $\chi_3(y_j)$, we  get the following expression, 
\[
\begin{array}{l c l}
\chi_4(y_j) & = & (\alpha_{j,0} + \alpha_{j,1} \alpha_{j,0}+ \alpha^2_{j,1} \alpha_{j,0}+\alpha^3_{j,1} \alpha_{j,0}) + \alpha^4_{j,1}  o_j + (\alpha^3_{j,1} \beta_{j,1}+ \alpha^2_{j,1}\beta_{j,2} + \alpha_{j,1}\beta_{j,3} + \beta_{j,1}) d^1_1 + \\
& & (\alpha^3_{j,1} \beta_{j,2}+\alpha^2_{j,1}\beta_{j,3} + \alpha_{j,1}\beta_{j,1} + \beta_{j,2}) d^1_2 + (\alpha^3_{j,1} \beta_{j,3} + \alpha^2_{j,1}\beta_{j,1} + \alpha_{j,1}\beta_{j,2} +\beta_{j,3}) d^1_3 + \\
& & (\alpha^3_{j,1} \beta_{j,4}+\alpha^2_{j,1}\beta_{j,5}) d^1_4 + (\alpha^3_{j,1} \beta_{j,5}) d^1_5 + (\alpha^3_{j,1} \beta_{j,6}+\alpha^2_{j,1}\beta_{j,4}+\alpha_{j,1}\beta_{j,5})d^1_6 + \\
& & (\alpha^3_{j,1} \beta_{j,7}) d^1_{\min(I_7)}+ \dots + (\alpha^3_{j,1} \beta_{j,r}) d^1_{\min(I_r)} + 
 (\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4} + \beta_{j,5}) d^2_{6} + \\
 & & (\alpha^2_{j,1}\beta_{j,7}) d^2_{\min(I_7)} + \dots + (\alpha^2_{j,1}\beta_{j,r}) d^2_{\min(I_r)}+  (\alpha_{j,1}\beta_{j,6}+\beta_{j,4}) d^3_{6} +  \\
 & & (\alpha_{j,1}\beta_{j,7}) d^3_{\min(I_7)} + \dots + (\alpha_{j,1}\beta_{j,r}) d^3_{\min(I_r)} + \beta_{j,6} d^4_{\min(I_6)} + \dots +  \beta_{j,r} d^4_{\min(I_r)}.
\end{array}
\] 

Consider the coefficient of $o_j, d^1_5, d^1_{\min(I_7)},\dots,d^1_{\min(I_r)}$.
\begin{itemize}
\item $\alpha^4_{j,1}o_j = \alpha^2_{j,1}o_j$, $(\alpha^3_{j,1} \beta_{j,5}) d^1_5 = (\alpha_{j,1} \beta_{j,5}) d^1_5$,
\item $(\alpha^3_{j,1} \beta_{j,7}) d^1_{\min(I_7)}= (\alpha_{j,1} \beta_{j,7}) d^1_{\min(I_7)}$, $\dots$, $(\alpha^3_{j,1} \beta_{j,r}) d^1_{\min(I_r)}= (\alpha_{j,1} \beta_{j,r}) d^1_{\min(I_r)}$.
\end{itemize}
Therefore, all these coefficients are the same as those in $\chi_2(y_j)$.

Let us check the constant coefficient and the coefficients of $d^1_1,d^1_2,d^1_3,d^1_4,d^1_5$ and $d^1_6,d^2_6,\dots$.

\begin{itemize}
\item The constant coefficient and the coefficient of $d^1_1$, $d^1_2$, $d^1_3$ can be seen as integer counters.  

\item The coefficient of $d^1_4$ is $\alpha_{j,1} \beta_{j,4}+\beta_{j,5}, \alpha_{j,1}(\alpha_{j,1} \beta_{j,4}+\beta_{j,5}), \alpha^2_{j,1}(\alpha_{j,1} \beta_{j,4}+\beta_{j,5}), \dots$.

\item The coefficient of $d^1_5$ is $\beta_{j,5},\alpha_{j,1}\beta_{j,5}, \alpha^2_{j,1}\beta_{j,5},\alpha^3_{j,1}\beta_{j,5},\dots$.

\item The coefficient of $d^1_6$ (resp. $d^2_6,d^3_6,\dots$) is $\beta_{j,6}, \alpha_{j,1}\beta_{j,6}+\beta_{j,4}, \alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}, \alpha_{j,1}(\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}),\alpha^2_{j,1}(\alpha^2_{j,1}\beta_{j,6}+\alpha_{j,1}\beta_{j,4}+\beta_{j,5}),\dots$.
\end{itemize}
Since $\alpha_{j,1} \in\{0,+1,-1\}$, the values of the coefficients of $d^1_4,d^1_5$ and $d^1_6,d^2_6,d^3_6,\dots$ are from a bounded domain.












\subsection{The analysis of a lasso with independently evolving multiple output variables}

Let $\Ss=(Q, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. 

We assume that $X=\emptyset$, thus all the guards in the transitions are trivial. Let $Y=\{y_1,\dots,y_l\}$. In addition, we assume that all the output variable are \emph{independently evolving} in the sense that for each transition $(q,g, \eta, q')$, it holds that for each $y \in Y$, only $y$ can occur in $\eta(y)$ and no other output variables can occur in $\eta(y)$. 

Suppose $q_0 q_1 \dots q_n C$ is a lasso where $C=p_0 p_1 \dots p_m$, $p_0 = p_m=q_n$, $O(q_n)$ is defined and $O(p_j)$ is undefined for each $j \neq 0,m$. $q_0 \dots q_n$ is called the handle of the lasso and $C$ is called the loop of the lasso. For each $i: 0 \le i < n$, $(q_i, g_i, \eta_i, q_{i+1})$ is the $i$-th transition in the handle, and for each $j: 0 \le j < m$, $(p_j, g'_j, \eta'_j, p_{j+1})$ is the $j$-th transition in the handle. 

In the following, we will illustrate that if only the non-zero output problem is concerned, then no matter what the initial values of the output variables are, it is sufficient to traverse the loop for a bounded number of times.

%Suppose $O(q_n) = a_0 + a_1 y_1 + \dots + a_l y_l$. As a result of the ``copyless'' constraint, we know that $|a_1|, \dots, |a_l| \le 1$.

Let us traverse the loop for the first time. Then for each $1 \le j \le l$, an expression 
\[f^1_{j} = \beta_{j,0} + \beta_{j} o_{j} + \gamma_{j,1} d^1_1 + \dots + \gamma_{j,m} d^1_m\] 
can be constructed to describe the value of the variable $y_{j}$ after traversing the loop for the first time, where $o_1,\dots,o_l$ denote the initial value of the output variables and $d^1_1, \dots, d^1_m$ denote the data values introduced when traversing the loop for the first time. Note that as a result of ``independently evolving'' constraint, for each $j: 1 \le j \le l$, $f^1_{j}$ contains only $o_{j}$ and no other output variables. Moreover, because of ``copyless'' constraint, $\beta_j \in \{0,+1,-1\}$.

Suppose $O(q_n)=a_0 + a_1 o_1 + \dots a_l o_l$. 

Let $\chi_1$ be the assignment $\chi_1(y_j)=f^1_j$ for each $j: 1\le j \le l$.
Then $\chi_1(O(q_n)) = a_0+ a_1 f^1_1 + \dots a_l f^1_l$ is the following expression,
\[
(a_0 + \sum \limits_{1 \le j \le l} (a_j\beta_{j,0})) +  (a_1 \beta_1) o_1 + \dots + (a_l \beta_l) o_l + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^1_m.
\]

If $(\sum \limits_{1 \le j \le l} a_j \gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j \gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.

We then traverse the loop for the second time. Then for each $1 \le j \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^2_{j} = \beta_{j,0} + \beta_{j} f^1_{j} + \gamma_{j,1} d^2_1 + \dots + \gamma_{j,m} d^2_m$, where $d^2_1, \dots, d^2_m$ denote the data values introduced when traversing the loop for the second time. 

By expanding the expressions $f^1_1,\dots, f^1_l$, we get the following expression for $f^2_{j}$ (where $1 \le j \le l$),
\[
%\begin{array}{l}
f^2_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0}) + (\beta_{j})^2 o_{j} +
%\\
(\beta_{j}\gamma_{j,1}) d^1_1 +\dots + (\beta_{j}\gamma_{j,m}) d^1_m  + 
%\\
\gamma_{j,1} d^2_1 + \dots + \gamma_{j,m} d^2_m.
%\end{array}
\]

Let $\chi_2$ be the assignment $\chi_2(y_j)=f^2_j$ for each $j: 1\le j \le l$.
Then $\chi_2(O(q_n)) = a_0+ a_1 f^2_1 + \dots a_l f^2_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0})) +  (a_1 (\beta_1)^2) o_1 + \dots + (a_l (\beta_l)^2) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j \beta_{j}\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_{j}\gamma_{j,m}) d^1_m + \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^2_m.
\end{array}
\]

If $(\sum \limits_{1 \le j \le l} a_j \beta_j\gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j \beta_j\gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.


We continue traversing the loop for the third time. Then for each $1 \le j \le l$,  the resulting value of the variable $y_{j}$ is described by the expression $f^3_{j} = \beta_{j,0} + \beta_{j} f^2_j  + \gamma_{j,1} d^3_1 + \dots + \gamma_{j,m} d^3_m$, where $d^3_1, \dots, d^3_m$ denote the data values introduced when traversing the loop for the third time. 

By expanding the expressions $f^2_1,\dots,f^2_l$, we get the following expression for $f^3_{j}$ (where $1\le j \le l$),
\[
\begin{array}{l}
f^3_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0}) + (\beta_{j})^3 o_{j} +
%\\
((\beta_{j})^2\gamma_{j,1}) d^1_1 +\dots + ((\beta_{j})^2\gamma_{j,m}) d^1_m  + \\
%\\
(\beta_j \gamma_{j,1}) d^2_1 + \dots + (\beta_j \gamma_{j,m}) d^2_m + \gamma_{j,1} d^3_1 + \dots + \gamma_{j,m} d^3_m.
\end{array}
\]

Let $\chi_3$ be the assignment $\chi_3(y_j)=f^3_j$ for each $j: 1\le j \le l$.
Then $\chi_3(O(q_n)) = a_0+ a_1 f^3_1 + \dots a_l f^3_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0})) +  (a_1 (\beta_1)^3) o_1 + \dots + (a_l (\beta_l)^3) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,m}) d^1_m + \\
(\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,m}) d^2_m \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^3_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^3_m. 
\end{array}
\]

Since for each $j: 1 \le j \le l$, $\beta_j \in \{0,+1,-1\}$, we know that for each $j: 1 \le j \le l$, $(\beta_j)^3=\beta_j$. Therefore, $(a_1 (\beta_1)^3) o_1 + \dots + (a_l (\beta_l)^3) o_l = (a_1 \beta_1) o_1 + \dots + (a_l \beta_l) o_l$.

If $(\sum \limits_{1 \le j \le l} a_j (\beta_j)^2\gamma_{j,i}) \neq 0$ for some $i: 1 \le i \le m$, then there is an input $w$ such that the output of $\Ss$ over $w$ is non-zero. Therefore, in the following, we assume that $(\sum \limits_{1 \le j \le l} a_j (\beta_j)^2\gamma_{j,i}) = 0$ for each $i: 1 \le i \le m$.


We continue traversing the loop for the fourth time. Then for each $1 \le j \le l$, the resulting value of the variable $y_j$ is described by the expression 
\[
\begin{array}{l}
f^4_{j} = (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0}+(\beta_j)^3 \beta_{j,0}) + (\beta_{j})^4 o_{j} +
\\
((\beta_{j})^3\gamma_{j,1}) d^1_1 +\dots + ((\beta_{j})^3 \gamma_{j,m}) d^1_m  + 
((\beta_{j})^2\gamma_{j,1}) d^2_1 +\dots + ((\beta_{j})^2 \gamma_{j,m}) d^2_m \\
(\beta_j \gamma_{j,1}) d^3_1 + \dots + (\beta_j \gamma_{j,m}) d^3_m + \gamma_{j,1} d^4_1 + \dots + \gamma_{j,m} d^4_m.
\end{array}
\]

Let $\chi_4$ be the assignment $\chi_4(y_j)=f^4_j$ for each $j: 1\le j \le l$.
Then $\chi_4(O(q_n)) = a_0+ a_1 f^4_1 + \dots a_l f^4_l$ is the following expression,
\[
\begin{array}{l}
(a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + (\beta_j)^2 \beta_{j,0} + (\beta_j)^3 \beta_{j,0})) +  (a_1 (\beta_1)^4) o_1 + \dots + (a_l (\beta_l)^4) o_l + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,1}) d^1_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,m}) d^1_m + \\
 (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,1}) d^2_1 + \dots + (\sum \limits_{1 \le j \le l} a_j (\beta_{j})^2\gamma_{j,m}) d^2_m + \\
(\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,1}) d^3_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \beta_j \gamma_{j,m}) d^3_m \\
(\sum \limits_{1 \le j \le l} a_j \gamma_{j,1}) d^4_1 + \dots + (\sum \limits_{1 \le j \le l} a_j \gamma_{j,m}) d^4_m. 
\end{array}
\]

Since for each $j: 1\le j \le l$, $(\beta_j)^3=\beta_j$, we deduce that $(\sum \limits_{1 \le j \le l} a_j (\beta_{j})^3\gamma_{j,i}) = (\sum \limits_{1 \le j \le l} a_j \beta_{j} \gamma_{j,i}) =0$ for each $i: 1\le i \le m$.

Since $\beta_j \in \{0,+1,-1\}$, we know that for each $j: 1\le j \le l$, $(\beta_j)^4=(\beta_j)^2$. Therefore, $(a_1 (\beta_1)^4) o_1 + \dots + (a_l (\beta_l)^4) o_l=(a_1 (\beta_1)^2) o_1 + \dots + (a_l (\beta_l)^2) o_l$.

Therefore, if the constant coefficient is ignored, then it is sufficient to traverse the loop for \emph{three times}.

For the consideration of the constant coefficient, let us assume that for each $j: 1 \le j \le l$, 
$o_j = \alpha_{j,0} + \alpha_{j,1} d_1+ \dots + \alpha_{j,n}d_n$, where $d_1,\dots,d_n$ are the data values introduced in the handle.

Then the constant coefficient after traversing the loop for $r$ times ($r \ge 1$) is described by the following expression,
\[a_0 + \sum \limits_{1 \le j \le l} a_j (\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}).\]

Since for each $j: 1 \le j \le l$, $\beta_j \in \{0,+1,-1\}$, we know that 
\begin{itemize}
\item if if $\beta_j=0$, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}=\beta_{j,0}$,
%
\item if $\beta_j=1$, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}=r\beta_{j,0} + \alpha_{j,0}$,
%
\item if $\beta_j = -1$ and $r$ is odd, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}= \beta_{j,0} - \alpha_{j,0}$,

\item if $\beta_j = -1$ and $r$ is even, then $\beta_{j,0} + \beta_{j} \beta_{j,0} + \dots + (\beta_j)^{r-1} \beta_{j,0} + (\beta_j)^r \alpha_{j,0}= 2\beta_{j,0} + \alpha_{j,0}$.
\end{itemize}

Therefore, the non-zero output problem is reduced to the following problem: 
\begin{quote}
\it Given an expression of the form $c_0+c_1 r$, where $c_0 ,c_1$ are constants, and $r$ is a variable ranging over natural numbers, decide whether there exists $r$ such that $c_0+ c_1 r$ is non-zero. 
\end{quote}

\zhilin{I stopped here}



\subsection{Flat transducer with independently evolving output variables}

Let $\Ss=(Q, K, X, Y, \delta, q_0, O)$ be a \SDSIT$_{\pm}$. Suppose $X=\{x_1,\dots,x_k\}$ and $Y=\{y_1,\dots,y_l\}$. For simplicity, we assume that $K = 1$, that is, each position holds one data value.

A path scheme is a path in the SCC graph, which corresponds to a sequence of SCCs in the transition graph such that for each pair of consecutive SCCs in the sequence, say $C_1$ and $C_2$, there is an edge from $C_1$ to $C_2$.

Let us fix a path scheme, say $C_0 \dots C_n$.

For simplicity, let us start with the easy case that for each $i: 0 \le i < n$, $C_i$ is a single state and $C_n$ contains more than one node, that is, $C_0 \dots C_n$ is $q_0 \dots q_{n-1} q_n (C^1_n,\dots,C^m_n)$, where $C^1_{n},\dots, C^m_n$ are the collection of simple cycles in $C_n$ which share a unique state $q_{n}$. Moreover, we assume that $O(q_n)$ is defined and $O$ is undefined in each of the other states of $C_n$.

Without loss of generality, assume that each state in $C_0 \dots C_n$ is reachable. It is known that the state reachability problem of flat register automata is PSPACE-complete (\cite{DL09}). 

%Recall that we assume that $\Ss$ is copyless.

We show by induction that for each $i: 1 \le i \le n$ and each variable $x_j$ (resp. $y_j$), an arithmetic expression $e_{i,x_j}$ (resp. $e_{i,y_j}$) corresponding to $x_j$(resp. $y_j$) after going through the state sequence $q_0 \dots q_i$ can be constructed. Let $(q_{i}, 1, g_{i}, \eta_{i}, q_{i+1})$ be the $i$-th transition for each $i: 0 \le i < n$.

For each $j: 1 \le j \le k$, if $\eta_1(x_j)=p_1$, then $e_{1,x_j}=d_1$, otherwise, $e_{1,x_j}=\bot$.

For each $j: 1 \le j \le l$, $e_{1,y_j} = (\eta_{1,y_j}[d_1/p_1])$. 

For each $i: 1 < i \le n$, 
\begin{itemize}
\item for each $j: 1 \le j \le k$, $e_{i,x_j}=d_i$ if $\eta_i(x_j)=p_1$, and $e_{i,x_j}=e_{i-1,x_j}$ otherwise,
%
\item for each $j: 1 \le j \le l$, $e_{i,y_j} = \theta_i(\eta_i(y_j))$, where $\theta_i(x_{j'})=e_{i-1,x_{j'}}$ and $\theta_i(y_{j'})=e_{i-1, y_{j'}}$, and $\theta_i(p_1)=d_i$.
\end{itemize}

Then for each $j$, $e_{n,y_j} = c_{0,j} + c_{1,j} d_1 + \dots + c_{n,j} d_n$, where $c_{0,j},\dots, c_{n,j}$ are integer constants.

\smallskip

\noindent {\bf Step 1}: Decide whether $\theta_{n+1}(O(q_n))$ is not identical to zero (it is easy to do so, just check the coefficients of $d_1,\dots,d_n$), where $\theta_{n+1}(x_j)=e_{n,x_j}$ and $\theta_{n+1}(y_j)=e_{n,y_j}$. If the answer is yes, then we are done. Otherwise, we will continue checking the cycles of $C_n$.

Similarly, for each cycle $C^i_n = q'_0 q'_1 \dots q'_{l_i}$ such that $q'_0 = q'_{l_i}=q_n$, we can construct expressions $e'_{i,x_j}$ and $e'_{i,y_j}$ where the variables $x_1,\dots,x_k,y_1,\dots,y_l$ and the data value variables $d'_1,\dots,d'_{l_i}$ occur. Note that $x_1,\dots,x_k,y_1,\dots,y_l$ denote the values of these variables before executing the transitions in the cycle.

\smallskip

\noindent {\bf Step 2}: Iterate the following procedure for $i = 1, \dots, m$.
\begin{enumerate}
\item Consider $\theta'_i(O(q_n))$, where $\theta'_i(x_j)=e'_{i,x_j}$ and $\theta'_i(y_j)=e'_{i,y_j}$. 
%
\item If there is $j: 1 \le j \le l_i$ such that the coefficient of $d'_j$ in $\theta'_i(O(q_n))$ is nonzero, then we are done. 
\end{enumerate}

\smallskip

\noindent {\bf Step 3}: Let $\theta''_0=\theta_{n+1}$ and $\theta''_i = \theta''_{i-1}(\theta'_i)$ for $i = 1, \dots, m$.  Continue iterating the following procedure for $i = 1, \dots, m$:   If in $\theta''_i(O(q_n))$, the constant coefficient or the coefficient of some $d_{i'}$ for some $i': 1 \le i' \le n$ is nonzero, then we are done. 

\zhilin{These three steps are basically what I thought. But Step 3 is incorrect. Since we may need iterate over a cycle for multiple times to reach nonzero output. For some special cases, e.g. difference constraints or octagon constraints, we can use Presburger formula to summarize the effect of a cycle}.

\zhilin{My current feeling is that the problem is indeed more difficult than what we thought. Therefore, let us focus on the problem at present. We will try to work for CAV. If in the end we do not work out a submittable version, then we will target another conference.}

\subsection{Generalized flat transducer with independently evolving output variables}






Step I, II, III.



In general, for each $j' \in J_{1,1}$ and each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$), the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \ \ \  (\ast)\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast)$ is of the form 
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j  s_j (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')},\]
where $s_j \in \{0,+1,-1\}$.

The expression $(\ast)$ can be rewritten as $\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')}$ for some integer constant $\mu_{\schm,(1,j')},\nu_{\schm,(1,j')}$ (possibly $\mu_{\schm,(1,j')}=0$). 


In the following, we will illustrate the argument for the case $n=2$, that is, there are only two cycles.


\smallskip

\noindent {\bf Step I}. Decide whether $\chi_0(O(q_m))$ is not identical to zero (it is easy to do so, just check the coefficients of $d^0_1, \dots, d^0_s$). If the answer is yes, then the decision procedure terminates and returns the answer $true$. Otherwise, the decision procedure continues.

\smallskip

For the cycle $C_b$ (where $b=1,2$), the assignment function $\chi_{b,\ell}$ can be defined to describe the values of the control and output variables after traversing the cycle $C_b$ for $\ell$ times.

Suppose that for $b=1,2$, the initial values of the $k$ control variables are $d^0_{\pi_0(1)},\dots,d^0_{\pi_0(k)}$. Moreover, suppose that the $r_b$ data values $d^1_{1}, \dots, d^1_{r_b}$ are introduced when traversing the cycle for the first time, with one data value for each of $I_{1},\dots,I_{r_b}$. 
In addition, suppose that the initial values of $y_1,\dots, y_l$ are $o_1,\dots,o_l$. 

Then for $b=1,2$, the assignment function $\chi_{b,1}$ is of the following form,
\begin{itemize}
\item there is an injective mapping $\pi_b: \{1,\dots,k\} \rightarrow \{1,\dots, k+r_b\}$ such that for each $x_j \in X$, if $\pi_b(j) \le k$, then $\pi_b(j)=j$ and $\chi_{b,1}(x_j)=d^0_{\pi_0(j)}$, otherwise, $\chi_{b,1}(x_j)=d^1_{\pi_b(j)-k}$,
% 
\item for each $y_j \in Y$, $\chi_{b,1}(y_j) = \alpha_{b,(j,0)} + \alpha_{b,(j,1)} o_j + \beta_{b,(j,1)} d^0_{\pi_0(1)} + \dots + \beta_{b,(j,k)} d^0_{\pi_0(k)} + \gamma_{b,(j,1)} d^1_1 +\dots + \gamma_{b,(j,r_b)} d^1_{r_b}$ such that $\alpha_{b,(j,1)} \in \{0,+1,-1\}$.
\end{itemize}

Let $J_{b,1}$ be set of indices $j \in \{1,\dots,k+r_b\}$ such that $\pi_b(j)= j$ and $J_{b,2} = \{1,\dots,k\} \setminus J_{b,1}$. Intuitively, the values of the variables from $J_1$ are  unchanged after traversing the cycle once, and the values of the variables from  $J_{b,2}$ are changed. Then $(J_{b,1}, J_{b,2})$ forms a partition of $\{1,\dots,k\}$. Moreover, let $J_{b,3}=\{\pi_b(j)-k \mid j \in J_{b,2}\}$ and $J_{b,4} = \{1,\dots,r_b\} \setminus J_{b,3}$. Then $(J_{b,3}, J_{b,4})$ forms a partition of $\{1,\dots,r_b\}$.

We will present the argument for the situation that $J_{1,1} \cap J_{2,1} \neq \emptyset$, $J_{1,1} \setminus J_{2,1} \neq \emptyset$, and $J_{2,1} \setminus J_{1,1} \neq \emptyset$.

A \emph{cycle scheme} $\schm$ is a sequence $\schm=(1,\ell_1) (2, \ell_2 ) \dots (((m-1) \bmod 2)+1, \ell_m)$ such that $\ell_1,\dots, \ell_m \ge 1$. The number $m$ is called the length of the cycle scheme $\schm$. In principle, for each cycle scheme $\schm$, the expressions $\chi_{\schm}(y_j)$ can be defined to describe the values of $y_j$ after traversing the cycles according to $\schm$.

%\begin{proposition}\label{prop-mult-cycle}
%From a cycle scheme $\schm=(1,\ell_1) (2, \ell_2 ) \dots (((m-1) \bmod 2)+1, \ell_m)$, for each $j: 1 \le j \le l$, an expression $\chi_{\schm}(y_j)$ can be constructed from $\chi_{(1,\ell_1)}(y_j),\dots,\chi_{(((m-1) \bmod 2)+1, \ell_m)}(y_j)$ by collecting all the data variables therein and some linear combinations of their coefficients.
%\end{proposition}

In the following, we first show how to construct the expressions $\chi_{(1,\ell_1)(2,\ell_2)}$ for a cycle scheme $(1,\ell_1)(2,\ell_2)$ such that $\ell_1,\ell_2 \ge 2$, to describe the values of the control and data variables after traversing $C_1$ for $\ell_1$ times and $C_2$ for $\ell_2$ times.

At first, from the analysis of cycles, we know that
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)}(y_j)  & = & (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) + \alpha^{\ell_1}_{1,(j,1)} o_j + \\
& & \sum \limits_{j' \in J_{1,1}} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{1,2}} (\alpha^{\ell_1-1}_{1,(j,1)}\beta_{1,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')}) d^1_{j'} + \dots + \sum \limits_{j' \in J_{1,3}} (\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha_{1,(j,1)} \gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \gamma_{1,(j, 1)} d^{\ell_1}_{1} + \dots + \gamma_{1,(j,r_1)} d^{\ell_1}_{r_1},
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi_{(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)}) + \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{2,1}} (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{2,2}} (\alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+\\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{j'} +  \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{r_2}.
\end{array} 
\]

The coefficients of $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ can be obtained those of $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ as follows: For each $i: 1 \le i \le \ell_1$ and $j': 1 \le j' \le r_1$, let $d^i_{j'}$ denote the data values introduced when traversing $C_1$, and for each  $i: 1 \le i \le \ell_2$ and $j': 1 \le j' \le r_2$, let $d^{i}_{(1, \ell_1),j'}$ denote the data values introduced when traversing $C_2$ for $\ell_2$ times (after traversing $C_1$ for $\ell_1$ times).
\begin{itemize}
\item The coefficient of $o_j$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\theta_1\theta_2$, where $\theta_1$ and $\theta_2$ are the coefficient of $o_j$ in $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.
%
\item The constant coefficient of $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1,\theta_2$ are the constant coefficient of $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.
%
\item For each $j': 1 \le j' \le k$, suppose $\chi_{(1,\ell_1)}(x_{j'})=d^{i}_{j'}$, then the coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1,\theta_2$ are the  coefficient of $d^i_{j'}$ in $\chi_{(1,\ell_1)}(y_j)$ and $\chi_{(2,\ell_2)}(y_j)$ respectively.  
%
%\item For $j' \in J_{1,2}$, the coefficient of $d^{\ell_1}_{\pi_1(j')-k}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta_1 + \theta_2$, where $\theta_1$ is the  coefficient of $d^{\ell_1}_{\pi_1(j')-k}$ in $\chi_{(1,\ell_1)}(y_j)$ and $\theta_2$ is the coefficient of $d^0_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$.
%
\item For each pair $(i,j')$ such that $d^i_{j'} \not \in \{\chi_{(1,\ell_1)}(x_{j''}) \mid 1 \le j'' \le k\}$, the coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\alpha^{\ell_2}_{2,(j,1)} \theta$, where $\theta$ is the  coefficient of $d^{i}_{j'}$ in $\chi_{(1,\ell_1)}(y_j)$.
%
\item For each pair $(i,j')$ such that $1 \le i \le \ell_2$ and $j' \in J_{2,3} \cup J_{2,4}$, the coefficient of $d^{i}_{(1, \ell_1),j'}$ in $\chi_{(1,\ell_1)(2,\ell_2)}(y_j)$ is $\theta$, where $\theta$ is the  coefficient of $d^{i}_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$, where $d^{i}_{(1, \ell_1),j'}$ is the data variable corresponding to $d^{i}_{j'}$ in $\chi_{(2,\ell_2)}(y_j)$, decorated with $(1,\ell_1)$.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
More specifically, 
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)} + \\
%
& & \alpha^{\ell_2}_{2,(j,1)} (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) ) + \alpha^{\ell_1}_{1,(j,1)} \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{1,1} \cap J_{2,1}} (\alpha^{\ell_2}_{2,(j,1)} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) + \\
%
& & (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')})) d^0_{j'}  + \\
%
& & \sum \limits_{j' \in J_{1,2} \cap J_{2,1}} (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j,\pi_1(j')-k)} + \beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots + \\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^{\ell_1}_{\pi_1(j')-k} + \\
%
& & \sum \limits_{j' \in J_{1,1} \cap J_{2,2}}  (\alpha^{\ell_2}_{2,(j,1)} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')})+ \\
& & \alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{j'} +\\
%
& & \sum \limits_{j' \in J_{1,2} \cap J_{2,2}}  (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j,\pi_1(j')-k)}+ \alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^{\ell_1}_{\pi_1(j')-k}  +\\
%
& & \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')})) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')})) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_2}_{2,(j,1)}(\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')})) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_2}_{2,(j,1)}(\alpha_{1,(j,1)} \gamma_{1,(j,j')})) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j'+k \not \in \pi_1(J_{1,2})} (\alpha^{\ell_2}_{2,(j,1)} \gamma_{1,(j, j')}) d^{\ell_1}_{j'}+ \\
%
& & \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{(1,\ell_1),j'} +  \\
%
& & \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{(1,\ell_1),j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{(1,\ell_1), j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{(1,\ell_1), j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{(1,\ell_1), 1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{(1,\ell_1), r_2}.
\end{array} 
\]
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\smallskip

\noindent {\bf Step II}. For $b=1,2$, let 
\[
\begin{array}{l c l}
\chi_{(b,\ell_b)}(O(q_m)) & = & a_0 + a_1 \chi_{(b,\ell_b)}(x_1) + \dots a_k \chi_{(b,\ell_b)}(x_k) + \\
& & a'_1 \chi_{(b,\ell_b)}(y_1) + \dots + a'_l \chi_{(b,\ell_b)}(y_l).
\end{array}
\] 

Then $\chi_{(b,\ell_b)}(O(q_m))$ is a linear combination of the variables $d^0_1,\dots, d^0_s$ and $d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$.

For each $j' \in J_{b,1}$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{(b,\ell_b)}(O(q_m))$ is 

\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\beta_{b,(j,j')}.\]

In general, for each $j' \in J_{1,1}$ and each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$), the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \ \ \  (\ast)\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast)$ is of the form 
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j  s_j (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')},\]
where $s_j \in \{0,+1,-1\}$.

The expression $(\ast)$ can be rewritten as $\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')}$ for some integer constant $\mu_{\schm,(1,j')},\nu_{\schm,(1,j')}$ (possibly $\mu_{\schm,(1,j')}=0$). 

If there are a cycle scheme $\schm$ starting from $C_1$  and $j' \in J_{1,1}$ such that $\mu_{\schm,(1,j')} \neq 0$, then return $true$. Note that in this case, we can let $\ell_1$ and $d^0_{\pi_0(j')}$ sufficiently large so that $(\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')})d^0_{\pi_0(j')}$ dominates $\chi_{\schm}(O(q_m))$ and $\chi_{\schm}(O(q_m))$ becomes non-zero. We would like to remark that although there are infinitely many cycle schemes $\schm$, the constants $\mu_{\schm,(1,j')}$ can only have values from a bounded domain. Therefore, it is decidable whether there exist such a desired cycle scheme $\schm$ starting from $C_1$ and $j' \in J_{1,1}$.

The similar discussion can be applied to $C_2$ and $J_{2,1}$.

If there are no desired cycle schemes $\schm$ and $j'$ for $C_1$ and $J_{1,1}$, as well as for  $C_2$ and $J_{2,1}$, then the decision procedure continues.

The constant coefficient in $\chi_{(b,\ell_b)}(O(q_m))$ is 

\[a_0 + \sum \limits_{1 \le j \le l} a'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)}.\]

In general, for each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$), the constant coefficient in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a_0 + \sum \limits_{1 \le j \le l} a'_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)}. \ \ \  (\ast\ast)\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast\ast)$ is of the form 
\[a_0 + \sum \limits_{1 \le j \le l} a'_j  s'_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\alpha_{b,(j,0)},\]
where $s'_j \in \{0,+1,-1\}$.

The expression $(\ast\ast)$ can be rewritten as $\mu_{\schm,(1,0)} \ell_1 + \nu_{\schm,(1,0)}$ for some integer constant $\mu_{\schm,(1,0)},\nu_{\schm, (1,0)}$ (possibly $\mu_{\schm,(1,0)}=0$). 

If there are a cycle scheme $\schm$ starting from $C_1$ such that $\mu_{\schm,(1,0)} \neq 0$, then return $true$. Note that in this case, we can let $\ell_1$ sufficiently large so that $\mu_{\schm,(1,0)} \ell_1 + \nu_{\schm,(1,0)}$ dominates $\chi_{\schm}(O(q_m))$ and $\chi_{\schm}(O(q_m))$ becomes non-zero. We would like to remark that although there are infinitely many cycle schemes $\schm$, the constants $\mu_{\schm,(1,0)}$ can only have values from a bounded domain. Therefore, it is decidable whether there exist such a desired cycle scheme $\schm$ starting from $C_1$.

A similar discussion for the constant coefficient can be applied to the cycle schemes starting from $C_2$.

If the decision procedure has not returned yet, then we go to Step III. 

\smallskip

\noindent {\bf Step III}. For each cycle scheme $\schm=(1,\ell_1) (2,\ell_2) \dots (1+ (t-1) \bmod 2,\ell_t)$ or $\schm=(2,\ell_1) (1,\ell_2) \dots (1+ (t-1) \bmod 2,\ell_t)$, we can ignore all the expressions of the form $c\ \ell_1,\dots, c\ \ell_m$ (where $c$ is an integer constant) in $\chi_{\schm}(y_j)$, since these expressions will disappear for sure in $\chi_{\schm}(O(q_m))$, according to the analysis above. From this observation, we can show that the constant coefficient as well as the coefficients for $d^0_{\pi_0(j')}$ with $j' \in J_{1,1} \cap J_{2,1}$ in $\chi_{\schm}(y_1),\dots,\chi_{\schm}(y_l), \chi_{\schm}(O(q_m))$ can be calculated by a $\intnum$-VAS (cf. \cite{HH14}), that is, an integer vector addition system. Moreover, all the other coefficients in $\chi_{\schm}(y_1),\dots,\chi_{\schm}(y_l), \chi_{\schm}(O(q_m))$ are from a bounded domain, no matter how long the scheme $\schm$ is.  

Therefore, in this case, the non-zero output reachability problem is reduced to the non-zero reachability problem of $\intnum$-VAS, that is, given an index $i$, decide whether a vector $\vec{z}$ where $z_i$ is non-zero can be reached.  It is not hard to see that the non-zero reachability problem of $\intnum$-VAS can be reduced to the coverability problem of $\intnum$-VAS. From the fact that the coverability of $\intnum$-VAS is NP-complete (\cite{HH14}),  we conclude that the non-zero output reachability of SNS$\pm$ whose transition graph is a generalized lasso is decidable.




The coefficients in $\chi'_{\schm}(y_j)$ are either $\theta_2 + \alpha^{(C_{i_2})}_{j,1}\theta_1 $, or $\alpha^{(C_{i_2})}_{j,1}\theta_1$, or $\theta_2$, where $\theta_1$ and $\theta_2$ are the counterpart coefficients in $(\chi^{(C_{i_1})}_{\ell_1})'$ and $(\chi^{(C_{i_2})}_{\ell_2})'$ respectively.

\zhilin{the rest to be cleaned}

If $\alpha^{(C_{i_1})}_{j,1} = 0$ and $\alpha^{(C_{i_2})}_{j,1} = 0$, then in $\chi'_\schm(y_j)$,
\begin{itemize}
\item the constant coefficient is $\alpha^{(C_{i_2})}_{j,0} + \alpha^{(C_{i_2})}_{j,1}  \alpha^{(C_{i_1})}_{j,0} = \alpha^{(C_{i_2})}_{j,0}$,
%
%
\item for $j': j' \le k, \pi_{C_{i_1}}(j') = j'$, the coefficient of $d^{(0)}_{j'}$ is $\beta^{(C_{i_2})}_{j,j'} + \alpha^{(C_{i_2})}_{j,1} \beta^{(C_{i_1})}_{j,j'} = \beta^{(C_{i_2})}_{j,j'}$,
%
\item for $j': j' \le r_{C_{i_1}}, j'+k \in \rng(\pi_{C_{i_1}})$, the coefficient of $d^{(C_{i_1},\ell_1)}_{j'}$ is $\beta^{(C_{i_2})}_{j, \pi^{-1}_{C_{i_1}}(j'+k)} $,
%
\item for $j': 1 \le j' \le r_{C_{i_2}}, j'+k \in \rng(\pi_{C_{i_2}})$, the coefficient of $d^{C_{i_2},\ell_2-1}_{j'}$ is $\beta^{(C_{i_2})}_{j, \pi^{-1}_{C_{i_2}}(j'+k)}$,
%
\item for $j': 1 \le j' \le r_{C_{i_2}}$, the coefficient of $d^{C_{i_2},\ell_2}_{j'}$ is $\gamma^{(C_{i_2})}_{j, j'}$,
%
\item all the other coefficients are zero.
\end{itemize}

If $\alpha^{(C_{i_1})}_{j,1} = 0$ and $\alpha^{(C_{i_2})}_{j,1} = 1$, then in $\chi'_\schm(y_j)$,
\begin{itemize}
\item the constant coefficient is $0 + \alpha^{(C_{i_2})}_{j,1}  \alpha^{(C_{i_1})}_{j,0} = \alpha^{(C_{i_1})}_{j,0}$ (here $\alpha^{(C_{i_2})}_{j,0} \ell_2$, the constant coefficient of $\chi^{(C_{i_2})}_{\ell_2}(y_j)$, is removed),
%
\item for $j': j' \le k, \pi_{C_{i_1}}(j') = j'$, the coefficient of $d^{(0)}_{j'}$ is $0 + \alpha^{(C_{i_2})}_{j,1} \beta^{(C_{i_1})}_{j,j'} = \beta^{(C_{i_1})}_{j,j'}$ (here $\beta^{(C_{i_2})}_{j,j'} \ell_2$ is removed),
%
\item for $j': j' \le r_{C_{i_1}}, j'+k \in \rng(\pi_{C_{i_1}})$, the coefficient of $d^{(C_{i_1},\ell_1-1)}_{j'}$ is the expression $\alpha^{(C_{i_2})}_{j,1} \beta^{(C_{i_1})}_{j, \pi^{-1}_{C_{i_1}}(j'+k)} = \beta^{(C_{i_1})}_{j, \pi^{-1}_{C_{i_1}}(j'+k)}$,
%
\item for $j': j' \le r_{C_{i_1}}, j'+k \in \rng(\pi_{C_{i_1}})$, the coefficient of $d^{(C_{i_1},\ell_1)}_{j'}$ is $\beta^{(C_{i_2})}_{j, \pi^{-1}_{C_{i_1}}(j'+k)}$,
%
\item for $j': j' \le r_{C_{i_1}}, j'+k \not \in \rng(\pi_{C_{i_1}})$, the coefficient of $d^{(C_{i_1},\ell_1)}_{j'}$ is $\alpha^{(C_{i_2})}_{j,1}  \gamma^{(C_{i_2})}_{j,j'} = \gamma^{(C_{i_2})}_{j,j'}$,
%
\item all the other coefficients are either those in $\chi^{(C_{i_2})}_{\ell_2}(y_j)$ or zero.
\end{itemize}

If $\alpha^{(C_{i_1})}_{j,1} = 1$ and $\alpha^{(C_{i_2})}_{j,1} = 0$, then in $\chi'_\schm(y_j)$,
\begin{itemize}
\item the constant coefficient is $ \alpha^{(C_{i_2})}_{j,0} + \alpha^{(C_{i_2})}_{j,1} 0 = \alpha^{(C_{i_2})}_{j,0}$ (here $\alpha^{(C_{i_1})}_{j,0} \ell_1$, the constant coefficient of $\chi^{(C_{i_1})}_{\ell_1}(y_j)$, is removed),
%
\item for $j': j' \le k, \pi_{C_{i_1}}(j') = j'$, the coefficient of $d^{(0)}_{j'}$ is $\beta^{(C_{i_2})}_{j, j'}  + \alpha^{(C_{i_2})}_{j,1} 0 = \beta^{(C_{i_2})}_{j,j'}$ (here $\beta^{(C_{i_1})}_{j,j'} \ell_1$ is removed),
%
\item for $j': j' \le r_{C_{i_1}}, j'+k \in \rng(\pi_{C_{i_1}})$, the coefficient of $d^{(C_{i_1},\ell_1-1)}_{j'}$ is the expression $\alpha^{(C_{i_2})}_{j,1} \beta^{(C_{i_1})}_{j, \pi^{-1}_{C_{i_1}}(j'+k)} = 0$,
%
\item for $j': j' \le r_{C_{i_1}}, j'+k \in \rng(\pi_{C_{i_1}})$, the coefficient of $d^{(C_{i_1},\ell_1)}_{j'}$ is $\beta^{(C_{i_2})}_{j, \pi^{-1}_{C_{i_1}}(j'+k)}$,
%
\item for $j': j' \le r_{C_{i_1}}, j'+k \not \in \rng(\pi_{C_{i_1}})$, the coefficient of $d^{(C_{i_1},\ell_1)}_{j'}$ is $\alpha^{(C_{i_2})}_{j,1}  \gamma^{(C_{i_2})}_{j,j'} = \gamma^{(C_{i_2})}_{j,j'}$,
%
\item all the other coefficients are either those in $\chi^{(C_{i_2})}_{\ell_2}(y_j)$ or zero.
\end{itemize}




Suppose that the mapping $\chi_{1,\ell_1}$ and $\chi_{2,\ell_2}$ to describe the values of the control and data variables after traversing the cycle $C_1$ and $C_2$ for $\ell_1$ and $\ell_2$ times are as in the analysis of generalized lasso above.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hide{
 that is,
\[
\begin{array}{l c l}
\chi_{(1,\ell_1)}(y_j)  & = & (\alpha_{1,(j,0)} + \alpha_{1,(j,1)} \alpha_{1,(j,0)}+ \dots +\alpha^{\ell_1-1}_{1,(j,1)} \alpha_{1,(j,0)}) + \alpha^{\ell_1}_{1,(j,1)} o_j + \\
& & \sum \limits_{j' \in J_{1,1}} (\beta_{1,(j,j')}+\alpha_{1,(j,1)}\beta_{1,(j,j')} + \dots +\alpha^{\ell_1-1}_{1,(j,1)}  \beta_{1,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{1,2}} (\alpha^{\ell_1-1}_{1,(j,1)}\beta_{1,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{1,3}} (\alpha^{\ell_1-2}_{1,(j,1)}\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha^{\ell_1-1}_{1,(j,1)}\gamma_{1,(j,j')}) d^1_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha^{\ell_1-1}_{1,(j,1)} \gamma_{1,(j,j')}) d^1_{j'} + \dots + \sum \limits_{j' \in J_{1,3}} (\beta_{1,(j, \pi^{-1}(j'+k))}+\alpha_{1,(j,1)}\gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \\
%
& & \sum \limits_{j' \in J_{1,4}} (\alpha_{1,(j,1)} \gamma_{1,(j,j')}) d^{\ell_1-1}_{j'} + \gamma_{1,(j, 1)} d^{\ell_1}_{1} + \dots + \gamma_{1,(j,r_1)} d^{\ell_1}_{r_1},
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi_{(2,\ell_2)}(y_j)  & = & (\alpha_{2,(j,0)} + \alpha_{2,(j,1)} \alpha_{2,(j,0)}+ \dots +\alpha^{\ell_2-1}_{2,(j,1)} \alpha_{2,(j,0)}) + \alpha^{\ell_2}_{2,(j,1)} o_j + \\
%
& & \sum \limits_{j' \in J_{2,1}} (\beta_{2,(j,j')}+\alpha_{2,(j,1)}\beta_{2,(j,j')} + \dots +\alpha^{\ell_2-1}_{2,(j,1)}  \beta_{2,(j,j')}) d^0_{\pi_0(j')} + \\
%
& & \sum \limits_{j' \in J_{2,2}} (\alpha^{\ell_2-1}_{2,(j,1)}\beta_{2,(j,j')}) d^0_{\pi_0(j')} +  \sum \limits_{j' \in J_{2,3}} (\alpha^{\ell_2-2}_{2,(j,1)}\beta_{2,(j, \pi^{-1}(j'+k))}+\\
%
& & \alpha^{\ell_2-1}_{2,(j,1)}\gamma_{2,(j,j')}) d^1_{j'} +  \sum \limits_{j' \in J_{2,4}} (\alpha^{\ell_2-1}_{2,(j,1)} \gamma_{2,(j,j')}) d^1_{j'} + \dots + \\
%
& & \sum \limits_{j' \in J_{2,3}} (\beta_{2,(j, \pi^{-1}(j'+k))}+ \alpha_{2,(j,1)}\gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \\
%
& &  \sum \limits_{j' \in J_{2,4}} (\alpha_{2,(j,1)} \gamma_{2,(j,j')}) d^{\ell_2-1}_{j'} + \gamma_{2,(j, 1)} d^{\ell_2}_{1} +  \dots + \gamma_{2,(j,r_2)} d^{\ell_2}_{r_2}.
\end{array} 
\]
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



Moreover, suppose $d''_1,\dots,d''_k$ are the initial values of the control variables and $o''_1,\dots,o''_l$ are the initial values of the data variables, then $\chi'_{1,\ell'_1}$ and $\chi'_{2,\ell'_2}$, which describe the values of the control and data variables after traversing the cycle $C'_1$ and $C'_2$ for $\ell_1$ and $\ell_2$ times respectively, are as follows, 
%
\[
\begin{array}{l c l}
\chi'_{(1,\ell'_1)}(y_j)  & = & (\alpha'_{1,(j,0)} + \alpha'_{1,(j,1)} \alpha'_{1,(j,0)}+ \dots +(\alpha'_{1,(j,1)})^{\ell'_1-1} \alpha'_{1,(j,0)}) + (\alpha'_{1,(j,1)})^{\ell'_1} o''_j + \\
& & \sum \limits_{j' \in J'_{1,1}} (\beta'_{1,(j,j')}+\alpha'_{1,(j,1)}\beta'_{1,(j,j')} + \dots +(\alpha'_{1,(j,1)})^{\ell'_1-1}  \beta'_{1,(j,j')}) d''_{j'} + \\
%
& & \sum \limits_{j' \in J'_{1,2}} ( (\alpha'_{1,(j,1)})^{\ell'_1-1} \beta'_{1,(j,j')}) d''_{j'} +  \sum \limits_{j' \in J'_{1,3}} ( (\alpha'_{1,(j,1)})^{\ell'_1-2} \beta'_{1,(j, \pi^{-1}(j'+k))}+\\
%
& &  (\alpha'_{1,(j,1)})^{\ell'_1-1} \gamma'_{1,(j,j')}) (d^1_{j'})' +  \sum \limits_{j' \in J'_{1,4}} ( (\alpha'_{1,(j,1)})^{\ell'_1-1} \gamma'_{1,(j,j')}) (d^1_{j'})' + \dots +  \\
%
& & \sum \limits_{j' \in J'_{1,3}} (\beta'_{1,(j, \pi^{-1}(j'+k))}+\alpha'_{1,(j,1)}\gamma'_{1,(j,j')}) (d^{\ell'_1-1}_{j'})' +\\
& & \sum \limits_{j' \in J'_{1,4}} (\alpha'_{1,(j,1)} \gamma'_{1,(j,j')}) (d^{\ell'_1-1}_{j'})' + \gamma'_{1,(j, 1)} (d^{\ell'_1}_{1})' + \dots + \gamma'_{1,(j,r_1)} (d^{\ell'_1}_{r'_1})',
\end{array} 
\]
and
\[
\begin{array}{l c l}
\chi'_{(2,\ell'_2)}(y_j)  & = & (\alpha'_{2,(j,0)} + \alpha'_{2,(j,1)} \alpha'_{2,(j,0)}+ \dots +(\alpha'_{2,(j,1)})^{\ell'_2-1} \alpha'_{2,(j,0)}) + (\alpha'_{2,(j,1)})^{\ell'_2} o''_j + \\
& & \sum \limits_{j' \in J'_{2,1}} (\beta'_{2,(j,j')}+\alpha'_{2,(j,1)}\beta'_{2,(j,j')} + \dots +(\alpha'_{2,(j,1)})^{\ell'_2-1}  \beta'_{2,(j,j')}) d''_{j'} + \\
%
& & \sum \limits_{j' \in J'_{2,2}} ( (\alpha'_{2,(j,1)})^{\ell'_2-1} \beta'_{2,(j,j')}) d''_{j'} +  \sum \limits_{j' \in J'_{2,3}} ( (\alpha'_{2,(j,1)})^{\ell'_2-2} \beta'_{2,(j, \pi^{-1}(j'+k))}+\\
%
& &  (\alpha'_{2,(j,1)})^{\ell'_2-1} \gamma'_{2,(j,j')}) (d^2_{j'})' +  \sum \limits_{j' \in J'_{2,4}} ( (\alpha'_{2,(j,1)})^{\ell'_2-1} \gamma'_{2,(j,j')}) (d^2_{j'})' + \dots +  \\
%
& & \sum \limits_{j' \in J'_{2,3}} (\beta'_{2,(j, \pi^{-1}(j'+k))}+\alpha'_{2,(j,1)}\gamma'_{2,(j,j')}) (d^{\ell'_2-1}_{j'})' +\\
& & \sum \limits_{j' \in J'_{2,4}} (\alpha'_{2,(j,1)} \gamma'_{2,(j,j')}) (d^{\ell'_2-1}_{j'})' + \gamma'_{2,(j, 1)} (d^{\ell'_2}_{1})' + \dots + \gamma'_{2,(j,r_1)} (d^{\ell'_2}_{r'_2})'.
\end{array} 
\]



Similarly to the analysis of generalized lassos, $\chi_{(b,\ell_b)}(O(q_m))$ is a linear combination of the variables $d^0_1,\dots, d^0_s$ and $d^1_1,\dots, d^1_{r_b}, \dots, d^{\ell_b}_1,\dots, d^{\ell_b}_{r_b}$. For each $j' \in J_{b,1}$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{(b,\ell_b)}(O(q_m))$ is 
%
\[a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (1+\alpha_{b,(j,1)} + \dots +\alpha^{\ell_b-1}_{b,(j,1)})\beta_{b,(j,j')}.\]
%

In general, for each $j' \in J_{1,1}$ and each cycle scheme $\schm=(1,\ell_1)(2,\ell_2) \dots (1+(t-1) \bmod 2,\ell_{t})$ (where $t \ge 1$) of $(C_1,C_2)$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm}(O(q_m))$ includes the following expression as a component,
%
\[a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)}) (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \ \ \  (\ast')\]

Note that since $\alpha_{1,(j,1)},\alpha_{2,(j,1)} \in \{0,+1,-1\}$, the expression $(\ast')$ is of the form 
\[a_{j'} + \sum \limits_{1 \le j \le l} a'_j  s_j (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')},\]
where $s_j \in \{0,+1,-1\}$.

The expression $(\ast')$ can be rewritten as $\mu_{\schm,(1,j')} \ell_1 + \nu_{\schm,(1,j')}$ for some integer constant $\mu_{\schm,(1,j')},\nu_{\schm,(1,j')}$ (possibly $\mu_{\schm,(1,j')}=0$). 

If $\mu_{\schm,(1,j')} \neq 0$, then return ``$true$''. 

Otherwise, for each cycle scheme $\schm'=(1,\ell'_1)(2,\ell'_2) \dots (1+(t'-1) \bmod 2,\ell'_{t'})$ (where $t' \ge 1$) of $(C'_1,C'_2)$, the coefficient of $d^0_{\pi_0(j')}$ in $\chi_{\schm (q'_0 \dots q'_{m'})\schm'}(O(q'_{m'}))$ includes the following expression as a component,
\[
\begin{array}{l c l}
a''_{j'} + \sum \limits_{1 \le j \le l} a'''_j (\alpha^{\ell_2}_{2,(j,1)} \dots \alpha^{\ell_t}_{1,(j,1)} (\alpha'_{1,(j,1)})^{\ell'_{1}} (\alpha'_{2,(j,1)})^{\ell'_{2}} \dots (\alpha'_{1,(j,1)})^{\ell'_{t'}}) \\
\hspace{16mm} (1+\alpha_{1,(j,1)} + \dots +\alpha^{\ell_1-1}_{1,(j,1)})\beta_{1,(j,j')}. \hspace{2cm}. (\ast'')
\end{array}
\]

The a similar analysis can be applied to $(\ast'')$ by considering all the cycle shcemes of $(C'_1,C'_2)$.

Moreover, we can apply a similar analysis for the cycle $C'_1,C'_2$ as for $C_1,C_2$, by using the output expressions $O(q'_{m'})$.

If the procedure does not return yet, then we go to Step III''.
